{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanoiervese/DL_Project/blob/main/Copia_di_DL_aggiornato.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "LhA0vWrGv07c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_lightning --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxDq5zBwwBHy",
        "outputId": "797da3ea-6799-4cf0-e255-b599e15777a7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.4/763.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r DL_Project\n",
        "!git clone https://github.com/stefanoiervese/DL_Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yqlBgIcwOvz",
        "outputId": "067f3eeb-b4e8-4a06-d4df-07c2cdd3a59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DL_Project'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 69 (delta 26), reused 4 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (69/69), 39.85 MiB | 1.41 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pack_sequence, pad_sequence\n"
      ],
      "metadata": {
        "id": "OL3QjmM-wXqS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities"
      ],
      "metadata": {
        "id": "xUYWE4La3O8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self,sentences):\n",
        "        self.sentences=sentences\n",
        "        self.vocab = self.crea_vocabolario(sentences)\n",
        "        self.word_to_id = {word: idx for idx, word in enumerate(self.vocab)}\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        tokens = re.findall(r'\\b\\w+\\b|\\d+|[^\\w\\s]', text)\n",
        "\n",
        "\n",
        "\n",
        "        token_id = []\n",
        "        unknown_tokens = []\n",
        "\n",
        "        new_tokens = []\n",
        "        for token in tokens:\n",
        "          flag=0\n",
        "          if '.' in token and token != '.':\n",
        "            token=token=token.split('.')[0]\n",
        "            flag=1\n",
        "          if token in self.word_to_id:\n",
        "            token_id.append(self.word_to_id[token])\n",
        "          else:\n",
        "                token_id.append(self.word_to_id['unknown'])\n",
        "                unknown_tokens.append(token)\n",
        "          if(flag==1):\n",
        "            token_id.append(self.word_to_id['.'])\n",
        "\n",
        "\n",
        "        if unknown_tokens:\n",
        "\n",
        "          print(\"Parole sconosciute:\", unknown_tokens)\n",
        "\n",
        "        return token_id\n",
        "\n",
        "    def crea_vocabolario(self, frasi):\n",
        "      vocabolario = set()\n",
        "\n",
        "      for frase in frasi:\n",
        "        parole = re.findall(r'\\b\\w+\\b|\\d+|[^\\w\\s]', frase.lower())\n",
        "        vocabolario.update(parole)\n",
        "      return ['&','#','@','unknown']+list(vocabolario)\n",
        "\n",
        "def paper_accuracy(predicted_answers, correct_answers):\n",
        "  num_correct_answers = 0\n",
        "  end_of_line=2\n",
        "\n",
        "  for i in range(len(predicted_answers)):\n",
        "\n",
        "    single_predicted_answer = torch.argmax(predicted_answers[i], 1).tolist()  # vector of shape (answer_max_length) (concatenates the max value for each row)\n",
        "\n",
        "\n",
        "    single_predicted_answer = single_predicted_answer[1:single_predicted_answer.index(2)]  # removing start and end of line char and additional characters\n",
        "\n",
        "\n",
        "    single_correct_answer = correct_answers[i].tolist()\n",
        "    single_correct_answer = single_correct_answer[1:single_correct_answer.index(2)]  # removing start of line, end of line and following characters\n",
        "\n",
        "    if (single_predicted_answer == single_correct_answer):\n",
        "      num_correct_answers += 1\n",
        "\n",
        "  return num_correct_answers/len(predicted_answers)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vja0OFLp3XVz"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jKZmIt9-jVF",
        "outputId": "6cc9cb30-5715-4b91-c8b7-199fba0a138c"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README.md',\n",
              " 'arithmetic__add_or_sub.txt.zip',\n",
              " 'interpolate',\n",
              " '.git',\n",
              " 'DL.ipynb',\n",
              " 'DL_Project',\n",
              " 'extrapolate.zip',\n",
              " 'interpolate.zip']"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNDAFYDRiQNg"
      },
      "source": [
        "# Dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='interpolate/interpolate/'\n",
        "for file in os.listdir(path):\n",
        "\n",
        "  with open(path+file, \"r\") as file:\n",
        "    content = file.read()\n",
        "    data_list=data_list+[x for x in content.split('\\n')]\n",
        "\n",
        "while '' in data_list:\n",
        "    data_list.remove('')\n",
        "\n",
        "len_data=len(data_list)\n",
        "quest=[]\n",
        "ans=[]\n",
        "for i in range(len_data):\n",
        "  if(i%2==0):\n",
        "    quest.append(data_list[i])\n",
        "  else:\n",
        "    data=\"# \" + data_list[i] + \" @\"\n",
        "    ans.append(data)\n",
        "coppie = list(zip(quest,ans))\n",
        "random.shuffle(coppie)\n",
        "quest, ans=zip(*coppie)\n",
        "l=int(len(quest)/3)\n",
        "train_q=quest[:2*l]\n",
        "test_q=quest[2*l:]\n",
        "train_a=ans[:2*l]\n",
        "test_a=ans[2*l:]\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(data_list)\n",
        "\n",
        "qt=[]\n",
        "at=[]\n",
        "for x in train_q:\n",
        "  qt.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "for x in train_a:\n",
        "  at.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "\n",
        "qtest=[]\n",
        "atest=[]\n",
        "for x in test_q:\n",
        "  qtest.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "for x in test_a:\n",
        "  atest.append(torch.tensor(tokenizer.tokenize(x.lower())))"
      ],
      "metadata": {
        "id": "dpME3bhqwAuZ"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_to_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pd-ggpk-Ilf",
        "outputId": "99117bd4-2345-49d0-92d4-11c33cbc8309"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'&': 0,\n",
              " '#': 1,\n",
              " '@': 2,\n",
              " 'unknown': 3,\n",
              " '91600037': 4,\n",
              " '0426': 5,\n",
              " '74378': 6,\n",
              " '52304': 7,\n",
              " '5064': 8,\n",
              " '08862': 9,\n",
              " '8481': 10,\n",
              " '9535231478': 11,\n",
              " '30b30': 12,\n",
              " '1747002247': 13,\n",
              " '1883802': 14,\n",
              " 'when': 15,\n",
              " '7921450118': 16,\n",
              " '8381': 17,\n",
              " '90649377': 18,\n",
              " '21991110': 19,\n",
              " '20837285': 20,\n",
              " '625588': 21,\n",
              " '00000070385857': 22,\n",
              " '3225782028': 23,\n",
              " '26159091858': 24,\n",
              " '227603': 25,\n",
              " '611609665499': 26,\n",
              " '2612774480': 27,\n",
              " '359079': 28,\n",
              " '7732842': 29,\n",
              " '30937554': 30,\n",
              " '41a06d': 31,\n",
              " '744303': 32,\n",
              " '1500513': 33,\n",
              " '29824612': 34,\n",
              " '008667': 35,\n",
              " '425887882': 36,\n",
              " '3881': 37,\n",
              " '94738984953': 38,\n",
              " '169308': 39,\n",
              " '59608': 40,\n",
              " 'imhii': 41,\n",
              " '92104': 42,\n",
              " '132310110': 43,\n",
              " '179968': 44,\n",
              " '2661': 45,\n",
              " '6457006': 46,\n",
              " '4367579239': 47,\n",
              " '3763': 48,\n",
              " '4426954184': 49,\n",
              " '5066123': 50,\n",
              " '4975262': 51,\n",
              " '31587470': 52,\n",
              " '5017585000000000': 53,\n",
              " '299526': 54,\n",
              " '249718': 55,\n",
              " '137407': 56,\n",
              " '788624': 57,\n",
              " '5830': 58,\n",
              " '00586971': 59,\n",
              " '1136323541': 60,\n",
              " '7537286': 61,\n",
              " '5669512': 62,\n",
              " '448712': 63,\n",
              " '1011001010100011110000': 64,\n",
              " '2152429': 65,\n",
              " '4458812238': 66,\n",
              " 'ubrxx': 67,\n",
              " '224680674': 68,\n",
              " '554340': 69,\n",
              " '597088046468': 70,\n",
              " '807ns': 71,\n",
              " '100112': 72,\n",
              " '111100001000110': 73,\n",
              " '830769': 74,\n",
              " '42244435': 75,\n",
              " '6909240': 76,\n",
              " '1707185': 77,\n",
              " '9395275428': 78,\n",
              " '4403210': 79,\n",
              " '98904916': 80,\n",
              " '839032': 81,\n",
              " '1051312': 82,\n",
              " '99430702': 83,\n",
              " '441596111': 84,\n",
              " '1240189': 85,\n",
              " '207593': 86,\n",
              " '1660039': 87,\n",
              " '93565': 88,\n",
              " 'gngqqvnqeva': 89,\n",
              " '164786': 90,\n",
              " '288708': 91,\n",
              " '1377696': 92,\n",
              " '863508': 93,\n",
              " '318281681': 94,\n",
              " 'nnnnhnnnnn': 95,\n",
              " '9994215400': 96,\n",
              " '72064': 97,\n",
              " '47082': 98,\n",
              " '33600': 99,\n",
              " '27054218': 100,\n",
              " '19520724': 101,\n",
              " '113879': 102,\n",
              " '40784973125183': 103,\n",
              " '107548': 104,\n",
              " '22193305884': 105,\n",
              " '492855': 106,\n",
              " '15350845': 107,\n",
              " '1946215': 108,\n",
              " '9441136': 109,\n",
              " '6591444': 110,\n",
              " '147989444': 111,\n",
              " '1213783': 112,\n",
              " '375673': 113,\n",
              " '223675': 114,\n",
              " 'odpo': 115,\n",
              " '38196042': 116,\n",
              " '1000011001010': 117,\n",
              " 'woodroooawdwoaaooww': 118,\n",
              " '3707847653': 119,\n",
              " '168073': 120,\n",
              " '5288092': 121,\n",
              " '281081': 122,\n",
              " '145529': 123,\n",
              " '906233111249': 124,\n",
              " '8580768': 125,\n",
              " '384056': 126,\n",
              " '242310065869': 127,\n",
              " '1183821': 128,\n",
              " '1809548': 129,\n",
              " '3625542': 130,\n",
              " '1116535885': 131,\n",
              " '6782368': 132,\n",
              " '10732150': 133,\n",
              " 'ffzasspsasfaspasazfp': 134,\n",
              " '34115040': 135,\n",
              " '238473': 136,\n",
              " 'mmx': 137,\n",
              " '85667': 138,\n",
              " '1145311': 139,\n",
              " '6041383': 140,\n",
              " '44918': 141,\n",
              " '7156639344': 142,\n",
              " '77848': 143,\n",
              " '44553': 144,\n",
              " '182807': 145,\n",
              " '21651260': 146,\n",
              " '6645552': 147,\n",
              " '229115': 148,\n",
              " '2dbb1': 149,\n",
              " '253621': 150,\n",
              " '21448': 151,\n",
              " '46628': 152,\n",
              " '1766656': 153,\n",
              " '34610': 154,\n",
              " '551335': 155,\n",
              " '78245': 156,\n",
              " '753214': 157,\n",
              " '542278': 158,\n",
              " '446050': 159,\n",
              " '229721': 160,\n",
              " '98932650': 161,\n",
              " '28519': 162,\n",
              " '489225': 163,\n",
              " '499998945': 164,\n",
              " '52589023': 165,\n",
              " '5094900': 166,\n",
              " '59498661': 167,\n",
              " 'hyw': 168,\n",
              " '20121101110': 169,\n",
              " '4088827': 170,\n",
              " '9932630702': 171,\n",
              " '9653618': 172,\n",
              " '835492': 173,\n",
              " '121324': 174,\n",
              " '493995560': 175,\n",
              " '16845': 176,\n",
              " 'muxmmmmuxmufm': 177,\n",
              " '8541400000': 178,\n",
              " '37536199': 179,\n",
              " '1033142': 180,\n",
              " '13676723': 181,\n",
              " '8391600': 182,\n",
              " '4226496420': 183,\n",
              " '8679078': 184,\n",
              " '81268': 185,\n",
              " '56184': 186,\n",
              " '29788825': 187,\n",
              " '2154041': 188,\n",
              " '13360': 189,\n",
              " '210102': 190,\n",
              " '227164': 191,\n",
              " '44070067258': 192,\n",
              " '458376846877': 193,\n",
              " '1779315': 194,\n",
              " '4221135': 195,\n",
              " '905457': 196,\n",
              " '125977': 197,\n",
              " '37227575': 198,\n",
              " '59046666': 199,\n",
              " '34882': 200,\n",
              " '4610802': 201,\n",
              " '1193190616': 202,\n",
              " '290786': 203,\n",
              " '1291335': 204,\n",
              " '58968': 205,\n",
              " '5547815': 206,\n",
              " '11309': 207,\n",
              " '10430988230': 208,\n",
              " '1100456': 209,\n",
              " 'hhhhrhrrrhhrhrrrrrr': 210,\n",
              " '81527': 211,\n",
              " '00037218346286': 212,\n",
              " '27058142': 213,\n",
              " '468055': 214,\n",
              " '618995': 215,\n",
              " '47048': 216,\n",
              " '64475468': 217,\n",
              " '62492': 218,\n",
              " '623927539': 219,\n",
              " '49531214': 220,\n",
              " '95699417': 221,\n",
              " '06075': 222,\n",
              " '44274261330': 223,\n",
              " '0612917321708': 224,\n",
              " '11177': 225,\n",
              " '7058888': 226,\n",
              " '2899755440': 227,\n",
              " '61656519': 228,\n",
              " 'xcxxc': 229,\n",
              " '1255737': 230,\n",
              " '111252160': 231,\n",
              " '2754340': 232,\n",
              " '17479546': 233,\n",
              " '1362830': 234,\n",
              " 'mu': 235,\n",
              " '2973103': 236,\n",
              " '379547': 237,\n",
              " '11110020': 238,\n",
              " '25866': 239,\n",
              " '75129': 240,\n",
              " '622076': 241,\n",
              " '557155083744': 242,\n",
              " '34149': 243,\n",
              " '50965992': 244,\n",
              " '556419': 245,\n",
              " 'qxqqqx': 246,\n",
              " '15504287': 247,\n",
              " '143787': 248,\n",
              " '93539098': 249,\n",
              " '11321234': 250,\n",
              " '5139920': 251,\n",
              " '10101001001100100111000': 252,\n",
              " '418146557': 253,\n",
              " '334518207': 254,\n",
              " '4147794': 255,\n",
              " '635553': 256,\n",
              " '905899': 257,\n",
              " '354573961': 258,\n",
              " '5593813': 259,\n",
              " '130312303': 260,\n",
              " '37469403': 261,\n",
              " '40946': 262,\n",
              " '14303341': 263,\n",
              " '17075033592332': 264,\n",
              " '2731219': 265,\n",
              " 'qxxn': 266,\n",
              " '32373': 267,\n",
              " '21587723': 268,\n",
              " '472499': 269,\n",
              " '13272400': 270,\n",
              " '448649': 271,\n",
              " 'xgfgg': 272,\n",
              " '200514': 273,\n",
              " '37417': 274,\n",
              " '6527': 275,\n",
              " '5665382': 276,\n",
              " '19283': 277,\n",
              " '42977': 278,\n",
              " '4505910': 279,\n",
              " '176247': 280,\n",
              " '9108': 281,\n",
              " '291604': 282,\n",
              " '4427ml': 283,\n",
              " '04883': 284,\n",
              " '1573469': 285,\n",
              " 'uorqauqu': 286,\n",
              " '1214465': 287,\n",
              " '67826': 288,\n",
              " '87652': 289,\n",
              " '3006804': 290,\n",
              " '2291387': 291,\n",
              " '291952': 292,\n",
              " '5407767': 293,\n",
              " '961912': 294,\n",
              " '966324311': 295,\n",
              " '355252287': 296,\n",
              " '32': 297,\n",
              " '362404827': 298,\n",
              " '0882654': 299,\n",
              " '612980': 300,\n",
              " '8312861': 301,\n",
              " '3102970947': 302,\n",
              " '325331': 303,\n",
              " '439348': 304,\n",
              " '15144465': 305,\n",
              " '268759': 306,\n",
              " '348774005': 307,\n",
              " '51872504': 308,\n",
              " '11487': 309,\n",
              " '89305143': 310,\n",
              " '82619522': 311,\n",
              " '52479242': 312,\n",
              " '1079683': 313,\n",
              " '25280': 314,\n",
              " '1840764': 315,\n",
              " '1065520': 316,\n",
              " '8648464': 317,\n",
              " '9973735755': 318,\n",
              " '6536784': 319,\n",
              " '1539035': 320,\n",
              " '345930022856': 321,\n",
              " 'bbbqb': 322,\n",
              " '991158': 323,\n",
              " '92248800': 324,\n",
              " '10600335': 325,\n",
              " '386444': 326,\n",
              " '209840': 327,\n",
              " '115780464584316': 328,\n",
              " '3276346': 329,\n",
              " '1603403': 330,\n",
              " 'igggogggiogg': 331,\n",
              " '203835': 332,\n",
              " '49138690': 333,\n",
              " '2286152': 334,\n",
              " '8390515': 335,\n",
              " '944785': 336,\n",
              " '142197': 337,\n",
              " '00210436173': 338,\n",
              " '16570400': 339,\n",
              " '228661558701472': 340,\n",
              " '6484170': 341,\n",
              " '10663800': 342,\n",
              " '943707483': 343,\n",
              " '6031255120000': 344,\n",
              " 'kpqqj': 345,\n",
              " '5178778': 346,\n",
              " '281042': 347,\n",
              " '54423650000000': 348,\n",
              " '206237': 349,\n",
              " '60387978': 350,\n",
              " 'ffhd': 351,\n",
              " '87574': 352,\n",
              " '7994000': 353,\n",
              " '99988818': 354,\n",
              " '206244': 355,\n",
              " '261501050073': 356,\n",
              " '2433426': 357,\n",
              " '1191292': 358,\n",
              " '299040': 359,\n",
              " '2484240464': 360,\n",
              " '2249580': 361,\n",
              " '159639680': 362,\n",
              " '751245305327': 363,\n",
              " '571026': 364,\n",
              " '1123516503': 365,\n",
              " '554606096': 366,\n",
              " '2987580': 367,\n",
              " '755104': 368,\n",
              " '1248323': 369,\n",
              " '65222': 370,\n",
              " '24696000': 371,\n",
              " '18287526': 372,\n",
              " 'foo': 373,\n",
              " '1722803': 374,\n",
              " '851379050921': 375,\n",
              " '2583110547': 376,\n",
              " '12006032': 377,\n",
              " '4269561617538687488': 378,\n",
              " '36345': 379,\n",
              " '128960': 380,\n",
              " '6733665': 381,\n",
              " '88746786': 382,\n",
              " '17245605': 383,\n",
              " '043t': 384,\n",
              " '13149951': 385,\n",
              " '822641': 386,\n",
              " '3869160508': 387,\n",
              " '23041': 388,\n",
              " '789655': 389,\n",
              " '660495556': 390,\n",
              " '312299': 391,\n",
              " '259767': 392,\n",
              " '8670060': 393,\n",
              " 'c46a': 394,\n",
              " '638494688': 395,\n",
              " '91976300000000000000': 396,\n",
              " '10770648267': 397,\n",
              " '100102102121': 398,\n",
              " 'boboobvovzodbvro': 399,\n",
              " '068098': 400,\n",
              " '60216102': 401,\n",
              " '1408279': 402,\n",
              " '1870291': 403,\n",
              " '221325738287484526': 404,\n",
              " '15498570': 405,\n",
              " '34094522524': 406,\n",
              " '110101': 407,\n",
              " '14245412': 408,\n",
              " '254907': 409,\n",
              " 'toozo': 410,\n",
              " '8188306568': 411,\n",
              " '1889005': 412,\n",
              " '21012220120': 413,\n",
              " '521619965': 414,\n",
              " '5761665': 415,\n",
              " '8891339': 416,\n",
              " '3163': 417,\n",
              " '95303': 418,\n",
              " '66457292145360': 419,\n",
              " '35334454400000': 420,\n",
              " '2792889l': 421,\n",
              " '38232': 422,\n",
              " '129154': 423,\n",
              " '112642': 424,\n",
              " '1360085731': 425,\n",
              " '818898': 426,\n",
              " '1216030': 427,\n",
              " '17558538': 428,\n",
              " '436149': 429,\n",
              " '16608222': 430,\n",
              " '7873236': 431,\n",
              " '977424': 432,\n",
              " '33768096': 433,\n",
              " '11111101101101100': 434,\n",
              " '16662889': 435,\n",
              " 'yoo': 436,\n",
              " '2891576832900': 437,\n",
              " '2087984353': 438,\n",
              " '3203599': 439,\n",
              " '411d6': 440,\n",
              " '20274': 441,\n",
              " '97661': 442,\n",
              " '393153': 443,\n",
              " '57887': 444,\n",
              " '320983': 445,\n",
              " '315279': 446,\n",
              " '2154b': 447,\n",
              " '5729235': 448,\n",
              " '66820395': 449,\n",
              " '96808189': 450,\n",
              " '32740400': 451,\n",
              " '6398784': 452,\n",
              " '590748': 453,\n",
              " '75051871': 454,\n",
              " '28790519625000': 455,\n",
              " '40918': 456,\n",
              " '1010000101000111100': 457,\n",
              " '64825918': 458,\n",
              " '577020': 459,\n",
              " '51654084': 460,\n",
              " 'btbbs': 461,\n",
              " '612942934752000': 462,\n",
              " '2325': 463,\n",
              " '33143022': 464,\n",
              " '456109': 465,\n",
              " '7725094190': 466,\n",
              " '5658442710': 467,\n",
              " '098496': 468,\n",
              " '41749': 469,\n",
              " '3777975': 470,\n",
              " '21998222': 471,\n",
              " '0007772703': 472,\n",
              " '91017370': 473,\n",
              " 'qehvh': 474,\n",
              " '0004266': 475,\n",
              " '53290646': 476,\n",
              " '2642101': 477,\n",
              " '0182298556': 478,\n",
              " '245402719': 479,\n",
              " '9769118392': 480,\n",
              " '50799': 481,\n",
              " '332233': 482,\n",
              " '30208500': 483,\n",
              " '268944': 484,\n",
              " '1623768': 485,\n",
              " '816861399': 486,\n",
              " '3753673': 487,\n",
              " '70300': 488,\n",
              " '14509477': 489,\n",
              " '3265221': 490,\n",
              " '8020022': 491,\n",
              " '149927': 492,\n",
              " '48ml': 493,\n",
              " '281357ml': 494,\n",
              " '10912788': 495,\n",
              " '2233777': 496,\n",
              " '10452151': 497,\n",
              " '58269797': 498,\n",
              " '46888393': 499,\n",
              " '15882955': 500,\n",
              " '34087': 501,\n",
              " '1034487925561287': 502,\n",
              " '104702': 503,\n",
              " '471713': 504,\n",
              " '517101': 505,\n",
              " '2598': 506,\n",
              " '23231211212': 507,\n",
              " '2493688380': 508,\n",
              " '55102': 509,\n",
              " '411952': 510,\n",
              " '35329713': 511,\n",
              " '85030412': 512,\n",
              " '40975': 513,\n",
              " '695427': 514,\n",
              " '640315633061': 515,\n",
              " '108135020389': 516,\n",
              " '2603015': 517,\n",
              " '26850523927': 518,\n",
              " '72411738': 519,\n",
              " '69075': 520,\n",
              " '841459': 521,\n",
              " '10597701308': 522,\n",
              " '57c23': 523,\n",
              " '7098981697225': 524,\n",
              " '0420511475': 525,\n",
              " '104018927': 526,\n",
              " '37990': 527,\n",
              " '50793148': 528,\n",
              " '18136842': 529,\n",
              " '98165': 530,\n",
              " '67739453': 531,\n",
              " '48865069485620': 532,\n",
              " '192151': 533,\n",
              " '162184400': 534,\n",
              " '17738349': 535,\n",
              " '33312031': 536,\n",
              " '32063280': 537,\n",
              " '8295244': 538,\n",
              " '347087039': 539,\n",
              " 'zdzd': 540,\n",
              " 'pppgigipaiapap': 541,\n",
              " '279298': 542,\n",
              " '4126865': 543,\n",
              " '45685845758': 544,\n",
              " '99415736': 545,\n",
              " '6698916': 546,\n",
              " '12310781888': 547,\n",
              " '0021': 548,\n",
              " '84222268': 549,\n",
              " '815920': 550,\n",
              " '032364': 551,\n",
              " '0000000008565014': 552,\n",
              " '241014166': 553,\n",
              " '188158': 554,\n",
              " '3379356': 555,\n",
              " '906386': 556,\n",
              " '68701': 557,\n",
              " '5022526': 558,\n",
              " '972883': 559,\n",
              " '640904': 560,\n",
              " 'xiexftxdet': 561,\n",
              " '1234802': 562,\n",
              " '16328804769': 563,\n",
              " 'pllpl': 564,\n",
              " '194151657': 565,\n",
              " 'pzzzzpzpppp': 566,\n",
              " '713417': 567,\n",
              " '252078914': 568,\n",
              " '232280': 569,\n",
              " '1106302': 570,\n",
              " '29455300000': 571,\n",
              " '51810': 572,\n",
              " '675975177': 573,\n",
              " '110414694': 574,\n",
              " '67677578': 575,\n",
              " '94250': 576,\n",
              " '46789': 577,\n",
              " '1994083680': 578,\n",
              " '28456530': 579,\n",
              " '13203310': 580,\n",
              " 'sna': 581,\n",
              " '371322': 582,\n",
              " '29670': 583,\n",
              " '189159704': 584,\n",
              " '3349068': 585,\n",
              " '381714': 586,\n",
              " '769095805': 587,\n",
              " '3374454': 588,\n",
              " 'xxhjjhxxhjhjj': 589,\n",
              " '5616644110': 590,\n",
              " '1985383': 591,\n",
              " '5340391': 592,\n",
              " '20282': 593,\n",
              " '15007144': 594,\n",
              " '39441396': 595,\n",
              " '6476275': 596,\n",
              " '4720684129': 597,\n",
              " '1194027': 598,\n",
              " '1479383': 599,\n",
              " '6635461': 600,\n",
              " '2191489': 601,\n",
              " '21969': 602,\n",
              " '1124142': 603,\n",
              " '31594': 604,\n",
              " '2400864': 605,\n",
              " '32005932': 606,\n",
              " '578437841': 607,\n",
              " '000067': 608,\n",
              " '326104': 609,\n",
              " '80175': 610,\n",
              " '17895332': 611,\n",
              " '12327': 612,\n",
              " '8208': 613,\n",
              " 'txlxlxt': 614,\n",
              " '34566': 615,\n",
              " '60109230': 616,\n",
              " '644063': 617,\n",
              " '22466173': 618,\n",
              " '40156808176': 619,\n",
              " '8660002': 620,\n",
              " 'bc6': 621,\n",
              " '3567179': 622,\n",
              " '9071095': 623,\n",
              " 'a01b4': 624,\n",
              " '23386': 625,\n",
              " '38931': 626,\n",
              " '6572': 627,\n",
              " 'kwdp': 628,\n",
              " '56064819': 629,\n",
              " '24241490': 630,\n",
              " '22434725589': 631,\n",
              " '442326': 632,\n",
              " '74539169': 633,\n",
              " '3775560613': 634,\n",
              " '145ab68': 635,\n",
              " 'iiifi': 636,\n",
              " '38142004': 637,\n",
              " '764208': 638,\n",
              " '56681': 639,\n",
              " '282507892': 640,\n",
              " '564570': 641,\n",
              " '6391710': 642,\n",
              " '017524': 643,\n",
              " '2114153': 644,\n",
              " '15812480': 645,\n",
              " '19813241': 646,\n",
              " '130680': 647,\n",
              " '1516511392800': 648,\n",
              " '561034': 649,\n",
              " '1833398005': 650,\n",
              " '3209456624': 651,\n",
              " '96003704': 652,\n",
              " '0000178057718': 653,\n",
              " 'mymmrrmmmmmrmmmmsmm': 654,\n",
              " '488471480': 655,\n",
              " '603040': 656,\n",
              " '67401': 657,\n",
              " '177783829405': 658,\n",
              " '5817510': 659,\n",
              " '2750000': 660,\n",
              " 'ooookoooooook': 661,\n",
              " '12090141': 662,\n",
              " '310095244634': 663,\n",
              " '80443629': 664,\n",
              " '831087': 665,\n",
              " '323556': 666,\n",
              " '2574152': 667,\n",
              " 'kkekqkkcqkk': 668,\n",
              " '31639775': 669,\n",
              " '14594788755': 670,\n",
              " '790152721': 671,\n",
              " '4877192': 672,\n",
              " '6668471': 673,\n",
              " '555351443': 674,\n",
              " '6043813': 675,\n",
              " '305570449860': 676,\n",
              " '2413846': 677,\n",
              " '0000004834563': 678,\n",
              " '2525887': 679,\n",
              " '2761665280': 680,\n",
              " '892224': 681,\n",
              " '3954725': 682,\n",
              " '280162': 683,\n",
              " '8855616': 684,\n",
              " '21140': 685,\n",
              " '14667768': 686,\n",
              " '45c16': 687,\n",
              " '365105': 688,\n",
              " '196098': 689,\n",
              " '12053283': 690,\n",
              " '372935': 691,\n",
              " '475585': 692,\n",
              " '06383': 693,\n",
              " '2607396': 694,\n",
              " '4132304': 695,\n",
              " '1290534': 696,\n",
              " '000000791961525': 697,\n",
              " '156408': 698,\n",
              " '64834951': 699,\n",
              " '79829095': 700,\n",
              " '33270': 701,\n",
              " 'klqd': 702,\n",
              " '3286359': 703,\n",
              " '2212212211': 704,\n",
              " '84359': 705,\n",
              " '209040252': 706,\n",
              " '2183922': 707,\n",
              " '3963': 708,\n",
              " '9642834': 709,\n",
              " '3131937': 710,\n",
              " '137751': 711,\n",
              " '3549075': 712,\n",
              " '5084088': 713,\n",
              " '2368464': 714,\n",
              " '4613': 715,\n",
              " '1576055': 716,\n",
              " '20307442100': 717,\n",
              " 'pdpoddwwnpowp': 718,\n",
              " 'pjjeppeejjei': 719,\n",
              " '181421': 720,\n",
              " '42085641': 721,\n",
              " '25338942': 722,\n",
              " '194711712722': 723,\n",
              " '15896790': 724,\n",
              " '244271': 725,\n",
              " '313550': 726,\n",
              " '900720': 727,\n",
              " '038l': 728,\n",
              " '637249': 729,\n",
              " '24480': 730,\n",
              " '292846': 731,\n",
              " '6834240': 732,\n",
              " '95927': 733,\n",
              " '05841': 734,\n",
              " '102922': 735,\n",
              " '13115': 736,\n",
              " '946914': 737,\n",
              " '437725344': 738,\n",
              " '157460999': 739,\n",
              " '3595088': 740,\n",
              " '1722002': 741,\n",
              " '1343651579': 742,\n",
              " '76568946': 743,\n",
              " '2126852': 744,\n",
              " '76321': 745,\n",
              " '10424526': 746,\n",
              " '36372': 747,\n",
              " '589180': 748,\n",
              " '578118812': 749,\n",
              " '1026869': 750,\n",
              " '2499475': 751,\n",
              " '1161083': 752,\n",
              " '260721': 753,\n",
              " '54248': 754,\n",
              " '354719340': 755,\n",
              " '31826688': 756,\n",
              " '4381663': 757,\n",
              " '77b7': 758,\n",
              " '713487620000': 759,\n",
              " '126189': 760,\n",
              " '306663': 761,\n",
              " '73640487': 762,\n",
              " '562991': 763,\n",
              " '2707000000': 764,\n",
              " '753503': 765,\n",
              " '44256': 766,\n",
              " '438825': 767,\n",
              " '29549844': 768,\n",
              " '2999800000': 769,\n",
              " '000000194651375': 770,\n",
              " '3808425': 771,\n",
              " '854726': 772,\n",
              " '70721': 773,\n",
              " '398832': 774,\n",
              " '1689806767706': 775,\n",
              " '20043': 776,\n",
              " '6036048': 777,\n",
              " '887156': 778,\n",
              " '5270310097': 779,\n",
              " '15379164': 780,\n",
              " '09677': 781,\n",
              " '7877982': 782,\n",
              " '3602708': 783,\n",
              " '266241': 784,\n",
              " '698374l': 785,\n",
              " '48946': 786,\n",
              " '5994': 787,\n",
              " '103353': 788,\n",
              " '157697': 789,\n",
              " 'klauiy': 790,\n",
              " '38586669': 791,\n",
              " 'eeweeeeeweeeeeecwe': 792,\n",
              " '77613550': 793,\n",
              " '178921441216': 794,\n",
              " 'lkttt': 795,\n",
              " '26576000': 796,\n",
              " '82707641100': 797,\n",
              " '034555749': 798,\n",
              " '3244291': 799,\n",
              " 'vffflvdevefzlfflv': 800,\n",
              " '804744': 801,\n",
              " '32089': 802,\n",
              " '1034141': 803,\n",
              " '5548989590': 804,\n",
              " '1743432': 805,\n",
              " '47660524824': 806,\n",
              " '47483423': 807,\n",
              " '104869401': 808,\n",
              " '30883943': 809,\n",
              " '185840012702': 810,\n",
              " '534041772925': 811,\n",
              " '0003187067': 812,\n",
              " '230119': 813,\n",
              " '161851': 814,\n",
              " '1034997': 815,\n",
              " '414552': 816,\n",
              " '19933': 817,\n",
              " '1708194452': 818,\n",
              " '62169': 819,\n",
              " '727987': 820,\n",
              " '52592': 821,\n",
              " '281792519': 822,\n",
              " '939741264': 823,\n",
              " '88887': 824,\n",
              " '610811487331': 825,\n",
              " 'hhhhhhhhhh': 826,\n",
              " '8364051': 827,\n",
              " '148221': 828,\n",
              " '6449407': 829,\n",
              " '133356': 830,\n",
              " '15757264183275': 831,\n",
              " '66632297': 832,\n",
              " '1709268': 833,\n",
              " '530887': 834,\n",
              " '147554738599': 835,\n",
              " '3069685': 836,\n",
              " '94677095': 837,\n",
              " '937797329230': 838,\n",
              " '396862': 839,\n",
              " '202073': 840,\n",
              " '237062': 841,\n",
              " '26000000': 842,\n",
              " '2884360769': 843,\n",
              " '381619': 844,\n",
              " '9841656': 845,\n",
              " '3627982': 846,\n",
              " '58774326': 847,\n",
              " '633565': 848,\n",
              " '11169047': 849,\n",
              " '3395155': 850,\n",
              " '360194': 851,\n",
              " '52086064': 852,\n",
              " '00558996': 853,\n",
              " '31136': 854,\n",
              " '4520210': 855,\n",
              " '35853874': 856,\n",
              " '36640': 857,\n",
              " '256703': 858,\n",
              " '2463198': 859,\n",
              " '93579': 860,\n",
              " '53917': 861,\n",
              " '12789920': 862,\n",
              " '13763651': 863,\n",
              " '16964701': 864,\n",
              " '351757608': 865,\n",
              " '756561053137922809': 866,\n",
              " '10069933': 867,\n",
              " 'wiiiw': 868,\n",
              " '97028': 869,\n",
              " '9903976': 870,\n",
              " '13ce2': 871,\n",
              " '292407': 872,\n",
              " '48041067': 873,\n",
              " '101010111011101110': 874,\n",
              " '30164577988': 875,\n",
              " '3200617009': 876,\n",
              " '4128141': 877,\n",
              " '9533903687': 878,\n",
              " '37675692648': 879,\n",
              " 'npnapwnnwnnpwppn': 880,\n",
              " '4419008': 881,\n",
              " '42407': 882,\n",
              " '30953': 883,\n",
              " '82792': 884,\n",
              " '90395118': 885,\n",
              " '14981424': 886,\n",
              " '89718': 887,\n",
              " '26605482': 888,\n",
              " '13593590': 889,\n",
              " '751283': 890,\n",
              " '593773': 891,\n",
              " '36685330': 892,\n",
              " '75835': 893,\n",
              " '55351242': 894,\n",
              " '1b24944': 895,\n",
              " '61221335': 896,\n",
              " '5773143': 897,\n",
              " '271888870926824': 898,\n",
              " '10393372': 899,\n",
              " '3338644': 900,\n",
              " '12469209': 901,\n",
              " '416019671ns': 902,\n",
              " '7344670141': 903,\n",
              " '523200': 904,\n",
              " '433752667': 905,\n",
              " '176610': 906,\n",
              " '90154802': 907,\n",
              " '355143': 908,\n",
              " '155804753235173952': 909,\n",
              " '11345177': 910,\n",
              " '937903': 911,\n",
              " '801938': 912,\n",
              " '13696200': 913,\n",
              " '89145': 914,\n",
              " '430390': 915,\n",
              " '27575': 916,\n",
              " '41865604': 917,\n",
              " '1851612': 918,\n",
              " '8078504538': 919,\n",
              " '05641': 920,\n",
              " '160789': 921,\n",
              " '220279': 922,\n",
              " '9583': 923,\n",
              " '1025704': 924,\n",
              " '678736': 925,\n",
              " '3343897263600': 926,\n",
              " '11020210': 927,\n",
              " '118000655511': 928,\n",
              " '96575': 929,\n",
              " 'jjff': 930,\n",
              " '50632': 931,\n",
              " '55288274': 932,\n",
              " '38110000': 933,\n",
              " '1173723': 934,\n",
              " 'cuydcyuycbducc': 935,\n",
              " '26048': 936,\n",
              " '636445': 937,\n",
              " '1613232': 938,\n",
              " '759826': 939,\n",
              " '1273821': 940,\n",
              " '1880060': 941,\n",
              " '3781': 942,\n",
              " '1384391': 943,\n",
              " '816043': 944,\n",
              " '29734768422': 945,\n",
              " '765029': 946,\n",
              " '1058137': 947,\n",
              " '1509615': 948,\n",
              " 'gejjgkogjkogjgjeojie': 949,\n",
              " '36767197': 950,\n",
              " '262822': 951,\n",
              " 'd1e7': 952,\n",
              " '973753': 953,\n",
              " '49759': 954,\n",
              " '2837779': 955,\n",
              " '335064': 956,\n",
              " '00145004337155': 957,\n",
              " '026446366': 958,\n",
              " '676653': 959,\n",
              " '2293779601': 960,\n",
              " '1552664': 961,\n",
              " '535354': 962,\n",
              " '713553': 963,\n",
              " '1598007': 964,\n",
              " '71820980': 965,\n",
              " '107019': 966,\n",
              " 'vvvsvvvvvvvvsvvvv': 967,\n",
              " '4324009': 968,\n",
              " '22089': 969,\n",
              " '96137': 970,\n",
              " '00267540281308': 971,\n",
              " '148834': 972,\n",
              " '68762469': 973,\n",
              " '19952': 974,\n",
              " '24499375': 975,\n",
              " '21261040': 976,\n",
              " '28408500': 977,\n",
              " '397849': 978,\n",
              " '2300500': 979,\n",
              " '00434': 980,\n",
              " '59643': 981,\n",
              " '39274399': 982,\n",
              " '14296997': 983,\n",
              " '3888171255': 984,\n",
              " '839013': 985,\n",
              " '3827615': 986,\n",
              " '9906408': 987,\n",
              " '5121543': 988,\n",
              " '71111544': 989,\n",
              " '121313312': 990,\n",
              " '54541278': 991,\n",
              " '35316': 992,\n",
              " '25129584': 993,\n",
              " '38487': 994,\n",
              " '6347111': 995,\n",
              " '39146472': 996,\n",
              " '793298880': 997,\n",
              " '86895047': 998,\n",
              " '2020740': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "tcep7jbFtFw_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "e8a3e6c2-8c59-40d1-8f30-0109cda9e632"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-a21107e88f05>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mqtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0matp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-a21107e88f05>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mqtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0matp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, questions, answers):\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.questions[idx], self.answers[idx]\n",
        "\n",
        "\n",
        "max_length1 = max(len(tensor) for tensor in qt)\n",
        "max_length2 = max(len(tensor) for tensor in at)\n",
        "max_length=max(max_length1,max_length2)\n",
        "\n",
        "qtp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in qt], batch_first=True)\n",
        "atp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in at], batch_first=True)\n",
        "\n",
        "\n",
        "max_length1 = max(len(tensor) for tensor in qtest)\n",
        "max_length2 = max(len(tensor) for tensor in atest)\n",
        "max_length=max(max_length1,max_length2)\n",
        "qtestp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in qtest], batch_first=True)\n",
        "atestp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in atest], batch_first=True)\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = Dataset(qtp,atp)\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "test_dataset = Dataset(qtestp,atestp)\n",
        "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSUfm1fqiGVp"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnvuAfhEqLBN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389,
          "referenced_widgets": [
            "c11fd78c24514ca39ac242f47dfc7d69",
            "bbcd85c193d04224876003ca6c85639c",
            "df8ef60e25f34607aac78317bf8b77f6",
            "17cb0b3c10854fe59e2b53ac23a64f94",
            "cdd87565fda248fbadf1542a07bf1fc9",
            "47082d3d34ed490981529ab79db12cd7",
            "38a5ad82f64e468c97716b0b2a848bf5",
            "dc9c31a4b59e4b4597e435caa9683c29",
            "1d7d6b636eab4692abd933e0642362ce",
            "ef10edde4c6349fd98cff82b0c61128a",
            "30c0cbad4b2c4024b5d79b96337e1193"
          ]
        },
        "outputId": "ce5ac35c-1497-4848-d079-f09fc320f672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 743 K \n",
            "1 | tgt_embedding       | Embedding | 743 K \n",
            "2 | transformer_encoder | Encoder   | 2.3 K \n",
            "3 | transformer_decoder | Decoder   | 2.9 K \n",
            "4 | fc                  | Linear    | 929 K \n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.683     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c11fd78c24514ca39ac242f47dfc7d69"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pytorch_lightning as pl\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads,dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v):\n",
        "        q = self.split_heads(self.W_q(q))  #64,2,22,2\n",
        "        k = self.split_heads(self.W_k(k))  #64,2,2,22\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "\n",
        "\n",
        "        att = self.att_score(q, k, v)  #62,2,22,22\n",
        "        out = self.W_o(self.combine_heads(att))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.emb_dim)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "      for i in range(tensor.size(0)):\n",
        "        for j in range(tensor.size(1)):\n",
        "          matrix = tensor[i, j]\n",
        "\n",
        "          mask = torch.triu(torch.ones(matrix.size(0), matrix.size(1)), diagonal=0,).t().to('cuda:0')\n",
        "\n",
        "          matrix = matrix * mask+ (-1e9) * (1 - mask)\n",
        "          tensor[i, j] = matrix\n",
        "          return tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class EncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x)\n",
        "\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output, encoder_output)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(x)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class Decoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Transformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=4, num_heads=2, num_layers=6, d_ff=256, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        self.transformer_encoder = Encoder(self.d_model,self.num_heads\n",
        "\n",
        "        )\n",
        "        self.transformer_decoder =Decoder(self.d_model,self.num_heads\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        pred = self.predict(batch_q,ans_len)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print_correct(self.dictionary, batch, pred)\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self,x,ans_len):\n",
        "      encode=self.transformer_encoder\n",
        "      batch_dim=x.shape[0]\n",
        "      max_seq_len=x.shape[1]\n",
        "      out=torch.zeros((batch_dim,max_seq_len+1))\n",
        "      out[:,0]=2\n",
        "      for i in range(ans_len):\n",
        "        enc= encode(x)\n",
        "        out=self.transformer_decoder(out,enc)\n",
        "      return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc=[]\n",
        "losses=[]\n",
        "voc_len=len(v)\n",
        "t=Transformer(voc_len,voc_len)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=3)  # Modifica il numero di epoche come desiderato\n",
        "trainer.fit(t, train_loader)\n",
        "\n",
        "\n",
        "#model_path='/content/drive/MyDrive/mathematics_dataset-v1.0/model'\n",
        "\n",
        "\n",
        "#torch.save(t.state_dict(), model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(acc)/len(acc)"
      ],
      "metadata": {
        "id": "faI6lBC0-vk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f4bb30-2312-4480-b2cd-5f12687d1a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8277239469787339"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpG2sQjR5SlI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "3a17aa0d9c294e1caae3ae7dafc1e463",
            "5efab40f314942869d983f48a29c53da",
            "cf7ae3fc37854f289fd9e19f09dbde31",
            "d0e97656f33d47a0b48046bdf3c32034",
            "f53ee952819641759b58c7c49da5d42b",
            "8ac8a9c2d895401b81c340291ac44439",
            "b9bc96485d954277be67552ce92920e5",
            "bab3376110354b7dbe0245b843d95cc5",
            "1276c5e9cfc74befa85b0d3298b63a54",
            "981747b63192448a94c5698ce6fe08e2",
            "7928d4fbbef5420d969399ccdbe83ea4"
          ]
        },
        "outputId": "c5f20213-ae7f-4b0a-accd-22d23a31e356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:490: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a17aa0d9c294e1caae3ae7dafc1e463"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model_path='/content/drive/MyDrive/modellino.pth'\n",
        "#torch.save(t.state_dict(), model_path)\n",
        "trainer.test(t,test_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(t,test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366,
          "referenced_widgets": [
            "6cd7f0d6eccf445287c4da59ab24b61f",
            "56840015c3b6454482e443fbd18171c7",
            "00d232fd98724632afdfefa05ae73457",
            "d1d572ac2d4345aca97e1a7e65999579",
            "4bd469a568054dc68bb9ae446c816cc9",
            "cb12a52aa92042bc83cc99e7451eba61",
            "758d7a1bde5e41fcbf3cda4123caf7ce",
            "8cdf398e3fd248e6a5feb6ac3d32fa7f",
            "beb52e6e7e724b9696f5bfb78dc3b591",
            "910c329b9c3040c9b93b226f36ddabf4",
            "27076776389f47c796fde47ba205936b"
          ]
        },
        "id": "_4Heqj0VVXF6",
        "outputId": "92e5139f-0dce-40e5-d37d-cf5a0232d964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cd7f0d6eccf445287c4da59ab24b61f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f1fed77ba32b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0m_verify_strategy_supports_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         return call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provided\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_provided\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         )\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m         \u001b[0;31m# remove the tensors from the test results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_tensors_to_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mprevious_dataloader_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;31m# run step hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_step\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-9e28698570d2>\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0;31m# Computing prediction and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_q\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mans_len\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape (batch_size, answer_max_length, dict_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaper_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_a\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# accuracy for the current batch as defined in the \"mathematics dataset\" paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-9e28698570d2>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, ans_len)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0menc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-9e28698570d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-9e28698570d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultihead_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0madd_nor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-9e28698570d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#64,2,22,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#64,2,2,22\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(acc)/len(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3shG2RuoVpO_",
        "outputId": "3d8bca1f-262f-4d1b-a944-149a5608ab64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9502231500143967"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g77qbpYn07y4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "5a7a489d-1e15-4966-e6ea-b14da811bf91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(t.state_dict(), 'trainato')"
      ],
      "metadata": {
        "id": "JDHGggG4y-A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.load_state_dict(torch.load('/content/drive/MyDrive/modellino.pth'))"
      ],
      "metadata": {
        "id": "MXQI9fjOmLLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a36909-ca79-4be9-f7d1-ce541294cbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RaXOrj_8KHy"
      },
      "source": [
        "# TP-Transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TPMultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads,dropout=0.1):\n",
        "        super(TPMultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_r = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v,r):\n",
        "        q = self.split_heads(self.W_q(q))  #64,2,22,2\n",
        "        k = self.split_heads(self.W_k(k))  #64,2,2,22\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "        r = self.split_heads(self.W_r(r))\n",
        "\n",
        "\n",
        "        att = self.att_score(q, k, v)  #62,2,22,22\n",
        "        #filler = torch.tensordot(att, r, dims=0)\n",
        "        #diagonal = torch.diagonal(filler)\n",
        "        #print(att.shape,filler.shape,diagonal.shape)\n",
        "\n",
        "\n",
        "        out = self.W_o(self.combine_heads(att*r))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.emb_dim)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "      for i in range(tensor.size(0)):\n",
        "        for j in range(tensor.size(1)):\n",
        "          matrix = tensor[i, j]\n",
        "\n",
        "          mask = torch.triu(torch.ones(matrix.size(0), matrix.size(1)), diagonal=0,).t().to('cuda:0')\n",
        "\n",
        "          matrix = matrix * mask+ (-1e9) * (1 - mask)\n",
        "          tensor[i, j] = matrix\n",
        "          return tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x,x)\n",
        "\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPEncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TPDecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x,x)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output,encoder_output, encoder_output)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(x)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class TPDecoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPDecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class TPTransformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=4, num_heads=2, num_layers=6, d_ff=256, dropout=0.1):\n",
        "        super(TPTransformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        self.transformer_encoder = TPEncoder(self.d_model,self.num_heads\n",
        "\n",
        "        )\n",
        "        self.transformer_decoder =TPDecoder(self.d_model,self.num_heads\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        pred = self(batch)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print_correct(self.dictionary, batch, pred)\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "acc=[]\n",
        "losses=[]\n",
        "voc_len=len(v)\n",
        "t=Transformer(voc_len,voc_len)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=3)  # Modifica il numero di epoche come desiderato\n",
        "trainer.fit(t, train_loader)\n",
        "\n",
        "\n",
        "#model_path='/content/drive/MyDrive/mathematics_dataset-v1.0/model'\n",
        "\n",
        "\n",
        "#torch.save(t.state_dict(), model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389,
          "referenced_widgets": [
            "360939eacdd34c2e90e91bf4cedae8cd",
            "40b9edab3b79465480960ef3064d4cab",
            "0771d54a121e434392366c38bf8bc67c",
            "480b994297d940daa6e62c902c01038d",
            "bc06e121934e47b39fda4fb3d3ff0530",
            "c4b9958c84d9431b8d656f444e6ab152",
            "91e4aa8cf3164ddcb1c69df9e80f037d",
            "1c12b7fcb20e46e794e29ca7931b927d",
            "e548f579aa1b48d298312f0a1ce5f0cb",
            "c3b10e59d7394e9eabaf13eaeca6a62f",
            "77ea0162892845d5b0a757672a7cd9ec"
          ]
        },
        "id": "24TtpczCL-Zk",
        "outputId": "4068be03-3485-421e-961d-448c099b29a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 284   \n",
            "1 | tgt_embedding       | Embedding | 284   \n",
            "2 | transformer_encoder | Encoder   | 2.4 K \n",
            "3 | transformer_decoder | Decoder   | 3.1 K \n",
            "4 | fc                  | Linear    | 355   \n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "6.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "6.5 K     Total params\n",
            "0.026     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "360939eacdd34c2e90e91bf4cedae8cd"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a17aa0d9c294e1caae3ae7dafc1e463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5efab40f314942869d983f48a29c53da",
              "IPY_MODEL_cf7ae3fc37854f289fd9e19f09dbde31",
              "IPY_MODEL_d0e97656f33d47a0b48046bdf3c32034"
            ],
            "layout": "IPY_MODEL_f53ee952819641759b58c7c49da5d42b"
          }
        },
        "5efab40f314942869d983f48a29c53da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ac8a9c2d895401b81c340291ac44439",
            "placeholder": "​",
            "style": "IPY_MODEL_b9bc96485d954277be67552ce92920e5",
            "value": "Testing DataLoader 0: 100%"
          }
        },
        "cf7ae3fc37854f289fd9e19f09dbde31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab3376110354b7dbe0245b843d95cc5",
            "max": 3473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1276c5e9cfc74befa85b0d3298b63a54",
            "value": 3473
          }
        },
        "d0e97656f33d47a0b48046bdf3c32034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_981747b63192448a94c5698ce6fe08e2",
            "placeholder": "​",
            "style": "IPY_MODEL_7928d4fbbef5420d969399ccdbe83ea4",
            "value": " 3473/3473 [01:01&lt;00:00, 56.78it/s]"
          }
        },
        "f53ee952819641759b58c7c49da5d42b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8ac8a9c2d895401b81c340291ac44439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9bc96485d954277be67552ce92920e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bab3376110354b7dbe0245b843d95cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1276c5e9cfc74befa85b0d3298b63a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "981747b63192448a94c5698ce6fe08e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7928d4fbbef5420d969399ccdbe83ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "360939eacdd34c2e90e91bf4cedae8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40b9edab3b79465480960ef3064d4cab",
              "IPY_MODEL_0771d54a121e434392366c38bf8bc67c",
              "IPY_MODEL_480b994297d940daa6e62c902c01038d"
            ],
            "layout": "IPY_MODEL_bc06e121934e47b39fda4fb3d3ff0530"
          }
        },
        "40b9edab3b79465480960ef3064d4cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b9958c84d9431b8d656f444e6ab152",
            "placeholder": "​",
            "style": "IPY_MODEL_91e4aa8cf3164ddcb1c69df9e80f037d",
            "value": "Epoch 0:   2%"
          }
        },
        "0771d54a121e434392366c38bf8bc67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c12b7fcb20e46e794e29ca7931b927d",
            "max": 6945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e548f579aa1b48d298312f0a1ce5f0cb",
            "value": 140
          }
        },
        "480b994297d940daa6e62c902c01038d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3b10e59d7394e9eabaf13eaeca6a62f",
            "placeholder": "​",
            "style": "IPY_MODEL_77ea0162892845d5b0a757672a7cd9ec",
            "value": " 140/6945 [00:08&lt;06:30, 17.42it/s, v_num=33]"
          }
        },
        "bc06e121934e47b39fda4fb3d3ff0530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c4b9958c84d9431b8d656f444e6ab152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e4aa8cf3164ddcb1c69df9e80f037d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c12b7fcb20e46e794e29ca7931b927d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e548f579aa1b48d298312f0a1ce5f0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3b10e59d7394e9eabaf13eaeca6a62f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ea0162892845d5b0a757672a7cd9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c11fd78c24514ca39ac242f47dfc7d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbcd85c193d04224876003ca6c85639c",
              "IPY_MODEL_df8ef60e25f34607aac78317bf8b77f6",
              "IPY_MODEL_17cb0b3c10854fe59e2b53ac23a64f94"
            ],
            "layout": "IPY_MODEL_cdd87565fda248fbadf1542a07bf1fc9"
          }
        },
        "bbcd85c193d04224876003ca6c85639c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47082d3d34ed490981529ab79db12cd7",
            "placeholder": "​",
            "style": "IPY_MODEL_38a5ad82f64e468c97716b0b2a848bf5",
            "value": "Epoch 0:   1%"
          }
        },
        "df8ef60e25f34607aac78317bf8b77f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc9c31a4b59e4b4597e435caa9683c29",
            "max": 1563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d7d6b636eab4692abd933e0642362ce",
            "value": 20
          }
        },
        "17cb0b3c10854fe59e2b53ac23a64f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef10edde4c6349fd98cff82b0c61128a",
            "placeholder": "​",
            "style": "IPY_MODEL_30c0cbad4b2c4024b5d79b96337e1193",
            "value": " 20/1563 [00:05&lt;07:39,  3.36it/s, v_num=2]"
          }
        },
        "cdd87565fda248fbadf1542a07bf1fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "47082d3d34ed490981529ab79db12cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a5ad82f64e468c97716b0b2a848bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc9c31a4b59e4b4597e435caa9683c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d7d6b636eab4692abd933e0642362ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef10edde4c6349fd98cff82b0c61128a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c0cbad4b2c4024b5d79b96337e1193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cd7f0d6eccf445287c4da59ab24b61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56840015c3b6454482e443fbd18171c7",
              "IPY_MODEL_00d232fd98724632afdfefa05ae73457",
              "IPY_MODEL_d1d572ac2d4345aca97e1a7e65999579"
            ],
            "layout": "IPY_MODEL_4bd469a568054dc68bb9ae446c816cc9"
          }
        },
        "56840015c3b6454482e443fbd18171c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb12a52aa92042bc83cc99e7451eba61",
            "placeholder": "​",
            "style": "IPY_MODEL_758d7a1bde5e41fcbf3cda4123caf7ce",
            "value": "Testing DataLoader 0:   0%"
          }
        },
        "00d232fd98724632afdfefa05ae73457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cdf398e3fd248e6a5feb6ac3d32fa7f",
            "max": 782,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beb52e6e7e724b9696f5bfb78dc3b591",
            "value": 0
          }
        },
        "d1d572ac2d4345aca97e1a7e65999579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_910c329b9c3040c9b93b226f36ddabf4",
            "placeholder": "​",
            "style": "IPY_MODEL_27076776389f47c796fde47ba205936b",
            "value": " 0/782 [00:00&lt;?, ?it/s]"
          }
        },
        "4bd469a568054dc68bb9ae446c816cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "cb12a52aa92042bc83cc99e7451eba61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758d7a1bde5e41fcbf3cda4123caf7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cdf398e3fd248e6a5feb6ac3d32fa7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb52e6e7e724b9696f5bfb78dc3b591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "910c329b9c3040c9b93b226f36ddabf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27076776389f47c796fde47ba205936b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
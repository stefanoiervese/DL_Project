{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhA0vWrGv07c"
      },
      "source": [
        "#Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UxDq5zBwwBHy"
      },
      "outputs": [],
      "source": [
        "pip install pytorch_lightning --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yqlBgIcwOvz",
        "outputId": "f373e8ae-f6bc-447d-b0c3-e47d216a5dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DL_Project'...\n",
            "remote: Enumerating objects: 114, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 114 (delta 24), reused 9 (delta 9), pack-reused 82\u001b[K\n",
            "Receiving objects: 100% (114/114), 55.79 MiB | 42.16 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "/content/DL_Project\n",
            "Archive:  Arithmetic_extrapolate.zip\n",
            "  inflating: arithmetic_extrapolate/Arithmetic_extrapolate/arithmetic__div_big.txt  \n",
            "  inflating: arithmetic_extrapolate/Arithmetic_extrapolate/arithmetic__mul_big.txt  \n",
            "  inflating: arithmetic_extrapolate/Arithmetic_extrapolate/arithmetic__add_sub_multiple_longer.txt  \n",
            "  inflating: arithmetic_extrapolate/Arithmetic_extrapolate/arithmetic__add_or_sub_big.txt  \n",
            "Archive:  Arithmetic_interpolate.zip\n",
            "  inflating: arithmetic_interpolate/Arithmetic_interpolate/arithmetic__add_sub_multiple.txt  \n",
            "  inflating: arithmetic_interpolate/Arithmetic_interpolate/arithmetic__add_or_sub.txt  \n",
            "  inflating: arithmetic_interpolate/Arithmetic_interpolate/arithmetic__div.txt  \n",
            "  inflating: arithmetic_interpolate/Arithmetic_interpolate/arithmetic__mul.txt  \n",
            "Archive:  Arithmetic.zip\n",
            "   creating: arithmetic_directory/Arithmetic/\n",
            "  inflating: arithmetic_directory/Arithmetic/arithmetic__add_or_sub.txt  \n",
            "  inflating: arithmetic_directory/Arithmetic/arithmetic__mul.txt  \n"
          ]
        }
      ],
      "source": [
        "!rm -r DL_Project\n",
        "!git clone https://github.com/stefanoiervese/DL_Project\n",
        "%cd DL_Project\n",
        "!unzip Arithmetic_extrapolate.zip -d arithmetic_extrapolate\n",
        "!unzip Arithmetic_interpolate.zip -d arithmetic_interpolate\n",
        "!unzip Arithmetic.zip -d arithmetic_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OL3QjmM-wXqS"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pack_sequence, pad_sequence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUYWE4La3O8V"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vja0OFLp3XVz"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, questions, answers):\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.questions[idx], self.answers[idx]\n",
        "\n",
        "class Tokenizer:\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.vocab = self.crea_vocabolario(sentences)\n",
        "        self.word_to_id = {word: idx for idx, word in enumerate(self.vocab)}\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        txt = re.sub(r'(\\d+)', lambda x: ' '.join(list(x.group(1))), text)\n",
        "        tokens = re.findall(r'\\b\\w+\\b|\\d+|[^\\w\\s]', txt)\n",
        "\n",
        "        token_id = []\n",
        "        unknown_tokens = []\n",
        "\n",
        "        new_tokens = []\n",
        "        for token in tokens:\n",
        "            flag = 0\n",
        "            if '.' in token and token != '.':\n",
        "                token = token.split('.')[0]\n",
        "                flag = 1\n",
        "            if token in self.word_to_id:\n",
        "                token_id.append(self.word_to_id[token])\n",
        "            else:\n",
        "                token_id.append(self.word_to_id['unknown'])\n",
        "                unknown_tokens.append(token)\n",
        "            if flag == 1:\n",
        "                token_id.append(self.word_to_id['.'])\n",
        "\n",
        "        if unknown_tokens:\n",
        "            print(\"Parole sconosciute:\", unknown_tokens)\n",
        "\n",
        "        return token_id\n",
        "\n",
        "    def crea_vocabolario(self, frasi):\n",
        "        vocabolario = set()\n",
        "\n",
        "        for frase in frasi:\n",
        "            txt = re.sub(r'(\\d+)', lambda x: ' '.join(list(x.group(1))), frase.lower())\n",
        "            parole = re.findall(r'\\b\\w+\\b|\\d+|[^\\w\\s]', txt)\n",
        "            vocabolario.update(parole)\n",
        "        return ['&', '#', '@', 'unknown'] + list(vocabolario)\n",
        "\n",
        "    def tokenize_q_and_a(self, questions, answers):\n",
        "        q = []\n",
        "        a = []\n",
        "        for x in questions:\n",
        "            q.append(torch.tensor(self.tokenize(x.lower())))\n",
        "        for x in answers:\n",
        "            a.append(torch.tensor(self.tokenize(x.lower())))\n",
        "        return q, a\n",
        "\n",
        "\n",
        "def build_dataset(data, q, a, tokenizer):\n",
        "    q, a = tokenizer.tokenize_q_and_a(q, a)\n",
        "    q, a = padding(q, a)\n",
        "    return q, a\n",
        "\n",
        "\n",
        "def load_dataset(path):\n",
        "    data = []\n",
        "    for file in os.listdir(path):\n",
        "        with open(path + file, \"r\") as file:\n",
        "            content = file.read()\n",
        "            data = data + [x for x in content.split('\\n')]\n",
        "    while '' in data:\n",
        "        data.remove('')\n",
        "    len_data = len(data)\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for i in range(len_data):\n",
        "        if(i % 2 == 0):\n",
        "            questions.append(data[i])\n",
        "        else:\n",
        "            dt = data[i] + \" @\"\n",
        "            answers.append(dt)\n",
        "    coppie = list(zip(questions, answers))\n",
        "    random.shuffle(coppie)\n",
        "    questions, answers = zip(*coppie)\n",
        "    return data, questions, answers\n",
        "\n",
        "\n",
        "def split_dataset(questions, answers):\n",
        "    l = int(len(questions) / 3)\n",
        "    train_q = questions[:2 * l]\n",
        "    test_q = questions[2 * l:]\n",
        "    train_a = answers[:2 * l]\n",
        "    test_a = answers[2 * l:]\n",
        "    return train_q, train_a, test_q, test_a\n",
        "\n",
        "\n",
        "def padding(questions, answers):\n",
        "    max_length1 = max(len(tensor) for tensor in questions)\n",
        "    max_length2 = max(len(tensor) for tensor in answers)\n",
        "    max_length = max(max_length1, max_length2)\n",
        "    q_padded = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor), dtype=torch.int)]) for tensor in questions], batch_first=True)\n",
        "    a_padded = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor), dtype=torch.int)]) for tensor in answers], batch_first=True)\n",
        "    return a_padded, q_padded\n",
        "\n",
        "def paper_accuracy(predicted_answers, correct_answers):\n",
        "  num_correct_answers = 0\n",
        "  end_of_line=2\n",
        "\n",
        "  for i in range(len(predicted_answers)):\n",
        "\n",
        "    single_predicted_answer = torch.argmax(predicted_answers[i], 1).tolist()  # vector of shape (answer_max_length) (concatenates the max value for each row)\n",
        "    index = single_predicted_answer.index(2) if 2 in single_predicted_answer else len(single_predicted_answer) -1\n",
        "    single_predicted_answer = single_predicted_answer[0:index]  # removing start and end of line char and additional characters\n",
        "    single_correct_answer = correct_answers[i].tolist()\n",
        "    single_correct_answer = single_correct_answer[0:single_correct_answer.index(2)]  # removing start of line, end of line and following characters\n",
        "\n",
        "    if (single_predicted_answer == single_correct_answer):\n",
        "      num_correct_answers += 1\n",
        "\n",
        "  return num_correct_answers/len(predicted_answers)\n",
        "\n",
        "\n",
        "def translate(phrase, vocab):\n",
        "    text = \"\"\n",
        "    for element in phrase:\n",
        "        text += vocab[element.item()]\n",
        "    return text\n",
        "\n",
        "def translate_from_output(phrase, vocab):\n",
        "    phrase = torch.argmax(F.softmax(phrase , dim = -1), dim = -1)\n",
        "    text = \"\"\n",
        "    for element in phrase:\n",
        "        text += vocab[element.item()]\n",
        "    return text\n",
        "\n",
        "def print_correct(dictionary, batch, res):\n",
        "\n",
        "  batch_q, batch_a =batch\n",
        "\n",
        "  for i in range(len(res)):\n",
        "\n",
        "    index_list = torch.argmax(res[i], 1) # reverse one_hot\n",
        "    predicted_string = answer_string = question_string = \"\"\n",
        "\n",
        "    for j in range(len(batch_q[i])):\n",
        "      question_string = question_string  + \" \" + dictionary[batch_q[i][j].item()]\n",
        "\n",
        "    for j in range(len(index_list)):\n",
        "      predicted_string = predicted_string + \" \" + dictionary[index_list[j].item()]\n",
        "\n",
        "    for j in range(len(batch_a[i])):\n",
        "      answer_string = answer_string + \" \" + dictionary[batch_a[i][j].item()]\n",
        "\n",
        "    print(dictionary)\n",
        "\n",
        "    print(\"QUESTION \" + question_string + \"\\n\", \"PREDICTED \" + predicted_string + \"\\n\",\"CORRECT \" + answer_string + \"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNDAFYDRiQNg"
      },
      "source": [
        "# Dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_HrQETDUMqc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dpME3bhqwAuZ"
      },
      "outputs": [],
      "source": [
        "path_train = './arithmetic_directory/Arithmetic/'\n",
        "path_ext = './arithmetic_extrapolate/Arithmetic_extrapolate/'\n",
        "path_inter = './arithmetic_interpolate/Arithmetic_interpolate/'\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "data, q, a = load_dataset(path_ext)\n",
        "tokenizer = Tokenizer(data)\n",
        "q_ext, a_ext = build_dataset(data, q, a, tokenizer)\n",
        "\n",
        "\n",
        "ext_dataset = Dataset(q_ext, a_ext)\n",
        "ext_loader = DataLoader(ext_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "data, q, a = load_dataset(path_train)\n",
        "q_train, a_train, q_test, a_test = split_dataset(q, a)\n",
        "q_train, a_train = build_dataset(data, q_train, a_train, tokenizer)\n",
        "#q_test, a_test = build_dataset(data, q_test, a_test)\n",
        "\n",
        "#ata, q, a = load_dataset(path_inter)\n",
        "#q_inter, a_inter = build_dataset(data, q, a)\n",
        "\n",
        "\n",
        "train_dataset = Dataset(q_train, a_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#test_dataset = Dataset(q_test, a_test)\n",
        "#test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#inter_dataset = Dataset(q_inter, a_inter)\n",
        "#inter_loader = DataLoader(inter_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pd-ggpk-Ilf",
        "outputId": "560b6f3b-e1db-40d2-89c2-c6d9caacb370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenizer.word_to_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "fpQJ02Hs6-AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import dropout\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "import random\n",
        "\n",
        "\n",
        "class LSTM(pl.LightningModule):\n",
        "  def __init__(self, dict_size, size, dictionary, teacher_forcing_ratio: float = 0.5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden_units = 2048\n",
        "    self.dict_size = dict_size\n",
        "    self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "    self.dictionary = dictionary\n",
        "    self.question_max_length=size\n",
        "    self.answer_max_length=size\n",
        "    # Initializing used layers\n",
        "    self.lstm = nn.LSTM(self.dict_size, self.hidden_units)\n",
        "    self.linear_layer = nn.Linear(self.hidden_units, dict_size, bias=False)  # used to return vectors of shape (dict_size)\n",
        "\n",
        "  def forward(self, batch):\n",
        "    batch_q, batch_a = batch\n",
        "\n",
        "    batch_size = len(batch_q)\n",
        "    batch_questions = batch_q  # shape (batch_size, question_max_length)\n",
        "    batch_questions = torch.transpose(batch_questions, 0, 1)  # shape (question_max_length, batch_size)\n",
        "    batch_questions = F.one_hot(batch_questions, self.dict_size)  # shape (question_max_length, batch_size, dict_size)\n",
        "    batch_questions = batch_questions.float().to(device)\n",
        "\n",
        "    if self.training:\n",
        "      batch_answers = batch_a  # shape (batch_size, answer_max_length)\n",
        "      batch_answers = torch.transpose(batch_answers, 0, 1)  # shape (answer_max_length, batch_size)\n",
        "      batch_answers = F.one_hot(batch_answers, self.dict_size)  # shape (answer_max_length, batch_size, dict_size)\n",
        "      batch_answers = batch_answers.float().to(device)\n",
        "\n",
        "    # Initializing hidden_state and cell_state used by the lstm cell.\n",
        "    hidden_state = torch.zeros(1, batch_size, self.hidden_units, requires_grad=True, dtype=torch.float).to(device)  # shape (D*num_layers, batch_size, H_out)\n",
        "    cell_state = torch.zeros(1, batch_size, self.hidden_units, requires_grad=True, dtype=torch.float).to(device)  # shape (D*num_layers, batch_size, H_cell)\n",
        "\n",
        "    # Initializing result tensor\n",
        "    result = torch.empty(self.answer_max_length, batch_size, self.dict_size).to(device)  # shape (answer_max_length, batch_size, dict_size)\n",
        "\n",
        "\n",
        "    # input shape (1, batch_size, dict_size)\n",
        "    # output shape (1, batch_size, hidden_size)\n",
        "    for i in range(self.question_max_length):\n",
        "      output, (hidden_state, cell_state) = self.lstm(batch_questions[i].unsqueeze(0), (hidden_state, cell_state))\n",
        "\n",
        "\n",
        "    for i in range(self.answer_max_length):\n",
        "\n",
        "      result_temp = self.linear_layer(output[0])  # shape (batch_size, dict_size)\n",
        "      result[i] = result_temp\n",
        "\n",
        "      if self.training:\n",
        "        teacher_force = random.random() < self.teacher_forcing_ratio  # true or false with prob 'teacher_forcing_ratio'\n",
        "\n",
        "        if teacher_force:  # use correct previous char\n",
        "          input = batch_answers[i].unsqueeze(0)  # shape (1, batch_size, dict_size)\n",
        "        else:  # use previous predicted char\n",
        "          input = F.one_hot(torch.argmax(result_temp, 1), self.dict_size).unsqueeze(0).float().to(device)  # shape (1, batch_size, dict_size)\n",
        "\n",
        "      else:\n",
        "        if i == 0:\n",
        "          input = F.one_hot(torch.tensor([1]), self.dict_size).repeat(batch_size, 1).unsqueeze(0).float().to(device)  # shape (1, batch_size, dict_size)\n",
        "        else:\n",
        "          input = F.one_hot(torch.argmax(result_temp, 1), self.dict_size).unsqueeze(0).float().to(device)  # shape (1, batch_size, dict_size)\n",
        "\n",
        "      output, (hidden_state, cell_state) = self.lstm(input, (hidden_state, cell_state))  # shape (1, batch_size, hidden_size)\n",
        "    return torch.transpose((result), 0, 1)  # shape (batch_size, answer_max_length, dict_size)\n",
        "\n",
        "  def training_step(self, batch, _):\n",
        "    batch_q, batch_a = batch\n",
        "    # Preparing inputs\n",
        "    batch_answers = batch_a  # shape (batch_size, answer_max_length)\n",
        "    batch_answers = batch_answers.flatten(0, 1)  # shape (batch_size * answer_max_length)\n",
        "\n",
        "    # Computing prediction and loss\n",
        "\n",
        "    pred = self(batch).flatten(0, 1)  # shape (batch_size * answer_max_length, dict_size)\n",
        "    loss = F.cross_entropy(pred, batch_answers, ignore_index=0)\n",
        "    losses.append(loss.detach().cpu().item())\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, _):\n",
        "    batch_q, batch_a = batch\n",
        "\n",
        "    # Computing prediction and accuracy\n",
        "    pred = self.predict(batch)  # shape (batch_size, answer_max_length, dict_size)\n",
        "    accuracy = paper_accuracy(pred, batch_a)\n",
        "\n",
        "    self.log(\"val_tot_accuracy\", accuracy)\n",
        "    return accuracy\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "\n",
        "    batch_q, batch_a = batch\n",
        "\n",
        "    # Computing prediction and accuracy\n",
        "    pred = self(batch)  # shape (batch_size, answer_max_length, dict_size)\n",
        "    accuracy = paper_accuracy(pred, batch_a)\n",
        "\n",
        "    print_correct(self.dictionary, batch, pred)\n",
        "\n",
        "    print(accuracy)\n",
        "    acc.append(accuracy)\n",
        "    return accuracy\n",
        "\n",
        "  def predict(self, questions):\n",
        "    return self(questions)\n",
        "\n",
        "  def print_predict(self, questions):\n",
        "    pred = self.predict(questions.copy())\n",
        "    return\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return torch.optim.Adam(self.parameters(), lr=6e-4, betas=(0.9, 0.995), eps=1e-9)"
      ],
      "metadata": {
        "id": "3kI4UAO97ClC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length1 = max(len(tensor) for tensor in qt)\n",
        "max_length2 = max(len(tensor) for tensor in at)\n",
        "max_length=max(max_length1,max_length2)\n",
        "\n",
        "max_length1 = max(len(tensor) for tensor in qtest)\n",
        "max_length2 = max(len(tensor) for tensor in atest)\n",
        "max_length_test=max(max_length1,max_length2)\n",
        "\n",
        "max_length=max([max_length, max_length_test])\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(max_length)\n",
        "acc=[]\n",
        "losses=[]\n",
        "net = LSTM(len(tokenizer.vocab),max_length, tokenizer.vocab)\n",
        "net.to(device)\n",
        "trainer= pl.Trainer(max_epochs=2)\n",
        "\n",
        "trainer.fit(net, train_loader)"
      ],
      "metadata": {
        "id": "xv-Bv_uv7Z2X",
        "outputId": "fd52cfff-ea02-4f20-aa6a-b11a58088499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-98c879d7237c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_length1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_length2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_length1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'qt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "a2WyUjd_azq9",
        "outputId": "15475189-3fbe-42d8-b46a-baa521a68e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d86f472a1a3d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'lstm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del losses"
      ],
      "metadata": {
        "id": "AcafpOo6YuGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path='./model_LSTM.pth'\n",
        "torch.save(net.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "1b2uIz_SFGIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path='./model_LSTM.pth'\n",
        "net.load_state_dict(torch.load(model_path))\n",
        "net.eval()\n",
        "\n",
        "acc = []\n",
        "\n",
        "trainer.test(net,test_loader)"
      ],
      "metadata": {
        "id": "Hc6WHB3g-NE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(acc)/len(acc)"
      ],
      "metadata": {
        "id": "Nd4V-Bra-Wqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d93f28b-19a7-41b3-8d46-4b630f1992fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.006392045454545455"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_losses = [tensor.item() for tensor in losses]"
      ],
      "metadata": {
        "id": "DqovYV3SXwxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lista_losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yd37_b44-XWg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "56d45be8-f8c2-4c67-c45c-4cf34cb7f31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSUfm1fqiGVp"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hnvuAfhEqLBN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479,
          "referenced_widgets": [
            "abaa3c76976c4e22ad238dc45c79b6fd",
            "4181b9ef0dc94b4a96aaea4a511a3aa1",
            "9e010f4f9a0d4efdb68c405baf4751af",
            "e3041a2166414f17a531e8edc88aec15",
            "3fa290ae473f47e196c186f0cdbe94a2",
            "49cf1dca04fe4e38b98eb090ecca2b7a",
            "faa2e65c5a1448448f5bbac1671eaa56",
            "fd9f0af7248f4cb4bcd92e3df3a033fe",
            "34e8f673eb804b57bbb04121c552e159",
            "98ba8100565e4df1a19576826ed45d3a",
            "9f3083a4e8a441479543ace85a811ee5"
          ]
        },
        "outputId": "56c900c8-1128-41f2-e1a9-e08d04f4e5f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:71: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 27.6 K\n",
            "1 | tgt_embedding       | Embedding | 27.6 K\n",
            "2 | transformer_encoder | Encoder   | 6.5 M \n",
            "3 | transformer_decoder | Decoder   | 12.8 M\n",
            "4 | fc                  | Linear    | 27.7 K\n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "19.4 M    Trainable params\n",
            "0         Non-trainable params\n",
            "19.4 M    Total params\n",
            "77.699    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abaa3c76976c4e22ad238dc45c79b6fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pytorch_lightning as pl\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads,dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v, mask=False):\n",
        "        q = self.split_heads(self.W_q(q))  #64,2,22,2\n",
        "        k = self.split_heads(self.W_k(k))  #64,2,2,22\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "\n",
        "\n",
        "        att = self.att_score(q, k, v, mask)  #62,2,22,22\n",
        "        out = self.W_o(self.combine_heads(att))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v, mask):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        if mask:\n",
        "          attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.emb_dim)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "        mask = torch.triu(torch.full((tensor.shape[2], tensor.shape[3]), float(\"-inf\"), device= device), diagonal=1)\n",
        "        tensor = tensor + mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "\n",
        "class EncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x)\n",
        "\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x, mask=True)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output, encoder_output)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(out2)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class Decoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "class Transformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=256, dropout=0.1, teacher_forcing_ratio = 0.9):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.tgt_vocab_size=tgt_vocab_size\n",
        "\n",
        "        self.transformer_encoder = Encoder(self.d_model,self.num_heads)\n",
        "        self.transformer_decoder = Decoder(self.d_model,self.num_heads)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        if self.training:\n",
        "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
        "            if teacher_force:\n",
        "                return self.classic_forward(batch)\n",
        "            else:\n",
        "                return self.predict(batch[0])\n",
        "        return self.predict(batch)\n",
        "\n",
        "    def classic_forward(self,batch):\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        tgt = torch.cat((torch.ones((batch_size,1), dtype=torch.int).to(device), tgt[:, :-1]), dim = 1)\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        pred = self(batch_q)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self, x):\n",
        "        length=x.shape[1]\n",
        "        src_embedded = self.src_embedding(x).to(device)+self.positional_encoding(length,self.d_model).to(device)\n",
        "        encode = self.transformer_encoder(src_embedded)\n",
        "        batch_dim = x.shape[0]\n",
        "        out = torch.zeros((batch_dim, length), dtype = torch.int).to(device)\n",
        "        out[:,0] = 1\n",
        "        output=torch.zeros(batch_dim,length,self.tgt_vocab_size).to(device)\n",
        "        for i in range(length - 2 ):\n",
        "            tgt_embedded = self.tgt_embedding(out)+self.positional_encoding(length,self.d_model).to(device)\n",
        "            decode = self.transformer_decoder(tgt_embedded, encode)\n",
        "            output[:,i]+=self.fc(decode)[:,i]\n",
        "            prob = F.softmax(output , dim = -1)\n",
        "            arg_max = torch.argmax(prob, dim = -1)\n",
        "            out[:, i+1] = arg_max[:,i]\n",
        "        return self.classic_forward((x,out))\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "acc=[]\n",
        "losses=[]\n",
        "voc_len=len(tokenizer.vocab)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "t=Transformer(voc_len,voc_len)\n",
        "t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=1)  # Modifica il numero di epoche come desiderato\n",
        "trainer.fit(t, train_loader)\n",
        "\n",
        "\n",
        "#model_path='/content/drive/MyDrive/mathematics_dataset-v1.0/model'\n",
        "\n",
        "\n",
        "#torch.save(t.state_dict(), model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faI6lBC0-vk0"
      },
      "outputs": [],
      "source": [
        "sum(acc)/len(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EgEu3RicFiK"
      },
      "outputs": [],
      "source": [
        "print(t.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpG2sQjR5SlI"
      },
      "outputs": [],
      "source": [
        "model_path='./model.pth'\n",
        "torch.save(t.state_dict(), model_path)\n",
        "#trainer.test(t,test_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "_4Heqj0VVXF6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "4ccb0a23-0462-412a-8382-4aef75270e00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    784\u001b[0m         )\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m         \u001b[0;31m# remove the tensors from the test results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;31m# strategy will configure model and move it to the device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/single_device.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/accelerators/cuda.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_nvidia_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0m_clear_cuda_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/accelerators/cuda.py\u001b[0m in \u001b[0;36m_clear_cuda_memory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_clearCublasWorkspaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-68e063cd29a0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0m_verify_strategy_supports_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         return call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"failed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;31m# teardown might access the stage so we reset it after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\n\u001b[1;32m   1002\u001b[0m         Callback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\n\u001b[0;32m-> 1003\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m         \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;31m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mteardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \"\"\"\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0m_optimizers_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/optimizer.py\u001b[0m in \u001b[0;36m_optimizers_to_device\u001b[0;34m(optimizers, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m\"\"\"Moves optimizer states for a sequence of optimizers to the device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0m_optimizer_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/optimizer.py\u001b[0m in \u001b[0;36m_optimizer_to_device\u001b[0;34m(optimizer, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m\"\"\"Moves the state of a single optimizer to the device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove_data_to_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_frozen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             v = apply_to_collection(\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Breaking condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0melem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/apply_func.py\u001b[0m in \u001b[0;36mmove_data_to_device\u001b[0;34m(batch, device)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_TransferableDataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Breaking condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0melem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/apply_func.py\u001b[0m in \u001b[0;36mbatch_to\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_BLOCKING_DEVICE_TYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"non_blocking\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mdata_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "acc = []\n",
        "trainer.test(t,test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04kw6SPmZ0CK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDC_FIgFiibr"
      },
      "outputs": [],
      "source": [
        "tokenizer.vocab[0]\n",
        "type(tokenizer.vocab)\n",
        "print(tokenizer.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETyytmPMZhxx"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "q,a= train_dataset[i]\n",
        "length = q.shape[0]\n",
        "print(q.device)\n",
        "print(t.device)\n",
        "print(device)\n",
        "t.to(device)\n",
        "print(q.unsqueeze(0))\n",
        "pred = t.predict(q.unsqueeze(0).to(device))\n",
        "c = translate_from_output(pred.squeeze(0), tokenizer.vocab)\n",
        "d = translate(a.squeeze(0), tokenizer.vocab)\n",
        "print(pred)\n",
        "print(translate(q,tokenizer.vocab))\n",
        "print(translate(a,tokenizer.vocab))\n",
        "print(\"trad 1: \", translate_from_output(pred.squeeze(0),tokenizer.vocab))\n",
        "g = a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnhvpHqj6uHX"
      },
      "outputs": [],
      "source": [
        "loaded_list = []\n",
        "\n",
        "with open('losses.pickle', 'wb') as file:\n",
        "    pickle.dump(losses, file)\n",
        "\n",
        "# Caricamento della lista da un file\n",
        "with open('losses.pickle', 'rb') as file:\n",
        "    loaded_list = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3shG2RuoVpO_"
      },
      "outputs": [],
      "source": [
        "sum(acc)/len(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g77qbpYn07y4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDHGggG4y-A4"
      },
      "outputs": [],
      "source": [
        "torch.save(t.state_dict(), 'trainato')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MXQI9fjOmLLt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "764312c6-304b-4e6d-948b-9295d9432f00"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-42723202b777>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2042\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Transformer:\n\tsize mismatch for src_embedding.weight: copying a param with shape torch.Size([46, 512]) from checkpoint, the shape in current model is torch.Size([54, 512]).\n\tsize mismatch for tgt_embedding.weight: copying a param with shape torch.Size([46, 512]) from checkpoint, the shape in current model is torch.Size([54, 512]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([46, 512]) from checkpoint, the shape in current model is torch.Size([54, 512]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([46]) from checkpoint, the shape in current model is torch.Size([54])."
          ]
        }
      ],
      "source": [
        "t.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"../\"))\n",
        "TPpath = \"../drive/MyDrive/models/TPTransformer_3epoc_95acc.pt\"\n",
        "path = \"../drive/MyDrive/models/transformer-3epoc-512d-acc91.pt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAB5JQTyWa3T",
        "outputId": "cdcbd524-bd50-49a1-f845-7ff8e1a63988"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'DL_Project', 'drive', \"Nico's cards.txt\", 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kk4_eU2NYaeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTlaKzonXuYc",
        "outputId": "82fef748-b870-4254-b69b-ebddfb74c914"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RaXOrj_8KHy"
      },
      "source": [
        "# TP-Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "63c9a373c5e542d68469acc72a182c53",
            "515a7bc4b7fd4ee296f5922c96460163",
            "baa037a83f8546f1a37f89001c979fdf",
            "e3dcb691799a4300b59bc3332d04d7e7",
            "47642df786d54e4880955c94638343d5",
            "bc6c00fdcf9942eab194e7bf6544c35c",
            "6815e7c4397345f09b3b192a5d902959",
            "fb9890e39eeb4ef2aae35441117119f0",
            "33f971e432c04928a950659e33c53fab",
            "42314ce79cda4488b3d342dd14c49916",
            "e420c84a759a47f1974591c636c1d820"
          ]
        },
        "id": "24TtpczCL-Zk",
        "outputId": "855d7f0d-2fc7-4d0b-dd67-18c51d721f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 23.6 K\n",
            "1 | tgt_embedding       | Embedding | 23.6 K\n",
            "2 | transformer_encoder | TPEncoder | 8.1 M \n",
            "3 | transformer_decoder | TPDecoder | 16.0 M\n",
            "4 | fc                  | Linear    | 23.6 K\n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "24.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "24.2 M    Total params\n",
            "96.819    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63c9a373c5e542d68469acc72a182c53"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pytorch_lightning as pl\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TPAttentionHead(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, emb_head, dropout=0.0):\n",
        "        super(TPAttentionHead, self).__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.emb_head = emb_head\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_head)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_head)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_head)\n",
        "        self.W_r = nn.Linear(self.emb_dim, self.emb_head)\n",
        "        self.W_o = nn.Linear(self.emb_head, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q, k, v, r, mask = False):\n",
        "\n",
        "        q = self.W_q(q)\n",
        "        k = self.W_k(k)\n",
        "        v = self.W_v(v)\n",
        "        r = self.W_r(r)\n",
        "\n",
        "        att = self.att_score(q, k, v, mask = mask)  #62,2,22,22\n",
        "\n",
        "        return self.W_o(att*r)\n",
        "\n",
        "    def att_score(self, q, k, v, mask = False):\n",
        "\n",
        "        attn_scores = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.emb_head)\n",
        "        if mask: attn_scores=self.apply_mask(attn_scores)\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "\n",
        "        mask = torch.triu(torch.full((tensor.shape[1], tensor.shape[2]), float(\"-inf\"), device=device), diagonal=1)\n",
        "        tensor = tensor + mask\n",
        "        return tensor\n",
        "\n",
        "class TPMultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads,dropout=0.0):\n",
        "        super(TPMultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Layers Initialization\n",
        "        self.attention_heads = nn.ModuleList([TPAttentionHead(self.emb_dim, self.head_dim) for _ in range(self.num_heads)])\n",
        "\n",
        "    def forward(self, q, k, v, r, mask = False):  # input shape (batch_size, len_k/len_q/len_v, embedding_size)\n",
        "\n",
        "        attention_heads_results = []\n",
        "\n",
        "        for head in self.attention_heads:\n",
        "          attention_heads_results.append(head( q, k, v, r, mask = mask))  # shape (batch_size, len_q, dv)\n",
        "        concatenated_results = torch.stack(attention_heads_results)  # shape (batch_size, len_q, num_heads*dv)\n",
        "\n",
        "        return torch.sum(concatenated_results, dim=0)\n",
        "\n",
        "class TPEncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x,x)\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPEncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TPDecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x, x, mask=True)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output,encoder_output, out1)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(out2)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class TPDecoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPDecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class TPTransformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=256, dropout=0.1, teacher_forcing_ratio = 0.9):\n",
        "        super(TPTransformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.tgt_vocab_size=tgt_vocab_size\n",
        "\n",
        "        self.transformer_encoder = TPEncoder(self.d_model,self.num_heads)\n",
        "        self.transformer_decoder = TPDecoder(self.d_model, self.num_heads)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        if self.training:\n",
        "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
        "            if teacher_force:\n",
        "                return self.classic_forward(batch)\n",
        "            else:\n",
        "                return self.predict(batch[0])\n",
        "        return self.predict(batch)\n",
        "\n",
        "\n",
        "    def classic_forward(self,batch):\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        tgt = torch.cat((torch.ones((batch_size,1), dtype=torch.int).to(device), tgt[:, :-1]), dim = 1)\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        TP_losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        pred = self(batch_q)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        TP_acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self, x):\n",
        "        length=x.shape[1]\n",
        "        src_embedded = self.src_embedding(x).to(device)+self.positional_encoding(length,self.d_model).to(device)\n",
        "        encode = self.transformer_encoder(src_embedded)\n",
        "        batch_dim = x.shape[0]\n",
        "        out = torch.zeros((batch_dim, length), dtype = torch.int).to(device)\n",
        "        out[:,0] = 1\n",
        "        output=torch.zeros(batch_dim,length,self.tgt_vocab_size).to(device)\n",
        "        for i in range(length - 2 ):\n",
        "            tgt_embedded = self.tgt_embedding(out)+self.positional_encoding(length,self.d_model).to(device)\n",
        "            decode = self.transformer_decoder(tgt_embedded, encode)\n",
        "            output[:,i]+=self.fc(decode)[:,i]\n",
        "            prob = F.softmax(output , dim = -1)\n",
        "            arg_max = torch.argmax(prob, dim = -1)\n",
        "            out[:, i+1] = arg_max[:,i]\n",
        "        return self.classic_forward((x,out))\n",
        "\n",
        "\n",
        "TP_acc=[]\n",
        "TP_losses=[]\n",
        "TP_voc_len=len(tokenizer.vocab)\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "TP_t=TPTransformer(TP_voc_len,TP_voc_len, d_model = 512)\n",
        "TP_t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "train_dataset = Dataset(qtp,atp)\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "TP_trainer = pl.Trainer(max_epochs=5)  # Modifica il numero di epoche come desiderato\n",
        "TP_trainer.fit(TP_t, train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBVvNsaZ6uHZ",
        "outputId": "24f2132b-1dd1-4270-bea2-5af94946ff97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory c:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\lightning_logs\\version_20\\checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 25.6 K\n",
            "1 | tgt_embedding       | Embedding | 25.6 K\n",
            "2 | transformer_encoder | TPEncoder | 8.1 M \n",
            "3 | transformer_decoder | TPDecoder | 16.0 M\n",
            "4 | fc                  | Linear    | 25.7 K\n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "24.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "24.1 M    Total params\n",
            "96.585    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:   1%|          | 248/20834 [00:29<40:09,  8.55it/s, v_num=20]\n",
            "Epoch 1:   1%|          | 195/20834 [00:10<18:39, 18.43it/s, v_num=20]"
          ]
        }
      ],
      "source": [
        "TP_trainer.fit(TP_t, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJVZ9A3a6uHZ"
      },
      "outputs": [],
      "source": [
        "torch.save(TP_t.state_dict(), 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ5xwlNF6uHZ",
        "outputId": "c40deac2-51d1-4198-c921-c28d03b2897d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cuda:0\n",
            "tensor([[[ -5.1869,  -5.7117,  -1.8526,  ...,  -1.0888,  -5.6759,  -5.7917],\n",
            "         [-12.2110, -12.5634,  -0.1012,  ...,  -0.7097, -12.7704, -12.3758],\n",
            "         [ -9.6622,  -9.6081,  -0.9746,  ...,  -0.5189,  -9.2818,  -9.5596],\n",
            "         ...,\n",
            "         [-12.3243, -11.9757,   9.2954,  ...,   0.7629, -12.4674, -12.8726],\n",
            "         [-12.2221, -11.8104,   9.2566,  ...,   0.6543, -12.3288, -12.7793],\n",
            "         [-12.1844, -11.7887,   9.2140,  ...,   0.6303, -12.3175, -12.7766]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "add-57and-0.31.&&&&&&&&&&&\n",
            "-57.31@&&&&&&&&&&&&&&&\n",
            "trad 1:  -57.31@@@@@@@@@@@@@@@@\n"
          ]
        }
      ],
      "source": [
        "i = 30000\n",
        "q,a= train_dataset[i]\n",
        "length = q.shape[0]\n",
        "print(q.device)\n",
        "print(TP_t.device)\n",
        "\n",
        "TP_t.to(device)\n",
        "\n",
        "pred = TP_t.predict(q.unsqueeze(0).to(device))\n",
        "c = translate_from_output(pred.squeeze(0), tokenizer.vocab)\n",
        "d = translate(a.squeeze(0), tokenizer.vocab)\n",
        "print(pred)\n",
        "print(translate(q,tokenizer.vocab))\n",
        "print(translate(a,tokenizer.vocab))\n",
        "print(\"trad 1: \", translate_from_output(pred.squeeze(0),tokenizer.vocab))\n",
        "g = a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "oEgVeGWtAdXm",
        "outputId": "5eec79ad-056b-467e-c4bc-732fafc333df"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(TP_losses)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "7d9a39813ecb41f697ffbfed9be5ca24",
            "0888cbc52e94409aa68dd5a3f7d464e7",
            "03fd8d6afed2456a957c2abe1405a393",
            "0a71224e0bfd4472a9a5c3d09f2dabd7",
            "4ef4f16fa5cd4915931d80df674bce44",
            "dfd45da3235745ab992fe3bc37cd9503",
            "c06eecbf5c54487f91e5b5c1af54a24e",
            "63128e7a84cc47548fdbb1e5753e804b",
            "7d249d8dcc954c3ca313542bf2b23dba",
            "1d51fec1aa8d4ab18971e126fac13830",
            "0372a03fa56d41e38394bd23ecaf4773"
          ]
        },
        "id": "BSvSVsf3BLjv",
        "outputId": "68c52ee5-b50b-4556-d3a2-1fc0f2f3044e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0:  13%|█▎        | 1338/10417 [03:28<23:37,  6.40it/s]\n",
            "Testing: 271it [00:40,  6.72it/s]"
          ]
        }
      ],
      "source": [
        "TP_trainer.test(TP_t,test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vppk5s6S6uHa"
      },
      "outputs": [],
      "source": [
        "loaded_list = []\n",
        "\n",
        "with open('TPlosses.pickle', 'wb') as file:\n",
        "    pickle.dump(TP_losses, file)\n",
        "\n",
        "# Caricamento della lista da un file\n",
        "with open('TPlosses.pickle', 'rb') as file:\n",
        "    loaded_list = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LFNGTGeEgLP",
        "outputId": "2a0075e7-89c9-4cff-8508-3138200353e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8369037445618397"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(TP_acc)/len(TP_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oXJQ40mm6uHa",
        "outputId": "a4fe39e9-2fe2-41b9-9274-6dd2a5585375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "5a08e763a83045f58b400458323b4989",
            "5fb376e2f71b4b46bdc7eb8006baa51c",
            "94ce0983700c43c5912d7073e9108bb8",
            "9a1655c31e274cf284beb87ca72be436",
            "0fcb3e9ae4ea45ac96f76bf540aa3ebf",
            "bf18b45851aa4c3d8c932b8b1b770fc5",
            "51e6770d0d5b4abda4821139ffa9c477",
            "0a72ed524e114d7e9dd44435c1f2a0d9",
            "a11069687b2745f88014cc9263658140",
            "6e2edf6bae2c44c685d9d3baca936876",
            "b80b2d5f093d437a85938545f1ab53af"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 5.9 K \n",
            "1 | tgt_embedding       | Embedding | 5.9 K \n",
            "2 | transformer_encoder | TPEncoder | 3.3 M \n",
            "3 | transformer_decoder | TPDecoder | 6.6 M \n",
            "4 | fc                  | Linear    | 5.9 K \n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "9.9 M     Trainable params\n",
            "0         Non-trainable params\n",
            "9.9 M     Total params\n",
            "39.735    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a08e763a83045f58b400458323b4989"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pytorch_lightning as pl\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TPMultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, dropout=0.1):\n",
        "        super(TPMultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim*num_heads)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim*num_heads)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim*num_heads)\n",
        "        self.W_r = nn.Linear(self.emb_dim, self.emb_dim*num_heads)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v,r, mask=False):\n",
        "        q = self.split_heads(self.W_q(q))\n",
        "        k = self.split_heads(self.W_k(k))\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "        r = self.split_heads(self.W_r(r))\n",
        "\n",
        "        att = self.att_score(q, k, v, mask)\n",
        "        out = self.W_o(self.combine_heads(att*r))\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v, mask):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        if mask: attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.emb_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return torch.sum(x, dim = 1)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "        mask = torch.triu(torch.full((tensor.shape[2], tensor.shape[3]), float(\"-inf\"), device=device), diagonal=1)\n",
        "        tensor = tensor + mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "class TPEncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x,x)\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPEncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TPDecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x, x, mask=True)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output,encoder_output, out1)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(out2)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class TPDecoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPDecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class TPTransformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=256, dropout=0.1, teacher_forcing_ratio = 0.9):\n",
        "        super(TPTransformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.tgt_vocab_size=tgt_vocab_size\n",
        "\n",
        "        self.transformer_encoder = TPEncoder(self.d_model,self.num_heads)\n",
        "        self.transformer_decoder = TPDecoder(self.d_model, self.num_heads)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        if self.training:\n",
        "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
        "            if teacher_force:\n",
        "                return self.classic_forward(batch)\n",
        "            else:\n",
        "                return self.predict(batch[0])\n",
        "        return self.predict(batch)\n",
        "\n",
        "\n",
        "    def classic_forward(self,batch):\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        tgt = torch.cat((torch.ones((batch_size,1), dtype=torch.int).to(device), tgt[:, :-1]), dim = 1)\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        TP_losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        pred = self(batch_q)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        TP_acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self, x):\n",
        "        length=x.shape[1]\n",
        "        src_embedded = self.src_embedding(x).to(device)+self.positional_encoding(length,self.d_model).to(device)\n",
        "        encode = self.transformer_encoder(src_embedded)\n",
        "        batch_dim = x.shape[0]\n",
        "        out = torch.zeros((batch_dim, length), dtype = torch.int).to(device)\n",
        "        out[:,0] = 1\n",
        "        output=torch.zeros(batch_dim,length,self.tgt_vocab_size).to(device)\n",
        "        for i in range(length - 2 ):\n",
        "            tgt_embedded = self.tgt_embedding(out)+self.positional_encoding(length,self.d_model).to(device)\n",
        "            decode = self.transformer_decoder(tgt_embedded, encode)\n",
        "            output[:,i]+=self.fc(decode)[:,i]\n",
        "            prob = F.softmax(output , dim = -1)\n",
        "            arg_max = torch.argmax(prob, dim = -1)\n",
        "            out[:, i+1] = arg_max[:,i]\n",
        "        return self.classic_forward((x,out))\n",
        "\n",
        "\n",
        "TP_acc=[]\n",
        "TP_losses=[]\n",
        "TP_voc_len=len(tokenizer.vocab)\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "TP_t=TPTransformer(TP_voc_len,TP_voc_len, d_model = 128)\n",
        "TP_t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "train_dataset = Dataset(qtp,atp)\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "TP_trainer = pl.Trainer(max_epochs=5)  # Modifica il numero di epoche come desiderato\n",
        "TP_trainer.fit(TP_t, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcxeGWyg6uHc",
        "outputId": "04210117-ae43-4421-c118-274eccc11d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cpu\n",
            "miaosaaaa\n",
            "snarps\n",
            "snarps\n",
            "snarps\n",
            "snarps\n",
            "miaos\n",
            "torch.Size([1, 8, 22, 512])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "shape '[1, 22, 512]' is invalid for input of size 90112",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(TP_t\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m TP_t\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pred \u001b[39m=\u001b[39m TP_t\u001b[39m.\u001b[39;49mpredict(q\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m c \u001b[39m=\u001b[39m translate_from_output(pred\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m), tokenizer\u001b[39m.\u001b[39mvocab)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m d \u001b[39m=\u001b[39m translate(a\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m), tokenizer\u001b[39m.\u001b[39mvocab)\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=253'>254</a>\u001b[0m length\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=254'>255</a>\u001b[0m src_embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_embedding(x)\u001b[39m.\u001b[39mto(device)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoding(length,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=255'>256</a>\u001b[0m encode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(src_embedded)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=256'>257</a>\u001b[0m batch_dim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=257'>258</a>\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((batch_dim, length), dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mint)\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m         x \u001b[39m=\u001b[39m layer(x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m     att \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultihead_attention(x,x,x,x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     add_nor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(att))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     ff_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeedforward(add_nor)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmiaos\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m att \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matt_score(q, k, v, mask)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_o(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_heads(att\u001b[39m*\u001b[39;49mr))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m batch_size, _, seq_length, head_dim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mcontiguous()\u001b[39m.\u001b[39;49mview(batch_size, seq_length, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49memb_dim)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 22, 512]' is invalid for input of size 90112"
          ]
        }
      ],
      "source": [
        "i = 30000\n",
        "q,a= train_dataset[i]\n",
        "length = q.shape[0]\n",
        "print(q.device)\n",
        "print(TP_t.device)\n",
        "\n",
        "TP_t.to(device)\n",
        "\n",
        "pred = TP_t.predict(q.unsqueeze(0).to(device))\n",
        "c = translate_from_output(pred.squeeze(0), tokenizer.vocab)\n",
        "d = translate(a.squeeze(0), tokenizer.vocab)\n",
        "print(pred)\n",
        "print(translate(q,tokenizer.vocab))\n",
        "print(translate(a,tokenizer.vocab))\n",
        "print(\"trad 1: \", translate_from_output(pred.squeeze(0),tokenizer.vocab))\n",
        "g = a"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0372a03fa56d41e38394bd23ecaf4773": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03fd8d6afed2456a957c2abe1405a393": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63128e7a84cc47548fdbb1e5753e804b",
            "max": 10417,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d249d8dcc954c3ca313542bf2b23dba",
            "value": 20
          }
        },
        "0888cbc52e94409aa68dd5a3f7d464e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfd45da3235745ab992fe3bc37cd9503",
            "placeholder": "​",
            "style": "IPY_MODEL_c06eecbf5c54487f91e5b5c1af54a24e",
            "value": "Testing DataLoader 0:   0%"
          }
        },
        "0a71224e0bfd4472a9a5c3d09f2dabd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d51fec1aa8d4ab18971e126fac13830",
            "placeholder": "​",
            "style": "IPY_MODEL_0372a03fa56d41e38394bd23ecaf4773",
            "value": " 20/10417 [00:22&lt;3:11:03,  1.10s/it]"
          }
        },
        "1d51fec1aa8d4ab18971e126fac13830": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef4f16fa5cd4915931d80df674bce44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "63128e7a84cc47548fdbb1e5753e804b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d249d8dcc954c3ca313542bf2b23dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d9a39813ecb41f697ffbfed9be5ca24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0888cbc52e94409aa68dd5a3f7d464e7",
              "IPY_MODEL_03fd8d6afed2456a957c2abe1405a393",
              "IPY_MODEL_0a71224e0bfd4472a9a5c3d09f2dabd7"
            ],
            "layout": "IPY_MODEL_4ef4f16fa5cd4915931d80df674bce44"
          }
        },
        "c06eecbf5c54487f91e5b5c1af54a24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfd45da3235745ab992fe3bc37cd9503": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abaa3c76976c4e22ad238dc45c79b6fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4181b9ef0dc94b4a96aaea4a511a3aa1",
              "IPY_MODEL_9e010f4f9a0d4efdb68c405baf4751af",
              "IPY_MODEL_e3041a2166414f17a531e8edc88aec15"
            ],
            "layout": "IPY_MODEL_3fa290ae473f47e196c186f0cdbe94a2"
          }
        },
        "4181b9ef0dc94b4a96aaea4a511a3aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49cf1dca04fe4e38b98eb090ecca2b7a",
            "placeholder": "​",
            "style": "IPY_MODEL_faa2e65c5a1448448f5bbac1671eaa56",
            "value": "Epoch 0:   1%"
          }
        },
        "9e010f4f9a0d4efdb68c405baf4751af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd9f0af7248f4cb4bcd92e3df3a033fe",
            "max": 13889,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34e8f673eb804b57bbb04121c552e159",
            "value": 100
          }
        },
        "e3041a2166414f17a531e8edc88aec15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98ba8100565e4df1a19576826ed45d3a",
            "placeholder": "​",
            "style": "IPY_MODEL_9f3083a4e8a441479543ace85a811ee5",
            "value": " 100/13889 [00:11&lt;25:26,  9.03it/s, v_num=1]"
          }
        },
        "3fa290ae473f47e196c186f0cdbe94a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "49cf1dca04fe4e38b98eb090ecca2b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa2e65c5a1448448f5bbac1671eaa56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd9f0af7248f4cb4bcd92e3df3a033fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e8f673eb804b57bbb04121c552e159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98ba8100565e4df1a19576826ed45d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3083a4e8a441479543ace85a811ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63c9a373c5e542d68469acc72a182c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_515a7bc4b7fd4ee296f5922c96460163",
              "IPY_MODEL_baa037a83f8546f1a37f89001c979fdf",
              "IPY_MODEL_e3dcb691799a4300b59bc3332d04d7e7"
            ],
            "layout": "IPY_MODEL_47642df786d54e4880955c94638343d5"
          }
        },
        "515a7bc4b7fd4ee296f5922c96460163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6c00fdcf9942eab194e7bf6544c35c",
            "placeholder": "​",
            "style": "IPY_MODEL_6815e7c4397345f09b3b192a5d902959",
            "value": "Epoch 0:   0%"
          }
        },
        "baa037a83f8546f1a37f89001c979fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb9890e39eeb4ef2aae35441117119f0",
            "max": 13889,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33f971e432c04928a950659e33c53fab",
            "value": 20
          }
        },
        "e3dcb691799a4300b59bc3332d04d7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42314ce79cda4488b3d342dd14c49916",
            "placeholder": "​",
            "style": "IPY_MODEL_e420c84a759a47f1974591c636c1d820",
            "value": " 20/13889 [00:10&lt;2:05:49,  1.84it/s, v_num=2]"
          }
        },
        "47642df786d54e4880955c94638343d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "bc6c00fdcf9942eab194e7bf6544c35c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6815e7c4397345f09b3b192a5d902959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb9890e39eeb4ef2aae35441117119f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33f971e432c04928a950659e33c53fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42314ce79cda4488b3d342dd14c49916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e420c84a759a47f1974591c636c1d820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a08e763a83045f58b400458323b4989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fb376e2f71b4b46bdc7eb8006baa51c",
              "IPY_MODEL_94ce0983700c43c5912d7073e9108bb8",
              "IPY_MODEL_9a1655c31e274cf284beb87ca72be436"
            ],
            "layout": "IPY_MODEL_0fcb3e9ae4ea45ac96f76bf540aa3ebf"
          }
        },
        "5fb376e2f71b4b46bdc7eb8006baa51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf18b45851aa4c3d8c932b8b1b770fc5",
            "placeholder": "​",
            "style": "IPY_MODEL_51e6770d0d5b4abda4821139ffa9c477",
            "value": "Epoch 0:   1%"
          }
        },
        "94ce0983700c43c5912d7073e9108bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a72ed524e114d7e9dd44435c1f2a0d9",
            "max": 13889,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a11069687b2745f88014cc9263658140",
            "value": 80
          }
        },
        "9a1655c31e274cf284beb87ca72be436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e2edf6bae2c44c685d9d3baca936876",
            "placeholder": "​",
            "style": "IPY_MODEL_b80b2d5f093d437a85938545f1ab53af",
            "value": " 80/13889 [00:07&lt;21:16, 10.81it/s, v_num=3]"
          }
        },
        "0fcb3e9ae4ea45ac96f76bf540aa3ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "bf18b45851aa4c3d8c932b8b1b770fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51e6770d0d5b4abda4821139ffa9c477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a72ed524e114d7e9dd44435c1f2a0d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a11069687b2745f88014cc9263658140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e2edf6bae2c44c685d9d3baca936876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b80b2d5f093d437a85938545f1ab53af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
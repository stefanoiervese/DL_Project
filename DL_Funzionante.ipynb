{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhA0vWrGv07c"
      },
      "source": [
        "#Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxDq5zBwwBHy",
        "outputId": "b5f5dd44-8a2b-4066-83b0-ea246cb7b709"
      },
      "outputs": [],
      "source": [
        "pip install pytorch_lightning --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yqlBgIcwOvz",
        "outputId": "5c3619a7-9363-4105-9fe5-150b383d39c4"
      },
      "outputs": [],
      "source": [
        "!rm -r DL_Project\n",
        "!git clone https://github.com/stefanoiervese/DL_Project\n",
        "%cd DL_Project\n",
        "!unzip Arithmetic.zip -d arithmetic_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OL3QjmM-wXqS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
            "  warnings.warn(\"No audio backend is available.\")\n"
          ]
        }
      ],
      "source": [
        "import pytorch_lightning as pl\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pack_sequence, pad_sequence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUYWE4La3O8V"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vja0OFLp3XVz"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self,sentences):\n",
        "        self.sentences=sentences\n",
        "        self.vocab = self.crea_vocabolario(sentences)\n",
        "        self.word_to_id = {word: idx for idx, word in enumerate(self.vocab)}\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        txt = re.sub(r'(\\d+)', lambda x: ' '.join(list(x.group(1))), text)\n",
        "        tokens = re.findall(r'\\b\\w+\\b|\\d+|[^\\w\\s]', txt)\n",
        "\n",
        "\n",
        "\n",
        "        token_id = []\n",
        "        unknown_tokens = []\n",
        "\n",
        "        new_tokens = []\n",
        "        for token in tokens:\n",
        "          flag=0\n",
        "          if '.' in token and token != '.':\n",
        "            token=token=token.split('.')[0]\n",
        "            flag=1\n",
        "          if token in self.word_to_id:\n",
        "            token_id.append(self.word_to_id[token])\n",
        "          else:\n",
        "                token_id.append(self.word_to_id['unknown'])\n",
        "                unknown_tokens.append(token)\n",
        "          if(flag==1):\n",
        "            token_id.append(self.word_to_id['.'])\n",
        "\n",
        "\n",
        "        if unknown_tokens:\n",
        "\n",
        "          print(\"Parole sconosciute:\", unknown_tokens)\n",
        "\n",
        "        return token_id\n",
        "\n",
        "    def crea_vocabolario(self, frasi):\n",
        "      vocabolario = set()\n",
        "\n",
        "      for frase in frasi:\n",
        "        txt = re.sub(r'(\\d+)', lambda x: ' '.join(list(x.group(1))), frase.lower())\n",
        "        parole = re.findall(r'\\b\\w+\\b|\\d+|[^\\w\\s]', txt)\n",
        "        vocabolario.update(parole)\n",
        "      return ['&','#','@','unknown']+list(vocabolario)\n",
        "\n",
        "def paper_accuracy(predicted_answers, correct_answers):\n",
        "  num_correct_answers = 0\n",
        "  end_of_line=2\n",
        "\n",
        "  for i in range(len(predicted_answers)):\n",
        "\n",
        "    single_predicted_answer = torch.argmax(predicted_answers[i], 1).tolist()  # vector of shape (answer_max_length) (concatenates the max value for each row)\n",
        "    index = single_predicted_answer.index(2) if 2 in single_predicted_answer else len(single_predicted_answer) -1\n",
        "    single_predicted_answer = single_predicted_answer[1:index]  # removing start and end of line char and additional characters\n",
        "    single_correct_answer = correct_answers[i].tolist()\n",
        "    single_correct_answer = single_correct_answer[0:single_correct_answer.index(2)]  # removing start of line, end of line and following characters\n",
        "\n",
        "    if (single_predicted_answer == single_correct_answer):\n",
        "      num_correct_answers += 1\n",
        "\n",
        "  return num_correct_answers/len(predicted_answers)\n",
        "\n",
        "\n",
        "def translate(phrase, vocab):\n",
        "    text = \"\"\n",
        "    for element in phrase:\n",
        "        text += vocab[element.item()]\n",
        "    return text\n",
        "def translate_from_output(phrase, vocab):\n",
        "    phrase = torch.argmax(F.softmax(phrase , dim = -1), dim = -1)\n",
        "    text = \"\"\n",
        "    for element in phrase:\n",
        "        text += vocab[element.item()]\n",
        "    return text\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNDAFYDRiQNg"
      },
      "source": [
        "# Dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dpME3bhqwAuZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['.git', 'Arithmetic', 'Arithmetic.zip', 'Arithmetic_extrapolate.zip', 'Arithmetic_interpolate.zip', 'arithmetic__add_or_sub.txt.zip', 'DL_Funzionante.ipynb', 'LSTM.ipynb', 'README.md', 'test2.py']\n"
          ]
        }
      ],
      "source": [
        "path='./Arithmetic/Arithmetic/'\n",
        "data_list=[]\n",
        "print(os.listdir(\"./\"))\n",
        "for file in os.listdir(path):\n",
        "\n",
        "  with open(path+file, \"r\") as file:\n",
        "    content = file.read()\n",
        "    data_list=data_list+[x for x in content.split('\\n')]\n",
        "\n",
        "while '' in data_list:\n",
        "    data_list.remove('')\n",
        "\n",
        "len_data=len(data_list)\n",
        "quest=[]\n",
        "ans=[]\n",
        "for i in range(len_data):\n",
        "  if(i%2==0):\n",
        "    quest.append(data_list[i])\n",
        "  else:\n",
        "    data= data_list[i] + \" @\"\n",
        "    ans.append(data)\n",
        "coppie = list(zip(quest,ans))\n",
        "random.shuffle(coppie)\n",
        "quest, ans=zip(*coppie)\n",
        "l=int(len(quest)/3)\n",
        "train_q=quest[:2*l]\n",
        "test_q=quest[2*l:]\n",
        "train_a=ans[:2*l]\n",
        "test_a=ans[2*l:]\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(data_list)\n",
        "\n",
        "qt=[]\n",
        "at=[]\n",
        "for x in train_q:\n",
        "  qt.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "for x in train_a:\n",
        "  at.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "\n",
        "qtest=[]\n",
        "atest=[]\n",
        "for x in test_q:\n",
        "  qtest.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "for x in test_a:\n",
        "  atest.append(torch.tensor(tokenizer.tokenize(x.lower())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pd-ggpk-Ilf",
        "outputId": "11c534f4-c79f-4f60-8bc0-ec528e447f54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'&': 0,\n",
              " '#': 1,\n",
              " '@': 2,\n",
              " 'unknown': 3,\n",
              " '\\x02': 4,\n",
              " '\\x00': 5,\n",
              " 'attr': 6,\n",
              " 'b4d3': 7,\n",
              " '3': 8,\n",
              " '\\x01': 9,\n",
              " '4f4f': 10,\n",
              " '\\x05': 11,\n",
              " '<': 12,\n",
              " '2': 13,\n",
              " '˜': 14,\n",
              " '4fa4baa': 15,\n",
              " 'mac': 16,\n",
              " 'quarantine': 17,\n",
              " 'ô': 18,\n",
              " '6': 19,\n",
              " '.': 20,\n",
              " '5': 21,\n",
              " '\\x16': 22,\n",
              " '7': 23,\n",
              " 'q': 24,\n",
              " 'apple': 25,\n",
              " '0': 26,\n",
              " '4c9': 27,\n",
              " '8': 28,\n",
              " '/': 29,\n",
              " '1': 30,\n",
              " '9': 31,\n",
              " '\\x07': 32,\n",
              " 'os': 33,\n",
              " 'safari': 34,\n",
              " 'com': 35,\n",
              " '8e0a8b': 36,\n",
              " '3c2': 37,\n",
              " '¢': 38,\n",
              " ';': 39,\n",
              " 'x': 40,\n",
              " '-': 41,\n",
              " '\\x15': 42,\n",
              " '5e2': 43}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.word_to_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tcep7jbFtFw_"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, questions, answers):\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.questions[idx], self.answers[idx]\n",
        "\n",
        "\n",
        "max_length1 = max(len(tensor) for tensor in qt)\n",
        "max_length2 = max(len(tensor) for tensor in at)\n",
        "max_length=max(max_length1,max_length2)\n",
        "\n",
        "qtp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in qt], batch_first=True)\n",
        "atp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in at], batch_first=True)\n",
        "\n",
        "\n",
        "max_length1 = max(len(tensor) for tensor in qtest)\n",
        "max_length2 = max(len(tensor) for tensor in atest)\n",
        "max_length=max(max_length1,max_length2)\n",
        "qtestp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in qtest], batch_first=True)\n",
        "atestp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in atest], batch_first=True)\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = Dataset(qtp,atp)\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "test_dataset = Dataset(qtestp,atestp)\n",
        "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSUfm1fqiGVp"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "hnvuAfhEqLBN",
        "outputId": "91264fa0-92f2-47ec-8685-5b5f620f2b12"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pytorch_lightning as pl\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads,dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v, mask=False):\n",
        "        q = self.split_heads(self.W_q(q))  #64,2,22,2\n",
        "        k = self.split_heads(self.W_k(k))  #64,2,2,22\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "\n",
        "\n",
        "        att = self.att_score(q, k, v, mask)  #62,2,22,22\n",
        "        out = self.W_o(self.combine_heads(att))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v, mask):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        if mask:\n",
        "          attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.emb_dim)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "        mask = torch.triu(torch.full((tensor.shape[2], tensor.shape[3]), float(\"-inf\"), device= device), diagonal=1)\n",
        "        tensor = tensor + mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "\n",
        "class EncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x)\n",
        "\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x, mask=True)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output, encoder_output)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(out2)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class Decoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "class Transformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=256, dropout=0.1, teacher_forcing_ratio = 0.9):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.tgt_vocab_size=tgt_vocab_size\n",
        "\n",
        "        self.transformer_encoder = Encoder(self.d_model,self.num_heads)\n",
        "        self.transformer_decoder = Decoder(self.d_model,self.num_heads)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        if self.training:\n",
        "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
        "            print(teacher_force)\n",
        "            if teacher_force:\n",
        "                return self.classic_forward(batch)\n",
        "            else:\n",
        "                return self.predict(batch[0])\n",
        "        return self.predict(batch)\n",
        "\n",
        "    def classic_forward(self,batch):\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        tgt = torch.cat((torch.ones((batch_size,1), dtype=torch.int).to(device), tgt[:, :-1]), dim = 1)\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        pred = self(batch_q)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self, x):\n",
        "        length=x.shape[1]\n",
        "        src_embedded = self.src_embedding(x).to(device)+self.positional_encoding(length,self.d_model).to(device)\n",
        "        encode = self.transformer_encoder(src_embedded)\n",
        "        batch_dim = x.shape[0]\n",
        "        out = torch.zeros((batch_dim, length), dtype = torch.int).to(device)\n",
        "        out[:,0] = 1\n",
        "        output=torch.zeros(batch_dim,length,self.tgt_vocab_size).to(device)\n",
        "        for i in range(length - 2 ):\n",
        "            tgt_embedded = self.tgt_embedding(out)+self.positional_encoding(length,self.d_model).to(device)\n",
        "            decode = self.transformer_decoder(tgt_embedded, encode)\n",
        "            output[:,i]+=self.fc(decode)[:,i]\n",
        "            prob = F.softmax(output , dim = -1)\n",
        "            arg_max = torch.argmax(prob, dim = -1)\n",
        "            out[:, i+1] = arg_max[:,i]\n",
        "        return self.classic_forward((x,out))\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "acc=[]\n",
        "losses=[]\n",
        "voc_len=len(tokenizer.vocab)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "t=Transformer(voc_len,voc_len)\n",
        "t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=1)  # Modifica il numero di epoche come desiderato\n",
        "trainer.fit(t, train_loader)\n",
        "\n",
        "\n",
        "#model_path='/content/drive/MyDrive/mathematics_dataset-v1.0/model'\n",
        "\n",
        "\n",
        "#torch.save(t.state_dict(), model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "faI6lBC0-vk0",
        "outputId": "a18977c8-2721-4d0c-bad9-cad396affacf"
      },
      "outputs": [],
      "source": [
        "sum(acc)/len(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EgEu3RicFiK"
      },
      "outputs": [],
      "source": [
        "print(t.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpG2sQjR5SlI"
      },
      "outputs": [],
      "source": [
        "model_path='./model.pth'\n",
        "torch.save(t.state_dict(), model_path)\n",
        "#trainer.test(t,test_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4Heqj0VVXF6"
      },
      "outputs": [],
      "source": [
        "trainer.test(t,test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04kw6SPmZ0CK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDC_FIgFiibr"
      },
      "outputs": [],
      "source": [
        "tokenizer.vocab[0]\n",
        "type(tokenizer.vocab)\n",
        "print(tokenizer.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETyytmPMZhxx"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "q,a= train_dataset[i]\n",
        "length = q.shape[0]\n",
        "print(q.device)\n",
        "print(t.device)\n",
        "print(device)\n",
        "t.to(device)\n",
        "print(q.unsqueeze(0))\n",
        "pred = t.predict(q.unsqueeze(0).to(device))\n",
        "c = translate_from_output(pred.squeeze(0), tokenizer.vocab)\n",
        "d = translate(a.squeeze(0), tokenizer.vocab)\n",
        "print(pred)\n",
        "print(translate(q,tokenizer.vocab))\n",
        "print(translate(a,tokenizer.vocab))\n",
        "print(\"trad 1: \", translate_from_output(pred.squeeze(0),tokenizer.vocab))\n",
        "g = a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_list = []\n",
        "\n",
        "with open('losses.pickle', 'wb') as file:\n",
        "    pickle.dump(losses, file)\n",
        "\n",
        "# Caricamento della lista da un file\n",
        "with open('losses.pickle', 'rb') as file:\n",
        "    loaded_list = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3shG2RuoVpO_"
      },
      "outputs": [],
      "source": [
        "sum(acc)/len(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g77qbpYn07y4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDHGggG4y-A4"
      },
      "outputs": [],
      "source": [
        "torch.save(t.state_dict(), 'trainato')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXQI9fjOmLLt"
      },
      "outputs": [],
      "source": [
        "t.load_state_dict(torch.load('/content/drive/MyDrive/modellino.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RaXOrj_8KHy"
      },
      "source": [
        "# TP-Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "2dc3183b4dc84d859294926b223fba82",
            "2f595131716f4b1eb3cf548d56335e13",
            "49f499f06f9a4780a38dfdddf620e554",
            "ce65c4628d1a4f119f682689895b841d",
            "e1eeeb388a654b7980e949a15af7fdd2",
            "fc633476ed604b9a880d7fae72c46381",
            "3e238527a8ff4bfcbf82f25c0113dca7",
            "45ac176968784ba399d25d5102042a26",
            "5cd69df7e9604fb0b75d52e43dca8182",
            "cab18985f07141e894356c396a60db5c",
            "77ac68976cde4f00854d598835ad3c2e"
          ]
        },
        "id": "24TtpczCL-Zk",
        "outputId": "42bcbb85-276c-4fe0-916b-c57e3afe461c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:71: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 25.6 K\n",
            "1 | tgt_embedding       | Embedding | 25.6 K\n",
            "2 | transformer_encoder | TPEncoder | 8.1 M \n",
            "3 | transformer_decoder | TPDecoder | 16.0 M\n",
            "4 | fc                  | Linear    | 25.7 K\n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "24.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "24.1 M    Total params\n",
            "96.585    Total estimated model params size (MB)\n",
            "c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Epoch 1:   3%|▎         | 596/20834 [42:37<24:07:22,  4.29s/it, v_num=19]\n",
            "Epoch 0:   0%|          | 101/20834 [1:02:40<214:24:34, 37.23s/it, v_num=17]\n",
            "Testing DataLoader 0:   0%|          | 0/10417 [1:01:55<?, ?it/s]\n",
            "Testing DataLoader 0:   3%|▎         | 307/10417 [41:06<22:33:46,  8.03s/it]\n",
            "Epoch 1:   1%|          | 248/20834 [00:12<17:45, 19.31it/s, v_num=20]  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pytorch_lightning as pl\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TPAttentionHead(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, emb_head, dropout=0.0):\n",
        "        super(TPAttentionHead, self).__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.emb_head = emb_head\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_head)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_head)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_head)\n",
        "        self.W_r = nn.Linear(self.emb_dim, self.emb_head)\n",
        "        self.W_o = nn.Linear(self.emb_head, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q, k, v, r, mask = False):\n",
        "\n",
        "        q = self.W_q(q)\n",
        "        k = self.W_k(k)\n",
        "        v = self.W_v(v)\n",
        "        r = self.W_r(r)\n",
        "\n",
        "        att = self.att_score(q, k, v, mask = mask)  #62,2,22,22\n",
        "\n",
        "        return self.W_o(att*r)\n",
        "\n",
        "    def att_score(self, q, k, v, mask = False):\n",
        "\n",
        "        attn_scores = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.emb_head)\n",
        "        if mask: attn_scores=self.apply_mask(attn_scores)\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "\n",
        "        mask = torch.triu(torch.full((tensor.shape[1], tensor.shape[2]), float(\"-inf\"), device=device), diagonal=1)\n",
        "        tensor = tensor + mask\n",
        "        return tensor\n",
        "\n",
        "class TPMultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads,dropout=0.0):\n",
        "        super(TPMultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Layers Initialization\n",
        "        self.attention_heads = nn.ModuleList([TPAttentionHead(self.emb_dim, self.head_dim) for _ in range(self.num_heads)])\n",
        "\n",
        "    def forward(self, q, k, v, r, mask = False):  # input shape (batch_size, len_k/len_q/len_v, embedding_size)\n",
        "\n",
        "        attention_heads_results = []\n",
        "\n",
        "        for head in self.attention_heads:\n",
        "          attention_heads_results.append(head( q, k, v, r, mask = mask))  # shape (batch_size, len_q, dv)\n",
        "        concatenated_results = torch.stack(attention_heads_results)  # shape (batch_size, len_q, num_heads*dv)\n",
        "\n",
        "        return torch.sum(concatenated_results, dim=0)\n",
        "\n",
        "class TPEncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x,x)\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPEncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TPDecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x, x, mask=True)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output,encoder_output, out1)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(out2)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class TPDecoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPDecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class TPTransformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=256, dropout=0.1, teacher_forcing_ratio = 0.9):\n",
        "        super(TPTransformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.tgt_vocab_size=tgt_vocab_size\n",
        "\n",
        "        self.transformer_encoder = TPEncoder(self.d_model,self.num_heads)\n",
        "        self.transformer_decoder = TPDecoder(self.d_model, self.num_heads)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        if self.training:\n",
        "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
        "            if teacher_force:\n",
        "                return self.classic_forward(batch)\n",
        "            else:\n",
        "                return self.predict(batch[0])\n",
        "        return self.predict(batch)\n",
        "\n",
        "\n",
        "    def classic_forward(self,batch):\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        tgt = torch.cat((torch.ones((batch_size,1), dtype=torch.int).to(device), tgt[:, :-1]), dim = 1)\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        TP_losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        pred = self(batch_q)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        TP_acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self, x):\n",
        "        length=x.shape[1]\n",
        "        src_embedded = self.src_embedding(x).to(device)+self.positional_encoding(length,self.d_model).to(device)\n",
        "        encode = self.transformer_encoder(src_embedded)\n",
        "        batch_dim = x.shape[0]\n",
        "        out = torch.zeros((batch_dim, length), dtype = torch.int).to(device)\n",
        "        out[:,0] = 1\n",
        "        output=torch.zeros(batch_dim,length,self.tgt_vocab_size).to(device)\n",
        "        for i in range(length - 2 ):\n",
        "            tgt_embedded = self.tgt_embedding(out)+self.positional_encoding(length,self.d_model).to(device)\n",
        "            decode = self.transformer_decoder(tgt_embedded, encode)\n",
        "            output[:,i]+=self.fc(decode)[:,i]\n",
        "            prob = F.softmax(output , dim = -1)\n",
        "            arg_max = torch.argmax(prob, dim = -1)\n",
        "            out[:, i+1] = arg_max[:,i]\n",
        "        return self.classic_forward((x,out))\n",
        "\n",
        "\n",
        "TP_acc=[]\n",
        "TP_losses=[]\n",
        "TP_voc_len=len(tokenizer.vocab)\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "TP_t=TPTransformer(TP_voc_len,TP_voc_len, d_model = 512)\n",
        "TP_t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "train_dataset = Dataset(qtp,atp)\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "TP_trainer = pl.Trainer(max_epochs=5)  # Modifica il numero di epoche come desiderato\n",
        "TP_trainer.fit(TP_t, train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory c:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\lightning_logs\\version_20\\checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 25.6 K\n",
            "1 | tgt_embedding       | Embedding | 25.6 K\n",
            "2 | transformer_encoder | TPEncoder | 8.1 M \n",
            "3 | transformer_decoder | TPDecoder | 16.0 M\n",
            "4 | fc                  | Linear    | 25.7 K\n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "24.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "24.1 M    Total params\n",
            "96.585    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:   1%|          | 248/20834 [00:29<40:09,  8.55it/s, v_num=20]\n",
            "Epoch 1:   1%|          | 195/20834 [00:10<18:39, 18.43it/s, v_num=20]"
          ]
        }
      ],
      "source": [
        "TP_trainer.fit(TP_t, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(TP_t.state_dict(), 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cuda:0\n",
            "tensor([[[ -5.1869,  -5.7117,  -1.8526,  ...,  -1.0888,  -5.6759,  -5.7917],\n",
            "         [-12.2110, -12.5634,  -0.1012,  ...,  -0.7097, -12.7704, -12.3758],\n",
            "         [ -9.6622,  -9.6081,  -0.9746,  ...,  -0.5189,  -9.2818,  -9.5596],\n",
            "         ...,\n",
            "         [-12.3243, -11.9757,   9.2954,  ...,   0.7629, -12.4674, -12.8726],\n",
            "         [-12.2221, -11.8104,   9.2566,  ...,   0.6543, -12.3288, -12.7793],\n",
            "         [-12.1844, -11.7887,   9.2140,  ...,   0.6303, -12.3175, -12.7766]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "add-57and-0.31.&&&&&&&&&&&\n",
            "-57.31@&&&&&&&&&&&&&&&\n",
            "trad 1:  -57.31@@@@@@@@@@@@@@@@\n"
          ]
        }
      ],
      "source": [
        "i = 30000\n",
        "q,a= train_dataset[i]\n",
        "length = q.shape[0]\n",
        "print(q.device)\n",
        "print(TP_t.device)\n",
        "\n",
        "TP_t.to(device)\n",
        "\n",
        "pred = TP_t.predict(q.unsqueeze(0).to(device))\n",
        "c = translate_from_output(pred.squeeze(0), tokenizer.vocab)\n",
        "d = translate(a.squeeze(0), tokenizer.vocab)\n",
        "print(pred)\n",
        "print(translate(q,tokenizer.vocab))\n",
        "print(translate(a,tokenizer.vocab))\n",
        "print(\"trad 1: \", translate_from_output(pred.squeeze(0),tokenizer.vocab))\n",
        "g = a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "oEgVeGWtAdXm",
        "outputId": "5eec79ad-056b-467e-c4bc-732fafc333df"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/A0lEQVR4nO3dd3xV9eH/8XcGCSsDZENYDpApIiKC1IECUqtWf7XUuupXq8W21k1V0KoFtXUjjqpUraKo4EBB9t6yR1gBwgghgeyd+/n9EXPJzbw3Ofee3JPX8/HI45F77rnnfJKT3PO+nxlijDECAACwQKjdBQAAAM5BsAAAAJYhWAAAAMsQLAAAgGUIFgAAwDIECwAAYBmCBQAAsAzBAgAAWCY80Cd0uVw6evSooqKiFBISEujTAwCAWjDGKDMzUx06dFBoaNX1EgEPFkePHlVcXFygTwsAACyQmJioTp06Vfl8wINFVFSUpJKCRUdHB/r0AACgFjIyMhQXF+e+j1cl4MGitPkjOjqaYAEAQJCpqRsDnTcBAIBlCBYAAMAyBAsAAGAZggUAALAMwQIAAFiGYAEAACxDsAAAAJYhWAAAAMsQLAAAgGUIFgAAwDIECwAAYBmCBQAAsAzBAgAQEOsPnNTHqw/KGGN3UeBHAV/dFADQMN341ipJUpczmuqSs1vbXBr4CzUWAICAOpCaY3cR4EcECwAAYBmCBQAAsAzBAgAAWIZgAQAALEOwAAAAlvEpWDz11FMKCQnx+OrZs6e/ygYAAIKMz/NY9O7dW/Pnzz99gHCmwgAAACV8TgXh4eFq166dP8oCAACCnM99LPbs2aMOHTqoe/fuuvnmm3Xo0KFq98/Pz1dGRobHFwAAcCafgsXgwYM1bdo0zZkzR1OnTlVCQoIuueQSZWZmVvmaSZMmKSYmxv0VFxdX50IDAID6KcTUYTWYtLQ0denSRS+99JLuvPPOSvfJz89Xfn6++3FGRobi4uKUnp6u6Ojo2p4aABBkuj42W5L0zHV9dMtFXWwuDXyVkZGhmJiYGu/fdep5GRsbq3POOUd79+6tcp/IyEhFRkbW5TQAACBI1Gkei6ysLO3bt0/t27e3qjwAACCI+RQsHnroIS1ZskQHDhzQypUrdf311yssLExjx471V/kAAE5T+xZ4BAGfmkIOHz6ssWPHKjU1Va1bt9awYcO0evVqtW7d2l/lAwAAQcSnYDF9+nR/lQMAADgAa4UAAADLECwAAIBlCBYAAMAyBAsAAGAZggUAALAMwQIAAFiGYAEAACxDsAAAAJYhWAAAAMsQLAAAgGUIFgAAwDIECwBAQLG2qbMRLAAAgGUIFgAAwDIECwAAYBmCBQAAsAzBAgAAWIZgAQAALEOwAAAAliFYAAAAyxAsAACAZQgWAADAMgQLAABgGYIFAACwDMECAABYhmABAAAsQ7AAvJBXWKyPVh1Q4skcu4sCBD3DuumOFm53AYBg8OqCPZq6eJ8iwndq97Oj7S4OANRb1FgAXli5L1WSVFDksrkkAFC/ESwAAIBlCBYAAMAyBAsAAGAZggUAALAMwQIAAFiGYAEAACxDsAAAAJYhWAAAAMsQLAAAgGUIFgAAwDIECwAAYBmCBQAgoAzLmzoawQLwQojdBQCAIEGwAAAAliFYAAAAyxAsAACAZQgWAADAMgQLAABgGYIFAACwDMECAABYhmABAAAsQ7AAAARUSAhTzjkZwQIAAFiGYAEAACxDsAC8QM0tAHinTsFi8uTJCgkJ0f33329RcQAAQDCrdbBYt26d3n77bfXr18/K8tTa+K+2atwnPynxZI7dRQEAVINl052tVsEiKytLN998s9599121aNHC6jLVyvydxzV7yzFl5hXZXRQAABqsWgWLcePGacyYMRoxYkSN++bn5ysjI8Pjy5+MSMIAANgl3NcXTJ8+XT/99JPWrVvn1f6TJk3S008/7XPBfEXfOgAA7OdTjUViYqL++te/6n//+58aN27s1WvGjx+v9PR091diYmKtCgoAAOo/n2osNmzYoOTkZJ1//vnubcXFxVq6dKneeOMN5efnKywszOM1kZGRioyMtKa0XqBPEAAA9vEpWFxxxRXaunWrx7Y77rhDPXv21KOPPlohVAQS8wwAAGA/n4JFVFSU+vTp47GtWbNmOuOMMypsBwAADY9jZt4MofsmAAC283lUSHmLFy+2oBjWoY8FAAD2cU6NBRUWAADYzjHBAvAncisAeMdxwYKZNwEAsI9jggWfKAEAsJ9jgkUpOm8CQP3G27SzOSZYhNB7EwAA2zkmWJQiCQMAYB/HBQsAAGAfggXgBWrCAMA7jgsWht6bAADYxjHBgr6bAADYzzHBohT1FQAA2McxwYIaCwAA7OeYYFGKLhYAANjHMcEihEm94Uf8dQGAdxwTLAAAgP0cGCxoCwEAwC6OCRZ03gQAwH6OCRal6LwJAIB9HBMsqLAAgODAB0Bnc0ywAAAA9nNcsCAIAwBgH8cEixB6bwIAYDvHBItStN0BAGAfxwQL6isAALCfY4JFKUOVBQAAtnFOsKDKAgAA2zknWAB+ROdgAPCO44IFDSEAANjHMcGCz5MAANjPMcGiFH03AQCwj2OCBW3gAADYzzHBopShlwUAALZxTLCgvgIAAPs5JlgAAIID9crO5rxgwV8sAAC2cUywoO8mAAD2c0ywKEWFBQAA9nFMsAih+yYAALZzTLAoxQRZ8AdiKwB4xzHBgj4WAADYzzHBAgAA2M9xwYKZNwEAsI/jggUAALCP44IFnTcBALCPY4IFq5sCAGA/xwSLUlRYAABgH8cEC+orAACwn2OCBQAgOBg6wzma44IFf7AAANjHMcGCvpsAANjPMcGiFPUVAFC/MYrP2RwTLPg7hT/x9wUA3nFMsAAAAPbzKVhMnTpV/fr1U3R0tKKjozVkyBD98MMP/ipb7dAWAj+gTzAAeMenYNGpUydNnjxZGzZs0Pr163X55Zfr2muv1fbt2/1VPq+FMJMFAAC2C/dl52uuucbj8XPPPaepU6dq9erV6t27t6UFqy1WNwUAwD4+BYuyiouLNWPGDGVnZ2vIkCFWlqlW6FwHAID9fA4WW7du1ZAhQ5SXl6fmzZtr5syZ6tWrV5X75+fnKz8/3/04IyOjdiX1Em3hAADYx+dRIT169NCmTZu0Zs0a3Xvvvbrtttu0Y8eOKvefNGmSYmJi3F9xcXF1KnBVqLAAAMB+PgeLiIgInXXWWRo4cKAmTZqk/v3769VXX61y//Hjxys9Pd39lZiYWKcCAwCA+qvWfSxKuVwuj6aO8iIjIxUZGVnX03iNphAAAOzjU7AYP368Ro8erc6dOyszM1OffPKJFi9erLlz5/qrfN6j9yYAALbzKVgkJyfr1ltv1bFjxxQTE6N+/fpp7ty5uvLKK/1VPp9RYQEA9RurUDubT8Hivffe81c56oz6CgAA7Oe4tUJIwvAHWtoAwDuOCRa88QMAYD/HBAsAAGA/xwULGkIAALCPY4IFLSEAANjPMcGiFH03AQCwj2OCRQi9NwEAsJ1jgsVpVFkAAGAXxwQL6isAALCfY4IFAACwn+OCBZ03AQCwj2OCBX03AQCwn2OCRSkqLAAAsI9jgkUI3TfhR/x9AYB3HBMsStHHAgAA+zgnWPCBEgAA2zknWAAAANs5LlgYum8CAGAbxwQLWkIAALCfY4JFKTpvAgBgH8cECybIAgDAfo4JFgAAwH6OCxa0hAAAYB/HBAtmRgQAwH6OCRalDL03AQCwjWOCBZ034Vf8fQGAVxwTLAAAgP0cEyyosQCA4ECLtbM5JljkFBRLku7/bJO9BQEAoAFzTLDYeChNUkkSvuW9NdpzPNPeAgEA0AA5JliUtWxPim7/YJ3dxQAAoMFxZLCQpGPpuXYXAQCABsexwYK+QQAABJ5zg4WRluw+oaz8IruLAgBAg+HYYCFJt72/Vre/v9buYgAA0GA4OlhI0vqDp+wuApyAtjUA8IrjgwUAAAgcggUAALAMwQLwBlPGA4BXCBYAAMAyBAsAAGAZggUAALBMgwgWi+OT7S4CAOBnhvHbjtYgggULkgEAEBgNIlgAAIDAIFgAAADLECwAAIBlCBYAAMAyBAsAAGCZBhMs1h04aXcRAABwvAYTLBJP5thdBAAAHK/BBAvDfCyoA9YgAwDvOCZY/G3EOXYXAQCABs8xweLis86o9vlle04EqCQAgOqEUAfoaI4JFoO6tqz2+VmbjgaoJAAANFw+BYtJkyZp0KBBioqKUps2bXTdddcpPj7eX2WzXG5Bsd1FAADA0XwKFkuWLNG4ceO0evVqzZs3T4WFhbrqqquUnZ3tr/JZ6tUFe+wuAgA0eKxu6mzhvuw8Z84cj8fTpk1TmzZttGHDBg0fPtzSgvnDW0v26dFRPRQSQvseAAD+4FOwKC89PV2S1LJl1f0b8vPzlZ+f736ckZFRl1MCAIB6rNadN10ul+6//34NHTpUffr0qXK/SZMmKSYmxv0VFxdX21NagvksAADwn1oHi3Hjxmnbtm2aPn16tfuNHz9e6enp7q/ExMTantIS5AoAAPynVk0h9913n7777jstXbpUnTp1qnbfyMhIRUZG1qpwAAAguPgULIwx+vOf/6yZM2dq8eLF6tatm7/K5TfGGDFBMwAA/uFTU8i4ceP08ccf65NPPlFUVJSSkpKUlJSk3Nxcf5XPcq8x5BQAAL/xKVhMnTpV6enpuvTSS9W+fXv312effeav8lnutYV77S4CghAjlAHAOz43hThBbkGxmkSEKb+oWJHhYXYXBwAAx3DMWiG+GPPaMk38ept6PDFH8UmZdhcHAADHaJDBYn9Ktv676qAk6bWF9LkAAMAqDTJYlOVyOaN5BwCA+qDBB4tiggUAAJZxVLC499IzfX6NyyEdUgEAqA8cFSzuGNrV59dQYwEAgcXnOWdzVLBoE9XY59cU8wcOAIBlHBUsaoPOmwAAWIdgQZ0cAACWcVywuHt4d5/2L6LGAgAAyzguWAw7q5VvLyBXwAshrIgLAF5xXLCIadLIp/1NuWSRmpVvZXEAAGhQHBcs+sfF+rT//hPZun/6Ru05nql3lu7TwGfn652l+/xTOAAAHM6n1U2dKDW7QLM2HdWS3Sd0KqdQkvTP73fp7uG+T7YFAEBD57gai9oqDRUAAKD2CBaAF8r3xQEAVM6RwWLmny62uwgAADRIjgwWfTrG2F0EAAAaJEcGi0Zh/v2xTmUXKPFkjl/PAQBAMHJksPC3Ac/M0yUvLFJyZp7dRQGAoEOPJWcjWNTBzmOZdhcBAIB6hWBRhbzC4hr3MSxgBgCAB8cGixHntqnT61mcDAAA3zk2WIy/+ly/n4Po0XCwCBkAeMexwaJ5ZN1mK/eqmYNkAQCAB8cGixA+YAIAEHCODRatm0fq8p5162dRE6Z5BgDAk2ODRUhIiN6/fVCtay6y870ZFVK7YwMA4FSODRalanvzf2X+bu05nqmT2QXWFggAAAerWw9HB5u+LlHT1yW6H8c/O0qR4WFV7h+flKlWzSN0RvPIQBQPAIB6yfE1Fk//qrclx7nt/bVVPrc3OVMjX1mqgc/Ot+RcAAAEK8cHi9su7mrJcVbvP1lhW2kzy7oDpyw5BwAAwc7xwUKSBnZpYclxCopcHo/puwkAgKcGESy+uGeIJcdJy6m8IydTZgAAUKJBBIuQkBDd84sz63wcI88ZOVmEDAB8x1unszWIYCFJj43uqevO61CnYxgjPTRjS4XtzPIJAECJBhMsJOnJX/aq0+uLjdGXPx12P958OE0SC1Q1BIRHAPBOgwoWkY2qnofCG0MnL/R4PGXRvjodDwAAp2lQwQIAAPhXgwoWYdRnAwDgVw0qWDSJqFtTSJXIKwAASGpgwUKSxl1W92Gn5ZErAAAo0eCCBeOnAQDwnwYXLJpFWruga1pOgUKq6bvhchmdyMy39JwAANRXDS5Y3H5xVw3pfoZlx3vy6+3VPn/Pxxs06Ln5Wrk3xbJzAgBQXzW4YNEsMlyf3n2RZcfbnJimH7Yecz/elZThsabIjzuOS5LeW55g2TkBAKivrG0XaIAOnczRoZM57sejXlkmSToweYzHfnTtAAA0BA2uxqLUzn+MsrsIAAA4ToMNFn6b06IKC3cl62habkDPCeswtxpgHUMdrqM12GDhbylZ+frbZ5s8tv11+kZ7CgMAQIA06GAx72/D/XbsJ2dt08yNRzy2JaRk62harvIKi/12XgAA7NSgO2+2bBbht2MfTM2psC0lq0AX/7xC6vmdYzX19wPVNrqx38oAAECgNegaC3+qqQXxp0Npenb2TklScmaelu9J0c5jGXp53m7lFBT5v4AAAPhBg66xiAj3X67aeSyjxn0y8wolSUMnL1Rh8ekokp1fpCd+2ctvZQMAwF98vrMuXbpU11xzjTp06KCQkBDNmjXLD8UKjKjGjdStVTPbzl+6bknZUCFJ246m21AaAAiMEJZudDSfg0V2drb69++vKVOm+KM8AXfbkC62ndtljD5fn2jb+QEAsJrPTSGjR4/W6NGj/VEWW/x6YCc99e0OW869bE+Klu2puIZIWk6hdh7L0Lnto20oFQAAtef3zpv5+fnKyMjw+KpPohs3srsIFexKytToV5dpx9H69bsCAKAmfg8WkyZNUkxMjPsrLi7O36d0jNX7U+0uAgAAPvF7sBg/frzS09PdX4mJ9CkAAMCp/B4sIiMjFR0d7fFV3/xtxDmSpEvObmVzSSpKzy1kpk4AQNBo0PNYlPrriLN19/DuahIRpq6Pzba7OG4ZeYXq//SPimocrq1PjbS7OAAA1MjnYJGVlaW9e/e6HyckJGjTpk1q2bKlOnfubGnhAinQq516Y3NimiQpM4+ZOAEAwcHnppD169drwIABGjBggCTpgQce0IABAzRhwgTLC9fQVTYt+ObENE34epvScgoCXh4AsALLpjubzzUWl156qYzhjyLQEk/mKK5lU107ZYWkklqMl286z95CAQBQDouQBYl1B056PN6TnGlTSQDAe5l5hXptwR7tP5Fld1EQIASLcp67vo/dRXBbHH/C7iIAQJ08+91OvTRvt0a8tMTuoiBACBbl3Dy4iz696yK7i1FBCGv2AAhC6w+W1La6aEFvMAgWlRhy5hm699Iz7S6GJR78fLMenrHZ7mIEPUbmAIB3CBZViAyvX7+aEIXom81Hq3y+oMiluz9cr1veW6OMvEJJUkpWvr786bBmbDjMKJI62nKYpeyB2gihurXBqV93z3rkjqHd1LNdlN3FcMsuKNJfPt3ofnwiM19dH5utro/Nlstl9OnaQ/pxx3Et25OiR2ZskSS5ytQ9MpAHABAIBIsqxDRppDn3D7e7GG55hS6Px8cz8t3frztwUsmZee7Hc7YnlXxT5oNCXXNFem4hw4wBADUiWASJ9NzCKp8rKHZV2JZf5Lm+iDehIK+wWF9uOKwTmfke21ftS1X/p3/Uo19u8bK0gO/eXbpft3+wtsLfLoIbDSEND8EiSLy2YE+Vzz0xa5vm70j22HbBM/MV4uO/9Itz4/XgjM0a9Nx8/X3mVuUUlHRYfHXBbknS5+sP+1hqwHvPfb9Ti+NPaNbGI3YXBUAdECwc4GBqjuKPe06YlZlfVOMkWgdSsvWbt1dp0g87VVTs0tzSJhRJn6w5pCmL9lbz6sDLLeCTbEOQw3V2FPpuNjwECx9c3bed2sc0trsYXvvdu2uqff7W99dqbcJJvb1kv/676mCFDp6HT+VKks81H/6wfE+Kzp0wRy/O3WV3UQAA1SBY1ODSHq0lSQM6x+rNmwdq1fgr9J9bL7C5VL4r38PCGKNDJ3Pcj1fvT9WRtFzLzvfagj36+8ytlfbtWJtwUlMW7fUYtVKTp7/dLkmasmifZWX0l+SMPC2KT6azay3xawOCm8+LkDU0r940QF9vPqIxfdu7t3Vr3czGEtXekbRcRYaHqlXzSCWX66BZmbq8wb80r6Rfxu8Hd1GvDtEez/3m7VWSpA6xjXX9gE61P0k9Nez5RSoodun1sQN0Tf8Odhcn6JArgOBGjUUNYpo20q1DuuqM5pHubaFB2GiYnluooZMX6oJn50uqGBrSc6oedeKLpbtPaOw7q92P86rp4Z+QklPlc+UF082mdJTOsj2s9QJUhlopZyNY1EKXlk3tLoLPDqRkV/v82nKrp5ZVNkdl55eMFMktKNai+GR9vj5RXR+b7R61cuv7a7Vqf6p7/2rfQHh3QSVoQnKW+tBHC4FFsKiF0NAQbZ54ld3F8EnZcLD7eKZMLesAek+cq7ScAj00Y7Pu+GCdHvmiZG6Ll+bt9qnPhORbLURDeWsyxuhYunV9XQAg0AgWtRTTpJFuHBg8/QPKfmrwdlGy1WVqHsr66qcjmr31WMVz1PHuX1TJRF9VcbmM/v1jvBbuOl63k9YzE7/ZriGTFmr62kN2FwWAj9YdOKnkjLyad3Q4gkUdBGuNbX6RS7uOVT/HhSQlZ+Zr2PMLtXJf5QHDO1X/ksr+/g6mZuvcCXM08ettXh11zvYkvb5wr/4wbX0dylZ3+UXFls4U+eGqg5KkF+bGW3ZMwE5B2CWtVtYdOKn/99YqXfjPBXYXxXYEizqobXOCHcZ98pP7e2OkO6at8+p1pXNZlFXdKqvleRu+pi7ep8Jio//+fGOtcJxyj49aODS2toqKXTrv6Xm64Jn5lTYDBWvwtBu/NwSjVXX6AOYsBAsLRYSH6pO7BttdjEqVnc2w/CydvtqUmFbp9rrcEGp67d7krNofvI6qCjEpWQXKLSxWZn6Rsn6e/twqdGAEggv/sqcRLOrguvM6Vth28Zmt9MpN5wW+MPVAoatiH4nq/tfeKDNleHW1P5VN3BUSoPpVY4wunrywVq9tKFXAVrO6JrCo2KVDqd4PbQZQNwSLOhh+Tmv9+LcyS6v//H4Y17KJPQWyWWWJvai4+pvEf1ce0KHUHG09klHlPnbWVhT5ONLFKqdyCrXtSLot5w525TsB3/Xheg1/cZG+r6TDMWCVYGoa9zeCRR2d0zaqwrZurZrbUBL7uSpJFv9Ztr/a10z8ZruGv7hIO495Boujabl6Y+EencwusLSMuQXFWrk3RYU+jECxyy9fX17p9vScQm05nOaxzRijvclZPo2sqa/qUqX8n2X71ePJOVpfZl6WRfElE5W9vzyhrkVDJbYdSdfhU9QI4TSChQWev6GvQkKkt28ZKElq2SzC5hLZ44lZFUd0LNiVXMme1ft49UHd9M4q/evH3frbZ5t0rIaOmhMqGUlyKDVHf/50Y4VP/b94cZF+9581uv2Dte5tK/emqOtjs/Xc7B0VjlPdTa7sJ5RAtq8Oe2GhfvXGCq3cl+Le9tm6RI14aYlHJ91gVZdf5bOzd6rYZdzzq1h1XFQu8WSOfvn6cg17fpHdRUE9QrCwwE2DOmvPs6N1Wc827m0HJo+xsUT2+OqnI5VuXxyfrFveW6PDp3K024uOo0/M2qbEkyVhYsXeFD321VaP5w+mZuuZ706HgA8rGUly90fr9e3moxU+9ZeukbJi7+ke3L/7T8kqsO8uq/iJti7Vm/4KG5l5JR1FF+w8HdreWVpSMzR3u3/m9XC5jB74bJPeXlL/F4GrCh1irRefVPP/c2X9ob7ccNgfxUE9wSJkFgkPI6NV5fYPSoa2Pjxji9Jz674myQOf1zzB1/4TnlOYZ+QV6p0l1TfLVKa6e1HZScdCQkpuXE96OQ+Ht3IKivSfZQka1addpc1uldl5LEPnto+ueUcfrNiXoq82lgTHP/7iTEuPHSjECnskpFTsI7W/hiUGENy4G/pR40anf70DOsfaV5B6YtX+VO04VnUnzcpU1nmyNv0u/vHtDo9RKN7y5UPuqv2p+nj16RkzrRgV8u8fd+ulebt11ctLKzxX1eFHv7qs7icuJzvfuknAauKvigUqLKxXU1+lI2m5yisM/n4/3uDv6zSChR8tefgyXXdeB33352GadvuFevKXvewukiN4dcMut8/mKubeqIkvTSFZedbOZSFVPWdIeZUNyYUnf7zvr9qXqo9WVz6pW0PwTg2ds7fU8v8OwY1g4Udtoxvrld8OUJ+OMYpp2kh3DuumufcPr/mFqF4ld4jKOl5acqpKzlU6J0L5zpv+GJrqbaVHfpFv66yU99GqA3r0iy1VLiTnzzk5CopcuuntVe7HwTRsb+y7q/XkrG1VrquTnJHn8+J8lSl2GZ2yeIRUbRhjtHDXcfekcRsPpdlboHokeP5q/Y9gEWBdzgi+Jdfrm8raZyvreFlWbW+MlU1pPvzFRfq//67zCB0JKdn60/9qHpGxbM8JbT1szfwUtXkje2HOLg14Zl6F4YFPfr1dn61P1OLdlY/iqa6a90harv41N969+FJeYbH2najYrp5bUHlzytztSVqTcHp4aIEPIcknfqyrPlDJ3+TyPSm68J8L9H8f1n09m7HvrtaAZ+ZpV5JvTYne2HksQ/d8tEF7k2vuiPnjjuP6w7T1tZ40Dg0DwSLAGjcK0/JHL9Mvzmltd1EcJyOvUFMX79P1b67wuDltP5qu3ccr3uiy8ov0aRWriD71zXY9+PlmjXylYt8GSZq/M1njy4xW+e07qyrs8/n6wx5v1vFJmbrlvbW65o3K56cIhDcX71N6bqHeWFh5f5PMWjTn/P4/a/TGor268J8LNPad1fr1myt1xb+XaNGuZPen9W83H9W5E+bovUrmkijfTv/K/D0qKHIpv6jYPZIjv6hY6Tl16/jrTaw4mpZbq+BXfuSSJL23vKSZYGEthlyXt/bn4PXFeutHU/z6zZWasz1Jv3t3TY37ll0P49X5eywvS1DzQ3AtLHbpH9/u0CIL/oYCiVEhNujUoqn++4cL9e3mozqjWYR7uCPqpt9TP1a6fcxrld/I+0ycW+n2omKXpq08UOP5luw+4f6+qg5qD83YolnjhkqSbnnv9HVesz9VO49l6LaLuwZsevKypq9L1NLdJ7T44csUEX7688WmxDR9vPqg/n71uRrQuYV7e/ki5hQUac62JF3es40SynxaX1WmSeDhL7Yov7BYE67ppUe/LJlX4pnvdujOYd1qLN+g5+YrPbdQUZHheu7XfTXp+506lp6n9U+MUKvmkbX6mXclZepoWq46xFY9M27pJ/GFD/5C3VvXv4nu/FHnkltYUpNUOhS7OmX/Dl6ev9sPpam/jmfkqU1UZED/X6evS9T7KxL0/oqEoJrCgBoLG13Tv4MuPquVx7a+HWNsKg38obTvQ3puoccb903vrNZT3+7wCCeVKfsedst7a/S/Nac7ClY322F2fpH+NTdeXR+brWPpJc05qVmeN46j6XkVahA+WHFA6w6c0vVvrnRvyyus2ITxxMxteuDzzfpDNavkpmTlKzO/SA9/sUW+djMoHZacmV+kv3y6UcfSS5pZJn6z3bcDlVFQ5PK6Cn/70ZqbHGrqO+GPG5DdIw9CvO714ywfrEjQ4H8u0L9+jA/oeevDKs61QbCoB565trckacVjl2vmny7Wyzf1t7lEsMrOYxnqM3GuHp9Zsapckg6d9H4q5GV7UvT4zNPzZFQ3GVbviXPdw2uHTFqoo2m5lc7/UX5q8PJenrdbPZ+co+V7Ujy2z9xUMqfFTwHuvDd7yzHt8OKmX3r/q+3U7d687oufKjZLpOcWWjJXS31VXVY6lV1QZT8af/ls3SG9FICb/dPflnQOn7IoeCeICySCRT1wy5CuOjB5jDrGNlF4WKiuH9BJnVo0zIXM7Pb8nF0+f7quSVZ+kb7bUvMCWJXNarnuwClLyvD7/6zRmoSKIxeKXUaPfVlx+utSry4oaUcvP6TSyk/Ovn6wn+rF7J8ul9HyPSnq+eQcr49bdmbOhBomcNpw8FSFacMLi13q//SP6v/0jyooclWoIQoGWw6n6b5PflJiFYG3uks14Jl5GvjsPP8UrAqPfrlVry3c6zF1/4nMfN0wdaVXs3seS8/1WFemvKJil9cztnr7L5GSlV9pLaCT0Meinlr+6OUqKnapz1NzG8wEM/XB1MX7NHVx4D6VzN2epLUJJ3XH0K6a9MOuWh2j2IskVNVMhz/uqLrWo6qq/vwie98Uw0JK3vBTsgrULqaxe/usjaenlD+QmqPfv+db36Wy94/CGlblvWHqygrbMsrUVKTlFmizRaN/yqrtUNzZW44pPCxEI3u3q3a/X72xQlJJTdo39w07fV5jlF/kqjEE5lhUY1FY7FJCSrbObtPcqyaljLzTv/sX5uzShoOntOHgKd0wsFO1rxsyqaRp7Jv7hqpfp9gKx7zk+UUaetYZvv8AlTiRma+tR9L0h2nr1TY6UqvHX1HjzxbI9yIrUWNRj4WHhbo7/sGZVuxN1XdbjumGqRVHlXjrzL9/b2GJTutexXF7POF9LYA/ZBcUq9eEubpo0gL3aAlJuv+zTV69vrJg5HIZTSkzM+tbtVgTpexNIjnDP7UVH6w44F7B1ttPvWk5BRr3yU/640cbvA6FCSeyPebNuPCfC9TzyTl+CUv7T2Rp1CtL9c3mo+5tZz/+g656ealufMvL/4syeatsyCgvr7BYS3efqPB72HCwYs3g7C3HlJ5bqO+3JnlVhFM5p39fWw+n656PNrhrUk5mF2jQc/P1h2klQ4+PZ+Rr0HPz9W2Zn7k8b9ZVqq8IFvVcjxrWh5hxz5AAlQT1Udnhf8GitOp51b5UbU5M05L46juwljdvx3EV/Hxz/c3bq/Tq/D1e1dqU+m8lI36+3XJU/55Xt1EOZftlVLXkfXlFxS5dN2WFHppR8/o3pe7930/q+ths9Xxyjka+vFQbDp4OV8cz8nTj1JX6etPp2pvS5qyS83n3e8rML9KAZ+bpnaUlAevEzx2PywY5qzzyxRbtSsrUXz7dKMnzhrrh4CntOZ7p7ruRV1ispJ878pZOVCdJt76/Vsv21Px39MgXW3Tr+2s1YZZnJ2ArmvYW7Tp9/t+9u1pztifpuiklNUAX/XNBhf1Tsgr05083VjlvS4oXo3TqK4JFPRcSEqLHrz630uem3ny+BnVtqe1PjwxwqVBfjH13td1F8NmNb63Sv3+M19h3V+vaKSs0a1PVn9q88fL83ZqxPtHr/Y+cylVuQbH+9tkmzdmWpGKX0V+nb6py/znbkjw+TVdlghcL0G09nO7Rpr96/0ltSkzTFz/3B3C5jL7ccFgvz9utX72xvNKRP/PKNF/FH8/0qO165rsdWn/wlMfP88GKA+7v5+887rHWTmY1n+4l6Z/f1655zhdZ+Z5zp+xL9pxz5sqXl+rq10rWv7ni30t00aQFmrMtScNfPL1Ue5HL6Jb31kqqfuRK6XX8bH2ix7woleUKb7r+GGOUW1CsU9kFHtPqZ/78M5XOxltQTWfgBz7f5P4+PadQXR+brfeXJ3g/7W49RLAIAncN766d/xhVYfvovu0lSc0iw/XG7wYEulhArb1exQRdtbXAhwmEMvOK9M7S/Zq58Yju+XhDpf0lShUUuXTPxxv0l0836kBKtj5afbDKRfBqWrLeGKNr3liuG99a5a41KXJ53nC+2nhED87YrFcX7NGWw+kaWcnic5XJLSjWJ2sOaW9yxYngyvrr9E265ufalPOfmae+Vcz9UpYvoa08bzrmlm1CSjyZU2nIK+1MW3rzvufjDbUuU6n+/6j+Z6+q7GU75Y775CedO2GOBjxT+06rZTt2l5bpH9/tqNDU1WfiXPfw00CPvvEVnTeDRJOIML0+doBW7U/VJ2sqzhb5y34dNHf78Wrb7ACnmldNJ9Ty9iRneXwarGqht2unrPBYvO7XU1fqZHaBnpxVc81EZcq21kz8ZrvaxTTW6wtPN1MUu4wmfb/T4zXZBcUefT+qMvmHnfrvKs+ROw98tkntYxtX2PdIWq4e+3KL16sEP/xF1aOGauJrZ85LXlhU5XPeNHWU9781B/X1xqN69vo+OqeaZmVvR35I0sBn5+vA5DEqKnZ53f+iJi/M2VVhmPJrCzyve1Z+kX7/nzU6dDJHRS6jZ67trVuGdLXk/FYjWASRa/p30Ji+7bX9aIZaNYuo8PzLv+mvNftTK8ygFxEe6r/1F4Agc/hUjrYeqbkTYvkVcb29EVel/M3rjx95fup+b/l+pVZyjhfn1jxPQ/lQIZXUflRl+rra10LUZMLX23RVr3YqdLkqnTul1Nebjig9t1A7j3m3/klpU0d1yi9GWDrvy//9d72WPnJZla9bFJ+suJZN9d6yBL10U391jG2iA6lVzzFjjNHHFq5q+2Yloz8qG/JcdnTXk19vJ1jAGqGhIZr1p4srHaYUHhaqtY+P0OFTOVq0K1lPfr1dzSPDNfdvwzX05xkHY5o0cvQEPkBNTtVxzZHaMMbUOPw1EP0ZAuHDVQf1YSVBp7zq+rXU1rvLEjSqkiG1KTXMKbJib6pW7C3pCP34zG1qGhGmH7ZVXRthjLTFi3BaF8H8Pk2wCEI1jX3u1KKpbh7cRR1im6hvpxi1iWqsb+8bppgmjdT5jKbacTRDD87Y7PUnBQB1sykxTav3Wz+iAhWVTmFflsuHpo6aptmXpB3HMrye3nzNfv+N3MovKlZkeJgk6dnvdqig2KV/XNvHb+fzFsHCoUJDQ3TFuW3dj/t2Or0GSa8O0fr+L8M0d3uSeraLVquoSD0xc6tuHBin3ccz9Y/vdlR2SAC1VHbtFfhXZXNt5BW6LO3w6O1wYqlk5I6/lM4ps+GJEfrPz+v+nNM2Sr+/qIvfzumNEONLrxULZGRkKCYmRunp6YqOjg7kqeEFY4y6jffPhEsA0NA8PLKHV/1k6qJ762baf+J0/wt/rYTq7f2b4abwEBISos0TrtLKxy7Xx3cOVvsyUybfWMP0uAAAT/4OFZI8QkV9QFMIKohp2kgxTRupQ2wTLX3kMn2wIkGp2QV68MoeatksQu8tT9BT1/RSYbHRtiPpuvfSM3Wll+PtAQD+lZyRpzbRFYcaBwpNIaizgiKXejz5g6UrXgIAaqdzy6bVDq+tLZpCEDAR4aHa8fQo/W5w5wrP7fvn1bq6bzv1K9N5tNSQ7tasGggAOO1QFcveBwrBApZoEhGmv199ru4e3l0f3DFIY/q210d3Xqiw0BC9efNAfXPfMI3pVzIF+QVdWmjN36/Qp3dfVOXx7hzWrcZzjigz6gUAcFp2uTVYAok+FrBM88hw/f3nBdMu69GmwvPP39BPvzinta7q1VaxTUtmDn32uj5asPO4FsWfUKvmkerbMVpP/6qPOp/RVHO3J+nwqVzdPLizRvdprx93JOnvV5+r91ck6PN1iZr06766PqGjxn3yk8d5ohqH68Ub++mej3+qUAYAaAiyC4rULNKeWzx9LFAvZOYVqllEuEJDT086czwjT/N3Htf1AzqqaUTV/yCZeYW687/r9ct+7XVrmSluL//3Yndv6bdvGaj+nWL1x4/Wu8e5L3vkMo+1CUb3aacjabk6kJKtGwZ20gVdWurqvu10y3trtXxvit699QLd9eF6i39yALDeqvGXq31ME0uP6e39m2ABx5qyaK97qFfpuO6k9Dz96X8bdOuQrrpuQEct3X1CL8/frajGjTTldwMU1bhRtcfs+tjsCtvOi4vVpsQ0Tfp1X43/aqv1PwgA+Mgfc1n4tfPmlClT1LVrVzVu3FiDBw/W2rU1Lw4DBNodQ7vqql5t9e//19+9rV1MY331p6G6bkBHSdLwc1pr5p+G6sM/XFhjqJCkdY+P0Bf3DNHVfUvWI3j7loH68t6LtXniVRp7YWf95YqzJUltoiL17X3DtOGJER6vX/7oZRrZu63evmWge9sN55+eH2TxQ5fq+Rv6au9zo3Vg8hgdmDxGCZOu1h1Du7r3uaLn6WamzROucn9/WY/WmvTrvipT6aMXbuynhElXe5Rh9l+G6cDkMfrxb8Pd29Y+foVaNa+4sF1dxDSp+fdZ1lu/P9/S8wOwh881Fp999pluvfVWvfXWWxo8eLBeeeUVzZgxQ/Hx8WrTpmK7ennUWMDJCotdWrr7hC7o2tJ9Y92bnKnnZu/U7wZ30ZW9Tnc4PZqWq2PpuerTMUZPfbNDl/ds4/F8eZl5hSoocqllswi9PH+PzouL0eU92yqvsFgRYaHuZiRjjP75/U4dS8/Ta78doNDQEG05nKYftiXpr1ecrcaNwtzHPJKWq7zCYp3ZurkWxSfrjg/WSZJuv7irpq08UKEM9156puJaNNWYfu0VGV7yueSuD9crLDREL97YX9uPpuv2D9bprku66fExvbTlcJrOaB6pPcczdWbr5jJGGv5ixaWxFz74C3Vv3Vyr9qVq7LurPZ6be/9w9WhXsuT13O1JHquCdjmjqQ5Wswol0FDZWWPhc7AYPHiwBg0apDfeeEOS5HK5FBcXpz//+c967LHHLCsYgMAyxmhTYpq6t2qumKaNtPNYhh6asVl/veJsZeUXaXD3M9Qxtm5ttpl5her71I+SpKv7ttO2Ixn69O6L3Mc1xui376xWm+jGah4ZrhOZ+Xr31oHuhfeKXUYPf7FZ58XF6obzOykyPFTXTlmhuBZN9djonmob3Vifr0/Uue2jtSspQxO+3q6J1/TSHUNLRhmVNmX9YWg3vb8iwaNs9/ziTL21ZJ8uObuVfnFOa3WIbaKr+7bXol3J+mLDYWXkFSq/0KWnftVbV7+2TJL0wJXnaFdShl777QCN/2qrerSL0pW92qrLGc2UllOgZpHhOnwqV5f9a3GF38XGJ6/UgGfmuY/TMbaJHpxR+TLjPdtF6fEx53osHV52peLfXNBJ1/Tv4H5+UNcWWnfglMcxzm7TXJ1aNNGi+BM6s3UzPf2rPrr/s41KySpZqv3eS89UUnqeHrjyHI++R2XdfnFXPTSyhwY+M0/5RS5J0jPX9dHvB3fW/Z9t0tebjlb6uvK6tWpW6bLgvnh4ZA9d1qON+1r8cXh3XXteR/dju/zj2t6a8PV2y4437Y5B2pyYrpfn7/b6NaVB3Wp+CRYFBQVq2rSpvvjiC1133XXu7bfddpvS0tL09ddfV3hNfn6+8vNPL1mbkZGhuLg4ggXQQK3cl6Lw0FBd2K2lJcczxlS54m9mXqFHE9eBlGwdPpWrYWe3UrHLqLDYpfxCl/alZGlAXKzScwsV3biRRyfiyhS7jFzGqFGYb63JmXmF+mxdokb3ba+OsU20OD5ZKVkF7unycwqKtHBXssJDQ3VeXKxaR0UqrExZCopc2nDwlBJSsvW7wZ2VlJ6ntNwC9WxX8b00I69QyRn5OqtN8yp/Ry6X0fajGerZPsrjZ8nKL9Ke45nq1SFaR9Py9Or83Zp4TW+1aFbSXGaM0ar9qRWu48erD2rr4XQN6tZS3Vo11dTF+zR/Z7L7+evO66AHr+qhuJZNPcqx/0SWXpq3W99tOSZJ+v4vl+iFubu0OP6E7rvsLF3dt72iGoerY2wThYR4rvBcUORSaIgU/nP5P1x1QP+aG69P7rpIKVn5uv2DdZrwy1768qfD2n40QzFNGunPl5+lo2l5emRUDzVuFKZJP+zUjqMZWrYnxX3crmc01Tu3XqCiYqPV+1PdizNO/nVfndc5Vhm5RerRLkrDnl+ozLwi/fWKs/W3K8+RVLJM++bENH2x4bCKXUY/7jguSVr/xAhFhIfqpR93e9QI9u0Yo4/uvFDpuYW65vXlGtC5hcZeGKeRvdu5f9ak9Dw9P2eXZm48UuE6doxtoiNpJau6DuraQjPuubjCPlbwS7A4evSoOnbsqJUrV2rIkCHu7Y888oiWLFmiNWvWVHjNU089paeffrrCdoIFADQMWflFSsspUKcWTWve+WfFLqPUrPxaTU1dWZByuYyW7D6hPh1j1Doq0udj7k3O1LoDp/SbC+I8wl51wdaXfbx1PCNPISqZOyiqcSPlFRarcaMw5RYUa9X+FF18ZiuP5k4reRss/D7Idfz48XrggQc8ChYXF+fv0wIA6onmkeFq7uOcCmGhIbVe76Kym3hoaIgu61lzP8CqnNUmSme1ifLqXLXZx1tty/1OSkNEk4gwXd6zfkwa6NOVbtWqlcLCwnT8+HGP7cePH1e7du0qfU1kZKQiI31PhwAAIPj41EAYERGhgQMHasGCBe5tLpdLCxYs8GgaAQAADZPPTSEPPPCAbrvtNl1wwQW68MIL9corryg7O1t33HGHP8oHAACCiM/B4qabbtKJEyc0YcIEJSUl6bzzztOcOXPUtm39aNsBAAD2YUpvAABQI79O6Q0AAFAZggUAALAMwQIAAFiGYAEAACxDsAAAAJYhWAAAAMsQLAAAgGUIFgAAwDJ+X920vNL5uDIyMgJ9agAAUEul9+2a5tUMeLDIzMyUJJZOBwAgCGVmZiomJqbK5wM+pbfL5dLRo0cVFRVl6Rr1GRkZiouLU2JiIlOF12Ncp+DAdQoOXKfg4JTrZIxRZmamOnTooNDQqntSBLzGIjQ0VJ06dfLb8aOjo4P6wjUUXKfgwHUKDlyn4OCE61RdTUUpOm8CAADLECwAAIBlHBMsIiMjNXHiREVGRtpdFFSD6xQcuE7BgesUHBradQp4500AAOBcjqmxAAAA9iNYAAAAyxAsAACAZQgWAADAMo4JFlOmTFHXrl3VuHFjDR48WGvXrrW7SI711FNPKSQkxOOrZ8+e7ufz8vI0btw4nXHGGWrevLluuOEGHT9+3OMYhw4d0pgxY9S0aVO1adNGDz/8sIqKijz2Wbx4sc4//3xFRkbqrLPO0rRp0wLx4wWtpUuX6pprrlGHDh0UEhKiWbNmeTxvjNGECRPUvn17NWnSRCNGjNCePXs89jl58qRuvvlmRUdHKzY2VnfeeaeysrI89tmyZYsuueQSNW7cWHFxcXrhhRcqlGXGjBnq2bOnGjdurL59++r777+3/OcNVjVdp9tvv73C/9eoUaM89uE6+dekSZM0aNAgRUVFqU2bNrruuusUHx/vsU8g3+eC7v5mHGD69OkmIiLCvP/++2b79u3mrrvuMrGxseb48eN2F82RJk6caHr37m2OHTvm/jpx4oT7+XvuucfExcWZBQsWmPXr15uLLrrIXHzxxe7ni4qKTJ8+fcyIESPMxo0bzffff29atWplxo8f795n//79pmnTpuaBBx4wO3bsMK+//roJCwszc+bMCejPGky+//578/jjj5uvvvrKSDIzZ870eH7y5MkmJibGzJo1y2zevNn86le/Mt26dTO5ubnufUaNGmX69+9vVq9ebZYtW2bOOussM3bsWPfz6enppm3btubmm28227ZtM59++qlp0qSJefvtt937rFixwoSFhZkXXnjB7NixwzzxxBOmUaNGZuvWrX7/HQSDmq7TbbfdZkaNGuXx/3Xy5EmPfbhO/jVy5EjzwQcfmG3btplNmzaZq6++2nTu3NlkZWW59wnU+1ww3t8cESwuvPBCM27cOPfj4uJi06FDBzNp0iQbS+VcEydONP3796/0ubS0NNOoUSMzY8YM97adO3caSWbVqlXGmJI31tDQUJOUlOTeZ+rUqSY6Otrk5+cbY4x55JFHTO/evT2OfdNNN5mRI0da/NM4U/kblsvlMu3atTMvvviie1taWpqJjIw0n376qTHGmB07dhhJZt26de59fvjhBxMSEmKOHDlijDHmzTffNC1atHBfJ2OMefTRR02PHj3cj3/zm9+YMWPGeJRn8ODB5o9//KOlP6MTVBUsrr322ipfw3UKvOTkZCPJLFmyxBgT2Pe5YLy/BX1TSEFBgTZs2KARI0a4t4WGhmrEiBFatWqVjSVztj179qhDhw7q3r27br75Zh06dEiStGHDBhUWFnpcj549e6pz587u67Fq1Sr17dtXbdu2de8zcuRIZWRkaPv27e59yh6jdB+uae0kJCQoKSnJ43caExOjwYMHe1yX2NhYXXDBBe59RowYodDQUK1Zs8a9z/DhwxUREeHeZ+TIkYqPj9epU6fc+3Dt6mbx4sVq06aNevTooXvvvVepqanu57hOgZeeni5JatmypaTAvc8F6/0t6INFSkqKiouLPS6eJLVt21ZJSUk2lcrZBg8erGnTpmnOnDmaOnWqEhISdMkllygzM1NJSUmKiIhQbGysx2vKXo+kpKRKr1fpc9Xtk5GRodzcXD/9ZM5V+nut7v8kKSlJbdq08Xg+PDxcLVu2tOTa8f/onVGjRunDDz/UggUL9Pzzz2vJkiUaPXq0iouLJXGdAs3lcun+++/X0KFD1adPH0kK2PtcsN7fAr66KYLf6NGj3d/369dPgwcPVpcuXfT555+rSZMmNpYMCH6//e1v3d/37dtX/fr105lnnqnFixfriiuusLFkDdO4ceO0bds2LV++3O6iBI2gr7Fo1aqVwsLCKvTGPX78uNq1a2dTqRqW2NhYnXPOOdq7d6/atWungoICpaWleexT9nq0a9eu0utV+lx1+0RHRxNeaqH091rd/0m7du2UnJzs8XxRUZFOnjxpybXj/7F2unfvrlatWmnv3r2SuE6BdN999+m7777TokWL1KlTJ/f2QL3PBev9LeiDRUREhAYOHKgFCxa4t7lcLi1YsEBDhgyxsWQNR1ZWlvbt26f27dtr4MCBatSokcf1iI+P16FDh9zXY8iQIdq6davHm+O8efMUHR2tXr16ufcpe4zSfbimtdOtWze1a9fO43eakZGhNWvWeFyXtLQ0bdiwwb3PwoUL5XK5NHjwYPc+S5cuVWFhoXufefPmqUePHmrRooV7H66ddQ4fPqzU1FS1b99eEtcpEIwxuu+++zRz5kwtXLhQ3bp183g+UO9zQXt/s7v3qBWmT59uIiMjzbRp08yOHTvM3XffbWJjYz1648I6Dz74oFm8eLFJSEgwK1asMCNGjDCtWrUyycnJxpiSYVidO3c2CxcuNOvXrzdDhgwxQ4YMcb++dBjWVVddZTZt2mTmzJljWrduXekwrIcfftjs3LnTTJkyheGmNcjMzDQbN240GzduNJLMSy+9ZDZu3GgOHjxojCkZbhobG2u+/vprs2XLFnPttddWOtx0wIABZs2aNWb58uXm7LPP9hjGmJaWZtq2bWtuueUWs23bNjN9+nTTtGnTCsMYw8PDzb/+9S+zc+dOM3HiRIYxllHddcrMzDQPPfSQWbVqlUlISDDz5883559/vjn77LNNXl6e+xhcJ/+69957TUxMjFm8eLHHsN+cnBz3PoF6nwvG+5sjgoUxxrz++uumc+fOJiIiwlx44YVm9erVdhfJsW666SbTvn17ExERYTp27Ghuuukms3fvXvfzubm55k9/+pNp0aKFadq0qbn++uvNsWPHPI5x4MABM3r0aNOkSRPTqlUr8+CDD5rCwkKPfRYtWmTOO+88ExERYbp3724++OCDQPx4QWvRokVGUoWv2267zRhTMuT0ySefNG3btjWRkZHmiiuuMPHx8R7HSE1NNWPHjjXNmzc30dHR5o477jCZmZke+2zevNkMGzbMREZGmo4dO5rJkydXKMvnn39uzjnnHBMREWF69+5tZs+e7befO9hUd51ycnLMVVddZVq3bm0aNWpkunTpYu66664KNxGuk39Vdn0kebwHBfJ9LtjubyybDgAALBP0fSwAAED9QbAAAACWIVgAAADLECwAAIBlCBYAAMAyBAsAAGAZggUAALAMwQIAAFiGYAEAACxDsAAAAJYhWAAAAMsQLAAAgGX+P07EpGKiktsEAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(TP_losses)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "7d9a39813ecb41f697ffbfed9be5ca24",
            "0888cbc52e94409aa68dd5a3f7d464e7",
            "03fd8d6afed2456a957c2abe1405a393",
            "0a71224e0bfd4472a9a5c3d09f2dabd7",
            "4ef4f16fa5cd4915931d80df674bce44",
            "dfd45da3235745ab992fe3bc37cd9503",
            "c06eecbf5c54487f91e5b5c1af54a24e",
            "63128e7a84cc47548fdbb1e5753e804b",
            "7d249d8dcc954c3ca313542bf2b23dba",
            "1d51fec1aa8d4ab18971e126fac13830",
            "0372a03fa56d41e38394bd23ecaf4773"
          ]
        },
        "id": "BSvSVsf3BLjv",
        "outputId": "68c52ee5-b50b-4556-d3a2-1fc0f2f3044e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0:  13%|█▎        | 1338/10417 [03:28<23:37,  6.40it/s]\n",
            "Testing: 271it [00:40,  6.72it/s]"
          ]
        }
      ],
      "source": [
        "TP_trainer.test(TP_t,test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_list = []\n",
        "\n",
        "with open('TPlosses.pickle', 'wb') as file:\n",
        "    pickle.dump(TP_losses, file)\n",
        "\n",
        "# Caricamento della lista da un file\n",
        "with open('TPlosses.pickle', 'rb') as file:\n",
        "    loaded_list = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3LFNGTGeEgLP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8369037445618397"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(TP_acc)/len(TP_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:71: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "  rank_zero_warn(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 23.6 K\n",
            "1 | tgt_embedding       | Embedding | 23.6 K\n",
            "2 | transformer_encoder | TPEncoder | 52.2 M\n",
            "3 | transformer_decoder | TPDecoder | 104 M \n",
            "4 | fc                  | Linear    | 23.6 K\n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "156 M     Trainable params\n",
            "0         Non-trainable params\n",
            "156 M     Total params\n",
            "626.075   Total estimated model params size (MB)\n",
            "c:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Epoch 0:   0%|          | 0/13889 [00:00<?, ?it/s] miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "Epoch 0:   0%|          | 1/13889 [00:00<34:41,  6.67it/s, v_num=2]miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "Epoch 0:   0%|          | 2/13889 [00:00<37:45,  6.13it/s, v_num=2]miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "Epoch 0:   0%|          | 3/13889 [00:00<38:31,  6.01it/s, v_num=2]miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "Epoch 0:   0%|          | 4/13889 [00:00<38:44,  5.97it/s, v_num=2]miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "Epoch 0:   0%|          | 5/13889 [00:00<38:39,  5.99it/s, v_num=2]miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "Epoch 0:   0%|          | 6/13889 [00:01<39:11,  5.91it/s, v_num=2]miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "Epoch 0:   0%|          | 7/13889 [00:01<39:06,  5.92it/s, v_num=2]miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "Epoch 0:   0%|          | 8/13889 [00:01<39:13,  5.90it/s, v_num=2]miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "Epoch 0:   0%|          | 9/13889 [00:01<39:26,  5.86it/s, v_num=2]miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "Epoch 0:   0%|          | 10/13889 [00:01<39:22,  5.87it/s, v_num=2]miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n",
            "miaosaaaa\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 11.99 GiB total capacity; 17.60 GiB already allocated; 0 bytes free; 17.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 34\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=277'>278</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_dataset,batch_size\u001b[39m=\u001b[39mbatch_size,shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=278'>279</a>\u001b[0m TP_trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)  \u001b[39m# Modifica il numero di epoche come desiderato\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=279'>280</a>\u001b[0m TP_trainer\u001b[39m.\u001b[39;49mfit(TP_t, train_loader)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n\u001b[1;32m--> 532\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    533\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    534\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[0;32m    562\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[0;32m    563\u001b[0m )\n\u001b[0;32m    565\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    566\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    567\u001b[0m     ckpt_path,\n\u001b[0;32m    568\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    569\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    570\u001b[0m )\n\u001b[1;32m--> 571\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    982\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1021\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1022\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1023\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1024\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[0;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:355\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[0;32m    354\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[0;32m    132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(data_fetcher)\n\u001b[0;32m    134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:219\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    218\u001b[0m         \u001b[39m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautomatic_optimization\u001b[39m.\u001b[39;49mrun(trainer\u001b[39m.\u001b[39;49moptimizers[\u001b[39m0\u001b[39;49m], kwargs)\n\u001b[0;32m    220\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_optimization\u001b[39m.\u001b[39mrun(kwargs)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:188\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         closure()\n\u001b[0;32m    183\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[0;32m    190\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[0;32m    191\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:266\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[0;32m    265\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[0;32m    267\u001b[0m     trainer,\n\u001b[0;32m    268\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    269\u001b[0m     trainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[0;32m    270\u001b[0m     batch_idx,\n\u001b[0;32m    271\u001b[0m     optimizer,\n\u001b[0;32m    272\u001b[0m     train_step_and_backward_closure,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[0;32m    276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:146\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 146\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    148\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    149\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1270\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[0;32m   1233\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1234\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1239\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer`\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[39m    calls the optimizer.\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[39m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1270\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:161\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    160\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[0;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:231\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[1;32m--> 231\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(optimizer, model\u001b[39m=\u001b[39;49mmodel, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:116\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 116\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adam.py:121\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m--> 121\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    124\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision_plugin.py:103\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[0;32m     92\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     93\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     optimizer: Optimizer,\n\u001b[0;32m     95\u001b[0m     closure: Callable[[], Any],\n\u001b[0;32m     96\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     97\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer)\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:142\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:128\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39menable_grad()\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 128\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[0;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:315\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m trainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\n\u001b[0;32m    314\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m training_step_output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m    316\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[0;32m    318\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_result_cls\u001b[39m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[39m.\u001b[39maccumulate_grad_batches)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:294\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 294\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    296\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    297\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:380\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[0;32m    379\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[1;32m--> 380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 34\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=203'>204</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=204'>205</a>\u001b[0m     src, tgt \u001b[39m=\u001b[39m batch\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=205'>206</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(batch)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=206'>207</a>\u001b[0m     loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)(output\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, output\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)), tgt\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=207'>208</a>\u001b[0m     TP_losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassic_forward(batch)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(batch[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(batch)\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 34\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=255'>256</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(length \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m ):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=256'>257</a>\u001b[0m     tgt_embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtgt_embedding(out)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoding(length,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=257'>258</a>\u001b[0m     decode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_decoder(tgt_embedded, encode)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=258'>259</a>\u001b[0m     output[:,i]\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(decode)[:,i]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=259'>260</a>\u001b[0m     prob \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(output , dim \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, encoder_output):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m         x \u001b[39m=\u001b[39m layer(x, encoder_output)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attention(x, x, x, x, mask\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m out1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attn_output))\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcross_attention(out1, encoder_output,encoder_output, out1)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m out2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm2(out1 \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attn_output))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m ff_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeedforward(out2)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 34\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_heads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_v(v))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_heads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_r(r))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m att \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49matt_score(q, k, v, mask)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_o(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_heads(att\u001b[39m*\u001b[39mr))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 34\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mif\u001b[39;00m mask: attn_scores\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_mask(attn_scores)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m attn_probs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(attn_scores, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(attn_probs, v)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X46sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
            "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 11.99 GiB total capacity; 17.60 GiB already allocated; 0 bytes free; 17.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pytorch_lightning as pl\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TPMultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, dropout=0.1):\n",
        "        super(TPMultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim*num_heads)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim*num_heads)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim*num_heads)\n",
        "        self.W_r = nn.Linear(self.emb_dim, self.emb_dim*num_heads)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v,r, mask=False):\n",
        "        q = self.split_heads(self.W_q(q))\n",
        "        k = self.split_heads(self.W_k(k))\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "        r = self.split_heads(self.W_r(r))\n",
        "\n",
        "        att = self.att_score(q, k, v, mask)\n",
        "        out = self.W_o(self.combine_heads(att*r))\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v, mask):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        if mask: attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.emb_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return torch.sum(x, dim = 1)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "        mask = torch.triu(torch.full((tensor.shape[2], tensor.shape[3]), float(\"-inf\"), device=device), diagonal=1)\n",
        "        tensor = tensor + mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "class TPEncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x,x)\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPEncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TPDecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x, x, mask=True)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output,encoder_output, out1)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(out2)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class TPDecoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPDecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class TPTransformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=256, dropout=0.1, teacher_forcing_ratio = 0.9):\n",
        "        super(TPTransformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.tgt_vocab_size=tgt_vocab_size\n",
        "\n",
        "        self.transformer_encoder = TPEncoder(self.d_model,self.num_heads)\n",
        "        self.transformer_decoder = TPDecoder(self.d_model, self.num_heads)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        if self.training:\n",
        "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
        "            if teacher_force:\n",
        "                return self.classic_forward(batch)\n",
        "            else:\n",
        "                return self.predict(batch[0])\n",
        "        return self.predict(batch)\n",
        "\n",
        "\n",
        "    def classic_forward(self,batch):\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        tgt = torch.cat((torch.ones((batch_size,1), dtype=torch.int).to(device), tgt[:, :-1]), dim = 1)\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to(device)\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        TP_losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        pred = self(batch_q)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        TP_acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self, x):\n",
        "        length=x.shape[1]\n",
        "        src_embedded = self.src_embedding(x).to(device)+self.positional_encoding(length,self.d_model).to(device)\n",
        "        encode = self.transformer_encoder(src_embedded)\n",
        "        batch_dim = x.shape[0]\n",
        "        out = torch.zeros((batch_dim, length), dtype = torch.int).to(device)\n",
        "        out[:,0] = 1\n",
        "        output=torch.zeros(batch_dim,length,self.tgt_vocab_size).to(device)\n",
        "        for i in range(length - 2 ):\n",
        "            tgt_embedded = self.tgt_embedding(out)+self.positional_encoding(length,self.d_model).to(device)\n",
        "            decode = self.transformer_decoder(tgt_embedded, encode)\n",
        "            output[:,i]+=self.fc(decode)[:,i]\n",
        "            prob = F.softmax(output , dim = -1)\n",
        "            arg_max = torch.argmax(prob, dim = -1)\n",
        "            out[:, i+1] = arg_max[:,i]\n",
        "        return self.classic_forward((x,out))\n",
        "\n",
        "\n",
        "TP_acc=[]\n",
        "TP_losses=[]\n",
        "TP_voc_len=len(tokenizer.vocab)\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "TP_t=TPTransformer(TP_voc_len,TP_voc_len, d_model = 512)\n",
        "TP_t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "train_dataset = Dataset(qtp,atp)\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "TP_trainer = pl.Trainer(max_epochs=5)  # Modifica il numero di epoche come desiderato\n",
        "TP_trainer.fit(TP_t, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cpu\n",
            "miaosaaaa\n",
            "snarps\n",
            "snarps\n",
            "snarps\n",
            "snarps\n",
            "miaos\n",
            "torch.Size([1, 8, 22, 512])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "shape '[1, 22, 512]' is invalid for input of size 90112",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(TP_t\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m TP_t\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pred \u001b[39m=\u001b[39m TP_t\u001b[39m.\u001b[39;49mpredict(q\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m c \u001b[39m=\u001b[39m translate_from_output(pred\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m), tokenizer\u001b[39m.\u001b[39mvocab)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m d \u001b[39m=\u001b[39m translate(a\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m), tokenizer\u001b[39m.\u001b[39mvocab)\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=253'>254</a>\u001b[0m length\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=254'>255</a>\u001b[0m src_embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_embedding(x)\u001b[39m.\u001b[39mto(device)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoding(length,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=255'>256</a>\u001b[0m encode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(src_embedded)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=256'>257</a>\u001b[0m batch_dim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=257'>258</a>\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((batch_dim, length), dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mint)\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m         x \u001b[39m=\u001b[39m layer(x)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m     att \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultihead_attention(x,x,x,x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     add_nor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(att))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     ff_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeedforward(add_nor)\n",
            "File \u001b[1;32mc:\\Users\\nicol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmiaos\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m att \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matt_score(q, k, v, mask)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_o(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_heads(att\u001b[39m*\u001b[39;49mr))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "\u001b[1;32mc:\\Users\\nicol\\Documents\\UNI\\IA&R\\DL\\DL_Project\\DL_Funzionante.ipynb Cell 36\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m batch_size, _, seq_length, head_dim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicol/Documents/UNI/IA%26R/DL/DL_Project/DL_Funzionante.ipynb#X50sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mcontiguous()\u001b[39m.\u001b[39;49mview(batch_size, seq_length, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49memb_dim)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 22, 512]' is invalid for input of size 90112"
          ]
        }
      ],
      "source": [
        "i = 30000\n",
        "q,a= train_dataset[i]\n",
        "length = q.shape[0]\n",
        "print(q.device)\n",
        "print(TP_t.device)\n",
        "\n",
        "TP_t.to(device)\n",
        "\n",
        "pred = TP_t.predict(q.unsqueeze(0).to(device))\n",
        "c = translate_from_output(pred.squeeze(0), tokenizer.vocab)\n",
        "d = translate(a.squeeze(0), tokenizer.vocab)\n",
        "print(pred)\n",
        "print(translate(q,tokenizer.vocab))\n",
        "print(translate(a,tokenizer.vocab))\n",
        "print(\"trad 1: \", translate_from_output(pred.squeeze(0),tokenizer.vocab))\n",
        "g = a"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0372a03fa56d41e38394bd23ecaf4773": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03fd8d6afed2456a957c2abe1405a393": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63128e7a84cc47548fdbb1e5753e804b",
            "max": 10417,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d249d8dcc954c3ca313542bf2b23dba",
            "value": 20
          }
        },
        "0888cbc52e94409aa68dd5a3f7d464e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfd45da3235745ab992fe3bc37cd9503",
            "placeholder": "​",
            "style": "IPY_MODEL_c06eecbf5c54487f91e5b5c1af54a24e",
            "value": "Testing DataLoader 0:   0%"
          }
        },
        "0a71224e0bfd4472a9a5c3d09f2dabd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d51fec1aa8d4ab18971e126fac13830",
            "placeholder": "​",
            "style": "IPY_MODEL_0372a03fa56d41e38394bd23ecaf4773",
            "value": " 20/10417 [00:22&lt;3:11:03,  1.10s/it]"
          }
        },
        "1d51fec1aa8d4ab18971e126fac13830": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dc3183b4dc84d859294926b223fba82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f595131716f4b1eb3cf548d56335e13",
              "IPY_MODEL_49f499f06f9a4780a38dfdddf620e554",
              "IPY_MODEL_ce65c4628d1a4f119f682689895b841d"
            ],
            "layout": "IPY_MODEL_e1eeeb388a654b7980e949a15af7fdd2"
          }
        },
        "2f595131716f4b1eb3cf548d56335e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc633476ed604b9a880d7fae72c46381",
            "placeholder": "​",
            "style": "IPY_MODEL_3e238527a8ff4bfcbf82f25c0113dca7",
            "value": "Epoch 0:   0%"
          }
        },
        "3e238527a8ff4bfcbf82f25c0113dca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ac176968784ba399d25d5102042a26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f499f06f9a4780a38dfdddf620e554": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45ac176968784ba399d25d5102042a26",
            "max": 20834,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cd69df7e9604fb0b75d52e43dca8182",
            "value": 80
          }
        },
        "4ef4f16fa5cd4915931d80df674bce44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5cd69df7e9604fb0b75d52e43dca8182": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63128e7a84cc47548fdbb1e5753e804b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ac68976cde4f00854d598835ad3c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d249d8dcc954c3ca313542bf2b23dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d9a39813ecb41f697ffbfed9be5ca24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0888cbc52e94409aa68dd5a3f7d464e7",
              "IPY_MODEL_03fd8d6afed2456a957c2abe1405a393",
              "IPY_MODEL_0a71224e0bfd4472a9a5c3d09f2dabd7"
            ],
            "layout": "IPY_MODEL_4ef4f16fa5cd4915931d80df674bce44"
          }
        },
        "c06eecbf5c54487f91e5b5c1af54a24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cab18985f07141e894356c396a60db5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce65c4628d1a4f119f682689895b841d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab18985f07141e894356c396a60db5c",
            "placeholder": "​",
            "style": "IPY_MODEL_77ac68976cde4f00854d598835ad3c2e",
            "value": " 80/20834 [00:19&lt;1:23:44,  4.13it/s, v_num=4]"
          }
        },
        "dfd45da3235745ab992fe3bc37cd9503": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1eeeb388a654b7980e949a15af7fdd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "fc633476ed604b9a880d7fae72c46381": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

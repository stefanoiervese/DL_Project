{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "LhA0vWrGv07c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_lightning --quiet"
      ],
      "metadata": {
        "id": "UxDq5zBwwBHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f5dd44-8a2b-4066-83b0-ea246cb7b709"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/727.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/727.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/763.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.4/763.4 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r DL_Project\n",
        "!git clone https://github.com/stefanoiervese/DL_Project\n",
        "%cd DL_Project\n",
        "!unzip Arithmetic.zip -d arithmetic_directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yqlBgIcwOvz",
        "outputId": "5c3619a7-9363-4105-9fe5-150b383d39c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'DL_Project': No such file or directory\n",
            "Cloning into 'DL_Project'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 75 (delta 30), reused 7 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (75/75), 39.89 MiB | 11.72 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n",
            "/content/DL_Project\n",
            "Archive:  Arithmetic.zip\n",
            "  inflating: arithmetic_directory/Arithmetic/arithmetic__add_or_sub.txt  \n",
            "  inflating: arithmetic_directory/Arithmetic/arithmetic__div.txt  \n",
            "  inflating: arithmetic_directory/Arithmetic/arithmetic__mul.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pack_sequence, pad_sequence\n"
      ],
      "metadata": {
        "id": "OL3QjmM-wXqS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities"
      ],
      "metadata": {
        "id": "xUYWE4La3O8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self,sentences):\n",
        "        self.sentences=sentences\n",
        "        self.vocab = self.crea_vocabolario(sentences)\n",
        "        self.word_to_id = {word: idx for idx, word in enumerate(self.vocab)}\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        txt = re.sub(r'(\\d+)', lambda x: ' '.join(list(x.group(1))), text)\n",
        "        tokens = re.findall(r'\\b\\w+\\b|\\d+|[^\\w\\s]', txt)\n",
        "\n",
        "\n",
        "\n",
        "        token_id = []\n",
        "        unknown_tokens = []\n",
        "\n",
        "        new_tokens = []\n",
        "        for token in tokens:\n",
        "          flag=0\n",
        "          if '.' in token and token != '.':\n",
        "            token=token=token.split('.')[0]\n",
        "            flag=1\n",
        "          if token in self.word_to_id:\n",
        "            token_id.append(self.word_to_id[token])\n",
        "          else:\n",
        "                token_id.append(self.word_to_id['unknown'])\n",
        "                unknown_tokens.append(token)\n",
        "          if(flag==1):\n",
        "            token_id.append(self.word_to_id['.'])\n",
        "\n",
        "\n",
        "        if unknown_tokens:\n",
        "\n",
        "          print(\"Parole sconosciute:\", unknown_tokens)\n",
        "\n",
        "        return token_id\n",
        "\n",
        "    def crea_vocabolario(self, frasi):\n",
        "      vocabolario = set()\n",
        "\n",
        "      for frase in frasi:\n",
        "        txt = re.sub(r'(\\d+)', lambda x: ' '.join(list(x.group(1))), frase.lower())\n",
        "        parole = re.findall(r'\\b\\w+\\b|\\d+|[^\\w\\s]', txt)\n",
        "        vocabolario.update(parole)\n",
        "      return ['&','#','@','unknown']+list(vocabolario)\n",
        "\n",
        "def paper_accuracy(predicted_answers, correct_answers):\n",
        "  num_correct_answers = 0\n",
        "  end_of_line=2\n",
        "\n",
        "  for i in range(len(predicted_answers)):\n",
        "\n",
        "    single_predicted_answer = torch.argmax(predicted_answers[i], 1).tolist()  # vector of shape (answer_max_length) (concatenates the max value for each row)\n",
        "    index = single_predicted_answer.index(2) if 2 in single_predicted_answer else len(single_predicted_answer) -1\n",
        "    single_predicted_answer = single_predicted_answer[1:index]  # removing start and end of line char and additional characters\n",
        "    single_correct_answer = correct_answers[i].tolist()\n",
        "    single_correct_answer = single_correct_answer[1:single_correct_answer.index(2)]  # removing start of line, end of line and following characters\n",
        "\n",
        "    if (single_predicted_answer == single_correct_answer):\n",
        "      num_correct_answers += 1\n",
        "\n",
        "  return num_correct_answers/len(predicted_answers)\n",
        "\n",
        "\n",
        "def translate(phrase, vocab):\n",
        "    text = \"\"\n",
        "    for element in phrase:\n",
        "        text += vocab[element.item()]\n",
        "    return text\n",
        "def translate_from_output(phrase, vocab):\n",
        "    phrase = torch.argmax(F.softmax(phrase , dim = -1), dim = -1)\n",
        "    text = \"\"\n",
        "    for element in phrase:\n",
        "        text += vocab[element.item()]\n",
        "    return text\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vja0OFLp3XVz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNDAFYDRiQNg"
      },
      "source": [
        "# Dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='./arithmetic_directory/Arithmetic/'\n",
        "data_list=[]\n",
        "for file in os.listdir(path):\n",
        "\n",
        "  with open(path+file, \"r\") as file:\n",
        "    content = file.read()\n",
        "    data_list=data_list+[x for x in content.split('\\n')]\n",
        "\n",
        "while '' in data_list:\n",
        "    data_list.remove('')\n",
        "\n",
        "len_data=len(data_list)\n",
        "quest=[]\n",
        "ans=[]\n",
        "for i in range(len_data):\n",
        "  if(i%2==0):\n",
        "    quest.append(data_list[i])\n",
        "  else:\n",
        "    data= data_list[i] + \" @\"\n",
        "    ans.append(data)\n",
        "coppie = list(zip(quest,ans))\n",
        "random.shuffle(coppie)\n",
        "quest, ans=zip(*coppie)\n",
        "l=int(len(quest)/3)\n",
        "train_q=quest[:2*l]\n",
        "test_q=quest[2*l:]\n",
        "train_a=ans[:2*l]\n",
        "test_a=ans[2*l:]\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(data_list)\n",
        "\n",
        "qt=[]\n",
        "at=[]\n",
        "for x in train_q:\n",
        "  qt.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "for x in train_a:\n",
        "  at.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "\n",
        "qtest=[]\n",
        "atest=[]\n",
        "for x in test_q:\n",
        "  qtest.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "for x in test_a:\n",
        "  atest.append(torch.tensor(tokenizer.tokenize(x.lower())))"
      ],
      "metadata": {
        "id": "dpME3bhqwAuZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_to_id"
      ],
      "metadata": {
        "id": "0pd-ggpk-Ilf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c534f4-c79f-4f60-8bc0-ec528e447f54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'&': 0,\n",
              " '#': 1,\n",
              " '@': 2,\n",
              " 'unknown': 3,\n",
              " '-': 4,\n",
              " '7': 5,\n",
              " 'calculate': 6,\n",
              " 'add': 7,\n",
              " '8': 8,\n",
              " '+': 9,\n",
              " 'what': 10,\n",
              " 'plus': 11,\n",
              " 'of': 12,\n",
              " 'multiply': 13,\n",
              " '*': 14,\n",
              " '0': 15,\n",
              " 'sum': 16,\n",
              " '.': 17,\n",
              " '5': 18,\n",
              " 'distance': 19,\n",
              " '/': 20,\n",
              " '3': 21,\n",
              " 'between': 22,\n",
              " 'put': 23,\n",
              " 'subtract': 24,\n",
              " 'work': 25,\n",
              " 'than': 26,\n",
              " '2': 27,\n",
              " '6': 28,\n",
              " 'total': 29,\n",
              " '9': 30,\n",
              " 'difference': 31,\n",
              " 'minus': 32,\n",
              " 'take': 33,\n",
              " '1': 34,\n",
              " 'times': 35,\n",
              " 'and': 36,\n",
              " 'divided': 37,\n",
              " 'out': 38,\n",
              " 'the': 39,\n",
              " '4': 40,\n",
              " 'away': 41,\n",
              " 'product': 42,\n",
              " 'by': 43,\n",
              " '?': 44,\n",
              " 'is': 45,\n",
              " 'divide': 46,\n",
              " 'from': 47,\n",
              " 'less': 48,\n",
              " 'together': 49}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tcep7jbFtFw_"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, questions, answers):\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.questions[idx], self.answers[idx]\n",
        "\n",
        "\n",
        "max_length1 = max(len(tensor) for tensor in qt)\n",
        "max_length2 = max(len(tensor) for tensor in at)\n",
        "max_length=max(max_length1,max_length2)\n",
        "\n",
        "qtp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in qt], batch_first=True)\n",
        "atp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in at], batch_first=True)\n",
        "\n",
        "\n",
        "max_length1 = max(len(tensor) for tensor in qtest)\n",
        "max_length2 = max(len(tensor) for tensor in atest)\n",
        "max_length=max(max_length1,max_length2)\n",
        "qtestp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in qtest], batch_first=True)\n",
        "atestp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in atest], batch_first=True)\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = Dataset(qtp,atp)\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "test_dataset = Dataset(qtestp,atestp)\n",
        "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSUfm1fqiGVp"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hnvuAfhEqLBN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "91264fa0-92f2-47ec-8685-5b5f620f2b12"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-5af7877989e0>\"\u001b[0;36m, line \u001b[0;32m114\u001b[0m\n\u001b[0;31m    self.self_attention = MultiHeadAttention(emb_dim, num_heads device = device)\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pytorch_lightning as pl\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, device = \"cpu\",dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.device = device\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v, mask=False):\n",
        "        q = self.split_heads(self.W_q(q))  #64,2,22,2\n",
        "        k = self.split_heads(self.W_k(k))  #64,2,2,22\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "\n",
        "\n",
        "        att = self.att_score(q, k, v, mask)  #62,2,22,22\n",
        "        out = self.W_o(self.combine_heads(att))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v, mask):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        if mask:\n",
        "          attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.emb_dim)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "        mask = torch.triu(torch.full((tensor.shape[2], tensor.shape[3]), float(\"-inf\"), device=self.device), diagonal=1)\n",
        "        tensor = tensor + mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "\n",
        "class EncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, device = \"cpu\", feedforward_dim=32, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.multihead_attention = MultiHeadAttention(emb_dim, num_heads, device = device)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x)\n",
        "\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, device = \"cpu\", num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(emb_dim, num_heads, feedforward_dim, dropout, device = device)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, device = \"cpu\", feedforward_dim=32, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.device = device\n",
        "        self.self_attention = MultiHeadAttention(emb_dim, num_heads device = device)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = MultiHeadAttention(emb_dim, num_heads, device = device)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x, mask=True)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output, encoder_output)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(out2)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class Decoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "class Transformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, device = \"cpu\", d_model=512, num_heads=8, num_layers=6, d_ff=256, dropout=0.1, teacher_forcing_ratio = 0.2):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.device = device\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.tgt_vocab_size=tgt_vocab_size\n",
        "\n",
        "        self.transformer_encoder = Encoder(self.d_model,self.num_heads, device = device)\n",
        "        self.transformer_decoder = Decoder(self.d_model,self.num_heads, device = device)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        if self.training:\n",
        "          teacher_force = random.random() < self.teacher_forcing_ratio\n",
        "\n",
        "          if teacher_force:\n",
        "            return self.classic_forward(batch)\n",
        "          else:\n",
        "            return self.predict(batch[0])[1]\n",
        "\n",
        "        print(\"Siamo in fase di test\")\n",
        "        return self.predict(batch[0])\n",
        "\n",
        "    def classic_forward(self,batch):\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        tgt = torch.cat((torch.ones((batch_size,1), dtype=torch.int).to(device), tgt[:, :-1]), dim = 1)\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        _, pred = self.predict(batch_q)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self, x):\n",
        "        length=x.shape[1]\n",
        "        src_embedded = self.src_embedding(x).to(device)+self.positional_encoding(length,self.d_model).to(device)\n",
        "        encode = self.transformer_encoder(src_embedded)\n",
        "        batch_dim = x.shape[0]\n",
        "        out = torch.zeros((batch_dim, length), dtype = torch.int).to(device)\n",
        "        out[:,0] = 1\n",
        "        output=torch.zeros(batch_dim,length,self.tgt_vocab_size).to(device)\n",
        "        for i in range(length -1 ):\n",
        "            tgt_embedded = self.tgt_embedding(out)+self.positional_encoding(length,self.d_model).to(device)\n",
        "            decode = self.transformer_decoder(tgt_embedded, encode)\n",
        "            output[:,i]+=self.fc(decode)[:,i]\n",
        "            prob = F.softmax(output , dim = -1)\n",
        "            arg_max = torch.argmax(prob, dim = -1)\n",
        "            out[:, i+1] = arg_max[:,i]\n",
        "        return out, output\n",
        "\n",
        "\n",
        "\n",
        "acc=[]\n",
        "losses=[]\n",
        "voc_len=len(tokenizer.vocab)\n",
        "t=Transformer(voc_len,voc_len)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=1)  # Modifica il numero di epoche come desiderato\n",
        "trainer.fit(t, train_loader)\n",
        "\n",
        "\n",
        "#model_path='/content/drive/MyDrive/mathematics_dataset-v1.0/model'\n",
        "\n",
        "\n",
        "#torch.save(t.state_dict(), model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(acc)/len(acc)"
      ],
      "metadata": {
        "id": "faI6lBC0-vk0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "a18977c8-2721-4d0c-bad9-cad396affacf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7e0a4b466b2e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.device)"
      ],
      "metadata": {
        "id": "8EgEu3RicFiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpG2sQjR5SlI"
      },
      "outputs": [],
      "source": [
        "model_path='./model.pth'\n",
        "torch.save(t.state_dict(), model_path)\n",
        "trainer.test(t,test_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(t,test_loader)"
      ],
      "metadata": {
        "id": "_4Heqj0VVXF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "04kw6SPmZ0CK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab[0]\n",
        "type(tokenizer.vocab)\n",
        "print(tokenizer.vocab)"
      ],
      "metadata": {
        "id": "MDC_FIgFiibr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 4\n",
        "q,a= train_dataset[i]\n",
        "length = q.shape[0]\n",
        "print(q.device)\n",
        "print(t.device)\n",
        "print(device)\n",
        "t.to(device)\n",
        "pred, output = t.predict(q.unsqueeze(0).to(device))\n",
        "print(\"#àààààààààààààààààààààààààààààààààààààààààààààà\")\n",
        "c = translate(pred.squeeze(0), tokenizer.vocab)\n",
        "d = translate(a.squeeze(0), tokenizer.vocab)\n",
        "print(pred)\n",
        "print(translate(q,tokenizer.vocab))\n",
        "print(translate(a,tokenizer.vocab))\n",
        "print(\"trad 1: \", translate(pred.squeeze(0),tokenizer.vocab))\n",
        "print(\"traduziones: \", translate_from_output(output.squeeze(0),tokenizer.vocab))\n",
        "g = a"
      ],
      "metadata": {
        "id": "ETyytmPMZhxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(acc)/len(acc)"
      ],
      "metadata": {
        "id": "3shG2RuoVpO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g77qbpYn07y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(t.state_dict(), 'trainato')"
      ],
      "metadata": {
        "id": "JDHGggG4y-A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.load_state_dict(torch.load('/content/drive/MyDrive/modellino.pth'))"
      ],
      "metadata": {
        "id": "MXQI9fjOmLLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RaXOrj_8KHy"
      },
      "source": [
        "# TP-Transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TPMultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, device = \"cpu\", dropout=0.1):\n",
        "        super(TPMultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "        self.device = device\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_r = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v,r, mask=False):\n",
        "        q = self.split_heads(self.W_q(q))\n",
        "        k = self.split_heads(self.W_k(k))\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "        r = self.split_heads(self.W_r(r))\n",
        "\n",
        "\n",
        "        att = self.att_score(q, k, v, mask)\n",
        "\n",
        "\n",
        "        out = self.W_o(self.combine_heads(att*r))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v, mask):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "\n",
        "        if mask: attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.emb_dim)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "        mask = torch.triu(torch.full((tensor.shape[2], tensor.shape[3]), float(\"-inf\"), device=self.device), diagonal=1)\n",
        "        tensor = tensor + mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, device = \"cpu\", feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = TPMultiHeadAttention(emb_dim, num_heads, device = device)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x,x)\n",
        "\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPEncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TPDecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, device = \"cpu\", feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = MultiHeadAttention(emb_dim, num_heads, device = device)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = MultiHeadAttention(emb_dim, num_heads, device = device)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x, x, mask=True)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output,encoder_output, encoder_output)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(out2)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class TPDecoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, device = \"cpu\", num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPDecoderLayer(emb_dim, num_heads, feedforward_dim, dropout, device = device)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class TPTransformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, device = \"cpu\", d_model=512, num_heads=8, num_layers=6, d_ff=256, dropout=0.1, teacher_forcing_ratio = 0.2):\n",
        "        super(TPTransformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.device = device\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.tgt_vocab_size=tgt_vocab_size\n",
        "\n",
        "        self.transformer_encoder = Encoder(self.d_model,self.num_heads, device = device)\n",
        "        self.transformer_decoder =Decoder(self.d_model, self.num_heads, device = device)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "\n",
        "        if self.training:\n",
        "          self.log('trainandosps')\n",
        "          teacher_force = random.random() < self.teacher_forcing_ratio\n",
        "\n",
        "          if teacher_force:\n",
        "            return self.classic_forward(batch)\n",
        "          else:\n",
        "            return self.predict(batch[0])[1]\n",
        "        self.log('testz')\n",
        "        return self.predict(batch[0])\n",
        "\n",
        "\n",
        "    def classic_forward(self,batch):\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        tgt = torch.cat((torch.ones((batch_size,1), dtype=torch.int).to(device), tgt[:, :-1]), dim = 1)\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        _, pred = self.predict(batch_q)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self, x):\n",
        "        length=x.shape[1]\n",
        "        src_embedded = self.src_embedding(x).to(device)+self.positional_encoding(length,self.d_model).to(device)\n",
        "        encode = self.transformer_encoder(src_embedded)\n",
        "        batch_dim = x.shape[0]\n",
        "        out = torch.zeros((batch_dim, length), dtype = torch.int).to(device)\n",
        "        out[:,0] = 1\n",
        "        output=torch.zeros(batch_dim,length,self.tgt_vocab_size).to(device)\n",
        "        for i in range(length -1 ):\n",
        "            tgt_embedded = self.tgt_embedding(out)+self.positional_encoding(length,self.d_model).to(device)\n",
        "            decode = self.transformer_decoder(tgt_embedded, encode)\n",
        "            output[:,i]+=self.fc(decode)[:,i]\n",
        "            prob = F.softmax(output , dim = -1)\n",
        "            arg_max = torch.argmax(prob, dim = -1)\n",
        "            out[:, i+1] = arg_max[:,i]\n",
        "        return out, output\n",
        "\n",
        "\n",
        "acc=[]\n",
        "losses=[]\n",
        "voc_len=len(tokenizer.vocab)\n",
        "t=Transformer(voc_len,voc_len, d_model = 1024)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=3)  # Modifica il numero di epoche come desiderato\n",
        "trainer.fit(t, train_loader)\n",
        "\n",
        "\n",
        "#model_path='/content/drive/MyDrive/mathematics_dataset-v1.0/model'\n",
        "\n",
        "\n",
        "#torch.save(t.state_dict(), model_path)\n"
      ],
      "metadata": {
        "id": "24TtpczCL-Zk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "2dc3183b4dc84d859294926b223fba82",
            "2f595131716f4b1eb3cf548d56335e13",
            "49f499f06f9a4780a38dfdddf620e554",
            "ce65c4628d1a4f119f682689895b841d",
            "e1eeeb388a654b7980e949a15af7fdd2",
            "fc633476ed604b9a880d7fae72c46381",
            "3e238527a8ff4bfcbf82f25c0113dca7",
            "45ac176968784ba399d25d5102042a26",
            "5cd69df7e9604fb0b75d52e43dca8182",
            "cab18985f07141e894356c396a60db5c",
            "77ac68976cde4f00854d598835ad3c2e"
          ]
        },
        "outputId": "42bcbb85-276c-4fe0-916b-c57e3afe461c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 51.2 K\n",
            "1 | tgt_embedding       | Embedding | 51.2 K\n",
            "2 | transformer_encoder | Encoder   | 25.6 M\n",
            "3 | transformer_decoder | Decoder   | 50.8 M\n",
            "4 | fc                  | Linear    | 51.2 K\n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "76.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "76.6 M    Total params\n",
            "306.342   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dc3183b4dc84d859294926b223fba82"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "oEgVeGWtAdXm",
        "outputId": "5eec79ad-056b-467e-c4bc-732fafc333df"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(t,test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "7d9a39813ecb41f697ffbfed9be5ca24",
            "0888cbc52e94409aa68dd5a3f7d464e7",
            "03fd8d6afed2456a957c2abe1405a393",
            "0a71224e0bfd4472a9a5c3d09f2dabd7",
            "4ef4f16fa5cd4915931d80df674bce44",
            "dfd45da3235745ab992fe3bc37cd9503",
            "c06eecbf5c54487f91e5b5c1af54a24e",
            "63128e7a84cc47548fdbb1e5753e804b",
            "7d249d8dcc954c3ca313542bf2b23dba",
            "1d51fec1aa8d4ab18971e126fac13830",
            "0372a03fa56d41e38394bd23ecaf4773"
          ]
        },
        "id": "BSvSVsf3BLjv",
        "outputId": "68c52ee5-b50b-4556-d3a2-1fc0f2f3044e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:490: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d9a39813ecb41f697ffbfed9be5ca24"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(acc)/len(acc)"
      ],
      "metadata": {
        "id": "3LFNGTGeEgLP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2dc3183b4dc84d859294926b223fba82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f595131716f4b1eb3cf548d56335e13",
              "IPY_MODEL_49f499f06f9a4780a38dfdddf620e554",
              "IPY_MODEL_ce65c4628d1a4f119f682689895b841d"
            ],
            "layout": "IPY_MODEL_e1eeeb388a654b7980e949a15af7fdd2"
          }
        },
        "2f595131716f4b1eb3cf548d56335e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc633476ed604b9a880d7fae72c46381",
            "placeholder": "​",
            "style": "IPY_MODEL_3e238527a8ff4bfcbf82f25c0113dca7",
            "value": "Epoch 0:   0%"
          }
        },
        "49f499f06f9a4780a38dfdddf620e554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45ac176968784ba399d25d5102042a26",
            "max": 20834,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cd69df7e9604fb0b75d52e43dca8182",
            "value": 80
          }
        },
        "ce65c4628d1a4f119f682689895b841d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab18985f07141e894356c396a60db5c",
            "placeholder": "​",
            "style": "IPY_MODEL_77ac68976cde4f00854d598835ad3c2e",
            "value": " 80/20834 [00:19&lt;1:23:44,  4.13it/s, v_num=4]"
          }
        },
        "e1eeeb388a654b7980e949a15af7fdd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "fc633476ed604b9a880d7fae72c46381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e238527a8ff4bfcbf82f25c0113dca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ac176968784ba399d25d5102042a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd69df7e9604fb0b75d52e43dca8182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cab18985f07141e894356c396a60db5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ac68976cde4f00854d598835ad3c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d9a39813ecb41f697ffbfed9be5ca24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0888cbc52e94409aa68dd5a3f7d464e7",
              "IPY_MODEL_03fd8d6afed2456a957c2abe1405a393",
              "IPY_MODEL_0a71224e0bfd4472a9a5c3d09f2dabd7"
            ],
            "layout": "IPY_MODEL_4ef4f16fa5cd4915931d80df674bce44"
          }
        },
        "0888cbc52e94409aa68dd5a3f7d464e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfd45da3235745ab992fe3bc37cd9503",
            "placeholder": "​",
            "style": "IPY_MODEL_c06eecbf5c54487f91e5b5c1af54a24e",
            "value": "Testing DataLoader 0:   0%"
          }
        },
        "03fd8d6afed2456a957c2abe1405a393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63128e7a84cc47548fdbb1e5753e804b",
            "max": 10417,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d249d8dcc954c3ca313542bf2b23dba",
            "value": 20
          }
        },
        "0a71224e0bfd4472a9a5c3d09f2dabd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d51fec1aa8d4ab18971e126fac13830",
            "placeholder": "​",
            "style": "IPY_MODEL_0372a03fa56d41e38394bd23ecaf4773",
            "value": " 20/10417 [00:22&lt;3:11:03,  1.10s/it]"
          }
        },
        "4ef4f16fa5cd4915931d80df674bce44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "dfd45da3235745ab992fe3bc37cd9503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c06eecbf5c54487f91e5b5c1af54a24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63128e7a84cc47548fdbb1e5753e804b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d249d8dcc954c3ca313542bf2b23dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d51fec1aa8d4ab18971e126fac13830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0372a03fa56d41e38394bd23ecaf4773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
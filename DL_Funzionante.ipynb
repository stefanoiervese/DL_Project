{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanoiervese/DL_Project/blob/main/DL_Funzionante.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "LhA0vWrGv07c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_lightning --quiet"
      ],
      "metadata": {
        "id": "UxDq5zBwwBHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78317c88-ef5b-42dc-eda9-a3e3ff1efe63"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.4/763.4 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r DL_Project\n",
        "!git clone https://github.com/stefanoiervese/DL_Project\n",
        "%cd DL_Project\n",
        "!unzip Arithmetic.zip -d arithmetic_directory\n",
        "!unzip Arithmetic_extrapolate.zip -d extrapolate\n",
        "!unzip Arithmetic_interpolate.zip -d extrapolate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yqlBgIcwOvz",
        "outputId": "64f62243-33b9-4797-e7bf-79c3ed8a1810"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'DL_Project': No such file or directory\n",
            "Cloning into 'DL_Project'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 94 (delta 39), reused 6 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (94/94), 39.96 MiB | 13.47 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "/content/DL_Project\n",
            "Archive:  Arithmetic.zip\n",
            "  inflating: arithmetic_directory/Arithmetic/arithmetic__add_or_sub.txt  \n",
            "  inflating: arithmetic_directory/Arithmetic/arithmetic__div.txt  \n",
            "  inflating: arithmetic_directory/Arithmetic/arithmetic__mul.txt  \n",
            "Archive:  Arithmetic_extrapolate.zip\n",
            "  inflating: extrapolate/Arithmetic_extrapolate/arithmetic__div_big.txt  \n",
            "  inflating: extrapolate/Arithmetic_extrapolate/arithmetic__mul_big.txt  \n",
            "  inflating: extrapolate/Arithmetic_extrapolate/arithmetic__add_sub_multiple_longer.txt  \n",
            "  inflating: extrapolate/Arithmetic_extrapolate/arithmetic__add_or_sub_big.txt  \n",
            "Archive:  Arithmetic_interpolate.zip\n",
            "  inflating: extrapolate/Arithmetic_interpolate/arithmetic__add_sub_multiple.txt  \n",
            "  inflating: extrapolate/Arithmetic_interpolate/arithmetic__add_or_sub.txt  \n",
            "  inflating: extrapolate/Arithmetic_interpolate/arithmetic__div.txt  \n",
            "  inflating: extrapolate/Arithmetic_interpolate/arithmetic__mul.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pack_sequence, pad_sequence\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "OL3QjmM-wXqS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utilities"
      ],
      "metadata": {
        "id": "xUYWE4La3O8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, questions, answers):\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.questions[idx], self.answers[idx]\n",
        "\n",
        "class Tokenizer:\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.vocab = self.crea_vocabolario(sentences)\n",
        "        self.word_to_id = {word: idx for idx, word in enumerate(self.vocab)}\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        txt = re.sub(r'(\\d+)', lambda x: ' '.join(list(x.group(1))), text)\n",
        "        tokens = re.findall(r'\\b\\w+\\b|\\d+|[^\\w\\s]', txt)\n",
        "\n",
        "        token_id = []\n",
        "        unknown_tokens = []\n",
        "\n",
        "        new_tokens = []\n",
        "        for token in tokens:\n",
        "            flag = 0\n",
        "            if '.' in token and token != '.':\n",
        "                token = token.split('.')[0]\n",
        "                flag = 1\n",
        "            if token in self.word_to_id:\n",
        "                token_id.append(self.word_to_id[token])\n",
        "            else:\n",
        "                token_id.append(self.word_to_id['unknown'])\n",
        "                unknown_tokens.append(token)\n",
        "            if flag == 1:\n",
        "                token_id.append(self.word_to_id['.'])\n",
        "\n",
        "        if unknown_tokens:\n",
        "            print(\"Parole sconosciute:\", unknown_tokens)\n",
        "\n",
        "        return token_id\n",
        "\n",
        "    def crea_vocabolario(self, frasi):\n",
        "        vocabolario = set()\n",
        "\n",
        "        for frase in frasi:\n",
        "            txt = re.sub(r'(\\d+)', lambda x: ' '.join(list(x.group(1))), frase.lower())\n",
        "            parole = re.findall(r'\\b\\w+\\b|\\d+|[^\\w\\s]', txt)\n",
        "            vocabolario.update(parole)\n",
        "        return ['&', '#', '@', 'unknown'] + list(vocabolario)\n",
        "\n",
        "    def tokenize_q_and_a(self, questions, answers):\n",
        "        q = []\n",
        "        a = []\n",
        "        for x in questions:\n",
        "            q.append(torch.tensor(self.tokenize(x.lower())))\n",
        "        for x in answers:\n",
        "            a.append(torch.tensor(self.tokenize(x.lower())))\n",
        "        return q, a\n",
        "\n",
        "\n",
        "def build_dataset(data, q, a):\n",
        "    tokenizer = Tokenizer(data)\n",
        "    q, a = tokenizer.tokenize_q_and_a(q, a)\n",
        "    q, a = padding(q, a)\n",
        "    return q, a\n",
        "\n",
        "\n",
        "def load_dataset(path):\n",
        "    data = []\n",
        "    for file in os.listdir(path):\n",
        "        with open(path + file, \"r\") as file:\n",
        "            content = file.read()\n",
        "            data = data + [x for x in content.split('\\n')]\n",
        "    while '' in data:\n",
        "        data.remove('')\n",
        "    len_data = len(data)\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for i in range(len_data):\n",
        "        if(i % 2 == 0):\n",
        "            questions.append(data[i])\n",
        "        else:\n",
        "            dt = data[i] + \" @\"\n",
        "            answers.append(dt)\n",
        "    coppie = list(zip(questions, answers))\n",
        "    random.shuffle(coppie)\n",
        "    questions, answers = zip(*coppie)\n",
        "    return data, questions, answers\n",
        "\n",
        "\n",
        "def split_dataset(questions, answers):\n",
        "    l = int(len(questions) / 3)\n",
        "    train_q = questions[:2 * l]\n",
        "    test_q = questions[2 * l:]\n",
        "    train_a = answers[:2 * l]\n",
        "    test_a = answers[2 * l:]\n",
        "    return train_q, train_a, test_q, test_a\n",
        "\n",
        "\n",
        "def padding(questions, answers):\n",
        "    max_length1 = max(len(tensor) for tensor in questions)\n",
        "    max_length2 = max(len(tensor) for tensor in answers)\n",
        "    max_length = max(max_length1, max_length2)\n",
        "    q_padded = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor), dtype=torch.int)]) for tensor in questions], batch_first=True)\n",
        "    a_padded = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor), dtype=torch.int)]) for tensor in answers], batch_first=True)\n",
        "    return a_padded, q_padded\n",
        "\n",
        "\n",
        "def paper_accuracy(predicted_answers, correct_answers):\n",
        "  num_correct_answers = 0\n",
        "  end_of_line=2\n",
        "\n",
        "  for i in range(len(predicted_answers)):\n",
        "\n",
        "    single_predicted_answer = torch.argmax(predicted_answers[i], 1).tolist()  # vector of shape (answer_max_length) (concatenates the max value for each row)\n",
        "    index = single_predicted_answer.index(2) if 2 in single_predicted_answer else len(single_predicted_answer) -1\n",
        "    single_predicted_answer = single_predicted_answer[1:index]  # removing start and end of line char and additional characters\n",
        "    single_correct_answer = correct_answers[i].tolist()\n",
        "    single_correct_answer = single_correct_answer[1:index]  # removing start of line, end of line and following characters\n",
        "\n",
        "    if (single_predicted_answer == single_correct_answer):\n",
        "      num_correct_answers += 1\n",
        "\n",
        "  return num_correct_answers/len(predicted_answers)\n"
      ],
      "metadata": {
        "id": "226CpR9e2XHi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_train = './arithmetic_directory/Arithmetic/'\n",
        "path_inter = './extrapolate/Arithmetic_interpolate/'\n",
        "path_ext = './extrapolate/Arithmetic_extrapolate/'\n",
        "batch_size = 64\n",
        "\n",
        "data, q, a = load_dataset(path_train)\n",
        "q_train, a_train, q_test, a_test = split_dataset(q, a)\n",
        "q_train, a_train = build_dataset(data, q_train, a_train)\n",
        "q_test, a_test = build_dataset(data, q_test, a_test)\n",
        "\n",
        "data, q, a = load_dataset(path_inter)\n",
        "q_inter, a_inter = build_dataset(data, q, a)\n",
        "\n",
        "data, q, a = load_dataset(path_ext)\n",
        "q_ext, a_ext = build_dataset(data, q, a)\n",
        "\n",
        "train_dataset = Dataset(q_train, a_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = Dataset(q_test, a_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "inter_dataset = Dataset(q_inter, a_inter)\n",
        "inter_loader = DataLoader(inter_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "ext_dataset = Dataset(q_ext, a_ext)\n",
        "ext_loader = DataLoader(ext_dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "H2BlMVy13MiJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q,a=next(iter(train_loader))\n",
        "q.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkq7gM1ON-Nf",
        "outputId": "ace87cea-2988-430b-b7f6-4a1436a621b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSUfm1fqiGVp"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, q, a = load_dataset(path_train)\n",
        "tokenizer = Tokenizer(data)"
      ],
      "metadata": {
        "id": "-9XtAipcPrpY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads,dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v, mask=False):\n",
        "        q = self.split_heads(self.W_q(q))  #64,2,22,2\n",
        "        k = self.split_heads(self.W_k(k))  #64,2,2,22\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "\n",
        "\n",
        "        att = self.att_score(q, k, v, mask)  #62,2,22,22\n",
        "        out = self.W_o(self.combine_heads(att))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v, mask):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        if mask:\n",
        "          attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.emb_dim)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "        mask = torch.triu(torch.full((tensor.shape[2], tensor.shape[3]), float(\"-inf\"), device= device), diagonal=1)\n",
        "        tensor = tensor + mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "\n",
        "class EncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x)\n",
        "\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x, mask=True)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output, encoder_output)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(out2)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class Decoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "class Transformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=256, dropout=0.1, teacher_forcing_ratio = 0.9):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.tgt_vocab_size=tgt_vocab_size\n",
        "\n",
        "        self.transformer_encoder = Encoder(self.d_model,self.num_heads)\n",
        "        self.transformer_decoder = Decoder(self.d_model,self.num_heads)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        if self.training:\n",
        "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
        "            print(teacher_force)\n",
        "            if teacher_force:\n",
        "                return self.classic_forward(batch)\n",
        "            else:\n",
        "                return self.predict(batch[0])\n",
        "        return self.predict(batch)\n",
        "\n",
        "    def classic_forward(self,batch):\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        tgt = torch.cat((torch.ones((batch_size,1), dtype=torch.int).to(device), tgt[:, :-1]), dim = 1)\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        pred = self(batch_q)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self, x):\n",
        "        length=x.shape[1]\n",
        "        src_embedded = self.src_embedding(x).to(device)+self.positional_encoding(length,self.d_model).to(device)\n",
        "        encode = self.transformer_encoder(src_embedded)\n",
        "        batch_dim = x.shape[0]\n",
        "        out = torch.zeros((batch_dim, length), dtype = torch.int).to(device)\n",
        "        out[:,0] = 1\n",
        "        output=torch.zeros(batch_dim,length,self.tgt_vocab_size).to(device)\n",
        "        for i in range(length - 2 ):\n",
        "            tgt_embedded = self.tgt_embedding(out)+self.positional_encoding(length,self.d_model).to(device)\n",
        "            decode = self.transformer_decoder(tgt_embedded, encode)\n",
        "            output[:,i]+=self.fc(decode)[:,i]\n",
        "            prob = F.softmax(output , dim = -1)\n",
        "            arg_max = torch.argmax(prob, dim = -1)\n",
        "            out[:, i+1] = arg_max[:,i]\n",
        "        return self.classic_forward((x,out))\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "acc=[]\n",
        "losses=[]\n",
        "voc_len=len(tokenizer.vocab)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "t=Transformer(voc_len,voc_len)\n",
        "t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=1)  # Modifica il numero di epoche come desiderato\n",
        "trainer.fit(t, train_loader)\n",
        "\n",
        "\n",
        "#model_path='/content/drive/MyDrive/mathematics_dataset-v1.0/model'\n",
        "\n",
        "\n",
        "#torch.save(t.state_dict(), model_path)\n"
      ],
      "metadata": {
        "id": "mkh3oh-bUO9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "u1BzY3wRO0d9",
        "outputId": "579546a9-09bc-43a8-ece9-7633669a9141"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c6192513b713>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(acc)/len(acc)"
      ],
      "metadata": {
        "id": "faI6lBC0-vk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7638a6-3f37-4ab7-ae4a-7064eea48fcc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpG2sQjR5SlI"
      },
      "outputs": [],
      "source": [
        "model_path='./model.pth'\n",
        "#torch.save(t.state_dict(), model_path)\n",
        "trainer.test(t,test_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(t,test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "f8177684e95f4fb2ab3008c6b7e3cb4f",
            "9cfe35efec5543f0b22e9d4dcc80f0fe",
            "2c44875630e8443a8b99b16ba02d31ca",
            "5f78839c0fda45d3a6971392f77dbb6c",
            "f7cce7f19b5a47db9d56d68518f6bd73",
            "51e25c0450c349f5a7cfddaf0a3fb8f9",
            "fffc0849248b4e1e91b66e31cf2b9f96",
            "7a890ed9e4cb4649966d5eb8ea5c9f11",
            "bc0252b290bb4d72bd6ced345d2df52f",
            "55f29403c4c84732b17c392d1e9fb345",
            "7f2e473f297a4d729acd4174f97fa98e"
          ]
        },
        "id": "_4Heqj0VVXF6",
        "outputId": "6c7ec451-1494-4ae9-82ef-9f400d1ec0ec"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:490: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8177684e95f4fb2ab3008c6b7e3cb4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(phrase, vocab):\n",
        "    text = \"\"\n",
        "    for element in phrase:\n",
        "        text += vocab[element.item()]\n",
        "    return text\n",
        "def translate_from_output(phrase, vocab):\n",
        "    phrase = torch.argmax(F.softmax(phrase , dim = -1), dim = -1)\n",
        "    text = \"\"\n",
        "    for element in phrase:\n",
        "        text += vocab[element.item()]\n",
        "    return text"
      ],
      "metadata": {
        "id": "04kw6SPmZ0CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 4\n",
        "q,a= train_dataset[i]\n",
        "length = q.shape[0]\n",
        "print(q.device)\n",
        "print(t.device)\n",
        "print(device)\n",
        "t.to(device)\n",
        "pred, output = t.predict(q.unsqueeze(0).to(device))\n",
        "print(\"#àààààààààààààààààààààààààààààààààààààààààààààà\")\n",
        "c = translate(pred.squeeze(0), tokenizer.vocab)\n",
        "d = translate(a.squeeze(0), tokenizer.vocab)\n",
        "print(pred)\n",
        "print(translate(q,tokenizer.vocab))\n",
        "print(translate(a,tokenizer.vocab))\n",
        "print(\"trad 1: \", translate(pred.squeeze(0),tokenizer.vocab))\n",
        "print(\"traduziones: \", translate_from_output(output.squeeze(0),tokenizer.vocab))\n",
        "g = a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETyytmPMZhxx",
        "outputId": "8e9cd3a1-89d5-4b60-850c-a87b4d8bee84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n",
            "cuda\n",
            "#àààààààààààààààààààààààààààààààààààààààààààààà\n",
            "tensor([[ 1,  4, 32, 21, 24,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
            "          2,  2,  2,  2]], device='cuda:0', dtype=torch.int32)\n",
            "-546--29&&&&&&&&&&&&&&\n",
            "-517@&&&&&&&&&&&&&&&&&\n",
            "trad 1:  #-517@@@@@@@@@@@@@@@@@\n",
            "traduziones:  -517@@@@@@@@@@@@@@@@@&\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(acc)/len(acc)"
      ],
      "metadata": {
        "id": "3shG2RuoVpO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g77qbpYn07y4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "1a096e6a-9723-46ae-9bc7-95d42d8c99a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(t.state_dict(), 'trainato')"
      ],
      "metadata": {
        "id": "JDHGggG4y-A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.load_state_dict(torch.load('/content/drive/MyDrive/modellino.pth'))"
      ],
      "metadata": {
        "id": "MXQI9fjOmLLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RaXOrj_8KHy"
      },
      "source": [
        "# TP-Transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TPMultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, dropout=0.1):\n",
        "        super(TPMultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_r = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v,r, mask=False):\n",
        "        q = self.split_heads(self.W_q(q))\n",
        "        k = self.split_heads(self.W_k(k))\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "        r = self.split_heads(self.W_r(r))\n",
        "\n",
        "        att = self.att_score(q, k, v, mask)\n",
        "\n",
        "        out = self.W_o(self.combine_heads(att*r))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v, mask):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "\n",
        "        if mask: attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.emb_dim)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "        mask = torch.triu(torch.full((tensor.shape[2], tensor.shape[3]), float(\"-inf\"), device=device), diagonal=1)\n",
        "        tensor = tensor + mask\n",
        "\n",
        "        return tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x,x)\n",
        "\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPEncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TPDencoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDencoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x, x, mask=True)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output,encoder_output, out1)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(out2)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class TPDencoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDencoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TPDencoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class TPTransformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, num_layers=6, d_ff=256, dropout=0.1, teacher_forcing_ratio = 0.9):\n",
        "        super(TPTransformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        self.tgt_vocab_size=tgt_vocab_size\n",
        "\n",
        "        self.transformer_encoder = TPEncoder(self.d_model,self.num_heads)\n",
        "        self.transformer_decoder = TPDecoder(self.d_model, self.num_heads)\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "        if self.training:\n",
        "            teacher_force = random.random() < self.teacher_forcing_ratio\n",
        "            if teacher_force:\n",
        "                return self.classic_forward(batch)\n",
        "            else:\n",
        "                return self.predict(batch[0])\n",
        "        return self.predict(batch)\n",
        "\n",
        "\n",
        "    def classic_forward(self,batch):\n",
        "        src,tgt = batch\n",
        "        max_seq_length=src.shape[1]\n",
        "        batch_size = src.shape[0]\n",
        "        tgt = torch.cat((torch.ones((batch_size,1), dtype=torch.int).to(device), tgt[:, :-1]), dim = 1)\n",
        "\n",
        "        src_embedded = self.dropout(self.src_embedding(src))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))+self.positional_encoding(max_seq_length,self.d_model).to('cuda:0')\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(batch)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        TP_losses.append(loss.cpu().detach().numpy())\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        batch_q, batch_a = batch\n",
        "        ans_len=batch_a.shape[1]\n",
        "\n",
        "      # Computing prediction and accuracy\n",
        "        pred = self(batch_q)  # shape (batch_size, answer_max_length, dict_size)\n",
        "        accuracy = paper_accuracy(pred, batch_a)  # accuracy for the current batch as defined in the \"mathematics dataset\" paper\n",
        "\n",
        "        #print(accuracy)  # at the end of every epoch it is logged the average of the accuracies of each batch\n",
        "        TP_acc.append(accuracy)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "    def predict(self, x):\n",
        "        length=x.shape[1]\n",
        "        src_embedded = self.src_embedding(x).to(device)+self.positional_encoding(length,self.d_model).to(device)\n",
        "        encode = self.transformer_encoder(src_embedded)\n",
        "        batch_dim = x.shape[0]\n",
        "        out = torch.zeros((batch_dim, length), dtype = torch.int).to(device)\n",
        "        out[:,0] = 1\n",
        "        output=torch.zeros(batch_dim,length,self.tgt_vocab_size).to(device)\n",
        "        for i in range(length - 2 ):\n",
        "            tgt_embedded = self.tgt_embedding(out)+self.positional_encoding(length,self.d_model).to(device)\n",
        "            decode = self.transformer_decoder(tgt_embedded, encode)\n",
        "            output[:,i]+=self.fc(decode)[:,i]\n",
        "            prob = F.softmax(output , dim = -1)\n",
        "            arg_max = torch.argmax(prob, dim = -1)\n",
        "            out[:, i+1] = arg_max[:,i]\n",
        "        return self.classic_forward((x,out))\n",
        "\n",
        "\n",
        "TP_acc=[]\n",
        "TP_losses=[]\n",
        "TP_voc_len=len(tokenizer.vocab)\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "TP_t=TPTransformer(TP_voc_len,TP_voc_len, d_model = 512)\n",
        "TP_t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "TP_trainer = pl.Trainer(max_epochs=3)  # Modifica il numero di epoche come desiderato\n",
        "TP_trainer.fit(TP_t, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "64Ob5MCtTiLk",
        "outputId": "99afceeb-ab27-465c-d713-c47beded51c3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-3435f921a793>\u001b[0m in \u001b[0;36m<cell line: 273>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m \u001b[0mTP_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTPTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTP_voc_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTP_voc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0mTP_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-3435f921a793>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, dropout, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TPDecoder' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f8177684e95f4fb2ab3008c6b7e3cb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cfe35efec5543f0b22e9d4dcc80f0fe",
              "IPY_MODEL_2c44875630e8443a8b99b16ba02d31ca",
              "IPY_MODEL_5f78839c0fda45d3a6971392f77dbb6c"
            ],
            "layout": "IPY_MODEL_f7cce7f19b5a47db9d56d68518f6bd73"
          }
        },
        "9cfe35efec5543f0b22e9d4dcc80f0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51e25c0450c349f5a7cfddaf0a3fb8f9",
            "placeholder": "​",
            "style": "IPY_MODEL_fffc0849248b4e1e91b66e31cf2b9f96",
            "value": "Testing: "
          }
        },
        "2c44875630e8443a8b99b16ba02d31ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a890ed9e4cb4649966d5eb8ea5c9f11",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc0252b290bb4d72bd6ced345d2df52f",
            "value": 1
          }
        },
        "5f78839c0fda45d3a6971392f77dbb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55f29403c4c84732b17c392d1e9fb345",
            "placeholder": "​",
            "style": "IPY_MODEL_7f2e473f297a4d729acd4174f97fa98e",
            "value": " 420/? [02:28&lt;00:00,  2.83it/s]"
          }
        },
        "f7cce7f19b5a47db9d56d68518f6bd73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "51e25c0450c349f5a7cfddaf0a3fb8f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fffc0849248b4e1e91b66e31cf2b9f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a890ed9e4cb4649966d5eb8ea5c9f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0252b290bb4d72bd6ced345d2df52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55f29403c4c84732b17c392d1e9fb345": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f2e473f297a4d729acd4174f97fa98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanoiervese/DL_Project/blob/main/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNDAFYDRiQNg"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xr2w9xJ9vPi",
        "outputId": "4a939881-5453-4f93-bca5-a44e74894441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.getcwd()\n",
        "path='/content/drive/MyDrive/mathematics_dataset-v1.0/train-easy/arithmetic__add_or_sub.txt'\n",
        "#os.listdir(path)\n",
        "with open(path, \"r\") as file:\n",
        "    # Leggi il contenuto del file\n",
        "    content = file.read()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "08BsEJoGXgmu"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "data_list = [x for x in content.split('\\n')]\n",
        "data_list=data_list[:-1]\n",
        "len_data=len(data_list)\n",
        "quest=[]\n",
        "ans=[]\n",
        "for i in range(len_data):\n",
        "  if(i%2==0):\n",
        "    quest.append(data_list[i])\n",
        "  else:\n",
        "    ans.append(data_list[i])\n",
        "coppie = list(zip(quest,ans))\n",
        "random.shuffle(coppie)\n",
        "quest, ans=zip(*coppie)\n",
        "l=int(len(quest)/3)\n",
        "train_q=quest[:2*l]\n",
        "test_q=quest[2*l:]\n",
        "train_a=ans[:2*l]\n",
        "test_a=ans[2*l:]\n",
        "\n",
        "voc_size=len([sentence.split() for sentence in data_list])\n",
        "\n",
        "\n",
        "def crea_vocabolario(frasi):\n",
        "    vocabolario = set()\n",
        "\n",
        "    for frase in frasi:\n",
        "        # Utilizza un'espressione regolare per estrarre parole, numeri e simboli dalla frase\n",
        "        parole = re.findall(r'\\d|\\.|[-=+*/()?]|\\S+|\\?', frase.lower())\n",
        "\n",
        "        # Aggiungi le parole al vocabolario\n",
        "        vocabolario.update(parole)\n",
        "\n",
        "\n",
        "    return list(vocabolario)+['unknown']\n",
        "\n",
        "v=crea_vocabolario(data_list)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzndWSJKjYLG"
      },
      "source": [
        "# Token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcr34WNkgaIc",
        "outputId": "0296d1b4-cae6-4339-d898-931e68527c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parole sconosciute: ['What']\n",
            "Token IDs: [38, 37, 9, 4]\n"
          ]
        }
      ],
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "        self.word_to_id = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        tokens = re.findall(r'\\d|\\.|[-=+*/()?]|\\S+', text)\n",
        "\n",
        "\n",
        "\n",
        "        token_id = []\n",
        "        unknown_tokens = []\n",
        "\n",
        "        new_tokens = []\n",
        "        for token in tokens:\n",
        "          flag=0\n",
        "          if '.' in token and token != '.':\n",
        "            token=token=token.split('.')[0]\n",
        "            flag=1\n",
        "          if token in self.word_to_id:\n",
        "            token_id.append(self.word_to_id[token])\n",
        "          else:\n",
        "                token_id.append(self.word_to_id['unknown'])\n",
        "                unknown_tokens.append(token)\n",
        "          if(flag==1):\n",
        "            token_id.append(self.word_to_id['.'])\n",
        "\n",
        "\n",
        "        if unknown_tokens:\n",
        "            print(\"Parole sconosciute:\", unknown_tokens)\n",
        "\n",
        "        return token_id\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(v)\n",
        "\n",
        "text = \"What is 3?\"\n",
        "token_ids = tokenizer.tokenize(text)\n",
        "print(\"Token IDs:\", token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2qqpAtgiexx"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eksaAYSFjxqJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "qt=[]\n",
        "at=[]\n",
        "for x in train_q:\n",
        "  qt.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "for x in train_a:\n",
        "  at.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "\n",
        "qtest=[]\n",
        "atest=[]\n",
        "for x in test_q:\n",
        "  qtest.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "for x in test_a:\n",
        "  atest.append(torch.tensor(tokenizer.tokenize(x.lower())))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUIrAXy1pejB"
      },
      "outputs": [],
      "source": [
        "pip install pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tcep7jbFtFw_"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pack_sequence, pad_sequence\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, questions, answers):\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.questions[idx], self.answers[idx]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "voc_size=100\n",
        "src_data = torch.randint(1, voc_size, (3264, 6))\n",
        "tg_data=torch.randint(1,voc_size,(3264,8))\n",
        "fake_dataset=Dataset(src_data,tg_data)\n",
        "fake_loader=DataLoader(fake_dataset,batch_size=32,shuffle=True)\n",
        "\n",
        "max_length1 = max(len(tensor) for tensor in qt)\n",
        "max_length2 = max(len(tensor) for tensor in at)\n",
        "max_length=max(max_length1,max_length2)\n",
        "qtp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in qt], batch_first=True)\n",
        "atp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in at], batch_first=True)\n",
        "\n",
        "\n",
        "max_length1 = max(len(tensor) for tensor in qtest)\n",
        "max_length2 = max(len(tensor) for tensor in atest)\n",
        "max_length=max(max_length1,max_length2)\n",
        "qtestp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in qtest], batch_first=True)\n",
        "atestp = pad_sequence([torch.cat([tensor, torch.zeros(max_length - len(tensor),dtype=torch.int)]) for tensor in atest], batch_first=True)\n",
        "\n",
        "\n",
        "batch_size = 3\n",
        "\n",
        "train_dataset = Dataset(qtp,atp)\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "'''\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=lambda batch: (\n",
        "    pad_sequence([item[0] for item in batch], batch_first=True),\n",
        "    pad_sequence([item[1] for item in batch], batch_first=True)\n",
        "))'''\n",
        "test_dataset = Dataset(qtestp,atestp)\n",
        "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSUfm1fqiGVp"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757,
          "referenced_widgets": [
            "6839e54149114eb596d36cc43d2ad03b",
            "17463f1794c04366a7f7a08a76696406",
            "a9113e9c7e9c4b329075b010b5b9b27e",
            "6794944435b64e768b4e5bde6500e858",
            "54c66b349a57417aa91618a8efa4b1a1",
            "777b8c712e1247d6a09f0c12e7155fa2",
            "96d6f26fab084fec9b285cb5ec32011e",
            "7981eecff10f478e82d0ad4522488a37",
            "7cced92b85104a069c2f6e8e00556d16",
            "ba36dea4de6143409d397e150e6d98b9",
            "0422690790d84df195ebb3832cbb832e"
          ]
        },
        "id": "hnvuAfhEqLBN",
        "outputId": "fbcf1a52-e7db-4840-d4b7-bc849b4f5384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                | Type      | Params\n",
            "--------------------------------------------------\n",
            "0 | src_embedding       | Embedding | 156   \n",
            "1 | tgt_embedding       | Embedding | 156   \n",
            "2 | transformer_encoder | Encoder   | 2.3 K \n",
            "3 | transformer_decoder | Decoder   | 2.9 K \n",
            "4 | fc                  | Linear    | 195   \n",
            "5 | dropout             | Dropout   | 0     \n",
            "--------------------------------------------------\n",
            "5.7 K     Trainable params\n",
            "0         Non-trainable params\n",
            "5.7 K     Total params\n",
            "0.023     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6839e54149114eb596d36cc43d2ad03b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-58c9d7db00dc>\u001b[0m in \u001b[0;36m<cell line: 260>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Modifica il numero di epoche come desiderato\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;31m#model_path='/content/drive/MyDrive/mathematics_dataset-v1.0/model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 )\n\u001b[1;32m    738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_unwrap_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0m_verify_strategy_supports_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/compile.py\u001b[0m in \u001b[0;36m_maybe_unwrap_optimized\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;34mf\"`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `{type(model).__qualname__}`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     )\n",
            "\u001b[0;31mTypeError\u001b[0m: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `DataLoader`"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import pytorch_lightning as pl\n",
        "import torch.optim as optim\n",
        "\n",
        "class MultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads,dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v):\n",
        "        q = self.split_heads(self.W_q(q))  #64,2,22,2\n",
        "        k = self.split_heads(self.W_k(k))  #64,2,2,22\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "\n",
        "\n",
        "        att = self.att_score(q, k, v)  #62,2,22,22\n",
        "        out = self.W_o(self.combine_heads(att))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        attn_scores=self.apply_mask(attn_scores)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.emb_dim)\n",
        "\n",
        "    def apply_mask(self,tensor):\n",
        "      for i in range(tensor.size(0)):\n",
        "        for j in range(tensor.size(1)):\n",
        "          matrix = tensor[i, j]\n",
        "\n",
        "          mask = torch.triu(torch.ones(matrix.size(0), matrix.size(1)), diagonal=0,).t().to('cuda:0')\n",
        "\n",
        "          matrix = matrix * mask+ (-1e9) * (1 - mask)\n",
        "          tensor[i, j] = matrix\n",
        "          return tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class EncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x)\n",
        "\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = MultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output, encoder_output)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(x)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "class Decoder(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, num_layers=6, feedforward_dim=32, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(emb_dim, num_heads, feedforward_dim, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "        return x\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Transformer(pl.LightningModule):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=4, num_heads=2, num_layers=6, d_ff=256, max_seq_length=22, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model=d_model\n",
        "        self.num_heads=num_heads\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = self.positional_encoding(max_seq_length=max_length, d_model=d_model)\n",
        "\n",
        "        self.transformer_encoder = Encoder(self.d_model,self.num_heads\n",
        "\n",
        "        )\n",
        "        self.transformer_decoder =Decoder(self.d_model,self.num_heads\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        #self.positional_encoding = self.positional_encoding(max_seq_length, d_model)  # Correggi l'argomento qui\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_embedded = self.dropout(self.src_embedding(src))\n",
        "\n",
        "        tgt_embedded = self.dropout(self.tgt_embedding(tgt))\n",
        "\n",
        "\n",
        "        enc_output = self.transformer_encoder(src_embedded)\n",
        "        dec_output = self.transformer_decoder(tgt_embedded, enc_output)\n",
        "\n",
        "        output = self.fc(dec_output)\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "        tgt_mask = (tgt != 0)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src, tgt)\n",
        "        tgt_mask = (tgt != 0)\n",
        "        loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "        self.log('val_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "      src, tgt = batch\n",
        "      output = self(src, tgt)\n",
        "      tgt_mask = (tgt != 0)\n",
        "      loss = nn.CrossEntropyLoss(ignore_index=0)(output.view(-1, output.size(-1)), tgt.view(-1))\n",
        "      self.log('test_loss', loss)  # Registra la loss del test\n",
        "      return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def positional_encoding(self, max_seq_length, d_model):\n",
        "\n",
        "        positional_encoding = torch.zeros(max_seq_length, d_model)\n",
        "        pos = torch.arange(0, max_seq_length, dtype=torch.float32).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        positional_encoding[:, 0::2] = torch.sin(pos * div_term)\n",
        "        positional_encoding[:, 1::2] = torch.cos(pos * div_term)\n",
        "        return positional_encoding\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "voc_len=len(v)\n",
        "t=Transformer(voc_len,voc_len)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "t.to(device)\n",
        "print(device)\n",
        "# Addestra il modello\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=5)  # Modifica il numero di epoche come desiderato\n",
        "trainer.fit(t, train_loader)\n",
        "trainer.test(test_loader)\n",
        "\n",
        "#model_path='/content/drive/MyDrive/mathematics_dataset-v1.0/model'\n",
        "\n",
        "\n",
        "#torch.save(t.state_dict(), model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULm4j3B22o9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Crea un tensore di esempio con matrici 3x3 duplicate\n",
        "tensor = torch.tensor([[[[1, 2, 3],\n",
        "                         [4, 5, 6],\n",
        "                         [7, 8, 9]],\n",
        "                        [[10, 11, 12],\n",
        "                         [13, 14, 15],\n",
        "                         [16, 17, 18]],\n",
        "                        [[19, 20, 21],\n",
        "                         [22, 23, 24],\n",
        "                         [25, 26, 27]],\n",
        "                        [[28, 29, 30],\n",
        "                         [31, 32, 33],\n",
        "                         [34, 35, 36]],\n",
        "                        [[37, 38, 39],\n",
        "                         [40, 41, 42],\n",
        "                         [43, 44, 45]]],\n",
        "                       [[[46, 47, 48],\n",
        "                         [49, 50, 51],\n",
        "                         [52, 53, 54]],\n",
        "                        [[55, 56, 57],\n",
        "                         [58, 59, 60],\n",
        "                         [61, 62, 63]],\n",
        "                        [[64, 65, 66],\n",
        "                         [67, 68, 69],\n",
        "                         [70, 71, 72]],\n",
        "                        [[73, 74, 75],\n",
        "                         [76, 77, 78],\n",
        "                         [79, 80, 81]],\n",
        "                        [[82, 83, 84],\n",
        "                         [85, 86, 87],\n",
        "                         [88, 89, 90]]]])\n",
        "\n",
        "# Imposta tutti i valori sopra la diagonale principale di ciascuna matrice a zero\n",
        "for i in range(tensor.size(0)):\n",
        "    for j in range(tensor.size(1)):\n",
        "        matrix = tensor[i, j]\n",
        "        mask = torch.triu(torch.ones(matrix.size(0), matrix.size(1)), diagonal=0).t()\n",
        "        matrix = matrix * mask+ (-1e9) * (1 - mask)\n",
        "        tensor[i, j] = matrix\n",
        "\n",
        "print(\"Tensore originale:\")\n",
        "print(tensor)\n",
        "\n"
      ],
      "metadata": {
        "id": "BbATkiwE2cqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([[1, 2, 3],\n",
        "                       [4, 5, 6],\n",
        "                       [7, 8, 9]])\n",
        "\n",
        "# Crea una maschera booleana per nascondere alcuni elementi nel tensore\n",
        "mask = torch.tensor([[0, 1, 0],  # Nascondi la seconda colonna\n",
        "                     [1, 0, 1],  # Nascondi la prima e la terza colonna\n",
        "                     [0, 1, 0]]) # Nascondi la seconda colonna\n",
        "\n",
        "# Applica la maschera al tensore utilizzando masked_fill\n",
        "masked_tensor = tensor.masked_fill(mask == 0, -1)\n",
        "\n",
        "print(\"Tensore originale:\")\n",
        "print(tensor)\n",
        "\n",
        "print(\"\\nMaschera:\")\n",
        "print(mask)\n",
        "\n",
        "print(\"\\nTensore mascherato:\")\n",
        "print(masked_tensor)"
      ],
      "metadata": {
        "id": "B_0-4hzM-jXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(size):\n",
        "    mask = torch.triu(torch.ones(size, size)).t()\n",
        "    return mask\n",
        "generate_square_subsequent_mask(3)"
      ],
      "metadata": {
        "id": "KMAuk6Vl3uDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adVxFxb2ydm3"
      },
      "outputs": [],
      "source": [
        "model_path='/content/drive/MyDrive/model'\n",
        "t.load_state_dict(torch.load(model_path))\n",
        "t.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(t.state_dict(), 'modello_dopo_training.pth')"
      ],
      "metadata": {
        "id": "JDHGggG4y-A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpG2sQjR5SlI"
      },
      "outputs": [],
      "source": [
        "trainer.test(t,test_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RaXOrj_8KHy"
      },
      "source": [
        "# TP-Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVK99j1M8OMt"
      },
      "outputs": [],
      "source": [
        "class TPMultiHeadAttention(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads,dropout=0.1):\n",
        "        super(TPMultiHeadAttention, self).__init__()\n",
        "        assert emb_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = self.emb_dim // num_heads\n",
        "\n",
        "        # Inizializzazione dei moduli lineari per proiettare Q, K, V e l'output.\n",
        "        self.W_q = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_k = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_v = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_r = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "        self.W_o = nn.Linear(self.emb_dim, self.emb_dim)\n",
        "\n",
        "\n",
        "    def forward(self, q,k,v,r):\n",
        "        q = self.split_heads(self.W_q(q))\n",
        "        k = self.split_heads(self.W_k(k))\n",
        "        v = self.split_heads(self.W_v(v))\n",
        "        r = self.split_heads(self.W_r(r))\n",
        "\n",
        "        att = self.att_score(q, k, v, mask)\n",
        "        filler = torch.tensordot(att, r, dims=0)\n",
        "        diagonal = torch.diagonal(filler)\n",
        "\n",
        "\n",
        "        out = self.W_o(self.combine_heads(att))\n",
        "\n",
        "        return out\n",
        "\n",
        "    def att_score(self, q, k, v):\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, v)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, head_dim = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.emb_dim)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TPEncoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPEncoderLayer, self).__init__()\n",
        "\n",
        "        self.multihead_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "\n",
        "        att = self.multihead_attention(x,x,x,x, mask)\n",
        "\n",
        "        add_nor = self.layer_norm1(x + self.dropout(att))\n",
        "        ff_out = self.feedforward(add_nor)\n",
        "        out = self.layer_norm2(add_nor + self.dropout(ff_out))\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class TPDecoderLayer(pl.LightningModule):\n",
        "    def __init__(self, emb_dim, num_heads, feedforward_dim=32, dropout=0.1):\n",
        "        super(TPDecoderLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention Layer (Auto-Attention)\n",
        "        self.self_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Cross-Attention Layer (Attenzione incrociata con l'encoder)\n",
        "        self.cross_attention = TPMultiHeadAttention(emb_dim, num_heads)\n",
        "\n",
        "        # Feedforward Neural Network Layer\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(emb_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, emb_dim)\n",
        "        )\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.layer_norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm2 = nn.LayerNorm(emb_dim)\n",
        "        self.layer_norm3 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n",
        "\n",
        "        attn_output = self.self_attention(x, x, x,x, tgt_mask)\n",
        "        out1 = self.layer_norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attention(out1, encoder_output, encoder_output, encoder_output, src_mask)\n",
        "        out2 = self.layer_norm2(out1 + self.dropout(attn_output))\n",
        "        ff_output = self.feedforward(x)\n",
        "        out3 = self.layer_norm3(out2 + self.dropout(ff_output))\n",
        "        return out3\n",
        "\n",
        "\n",
        "voc_len=39\n",
        "t2=Transformer(voc_len,voc_len)\n",
        "trainer2 = pl.Trainer(max_epochs=1)  # Modifica il numero di epoche come desiderato\n",
        "trainer2.fit(t2, train_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzVKAvZCmwHCZIhf5Ejr3N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6839e54149114eb596d36cc43d2ad03b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17463f1794c04366a7f7a08a76696406",
              "IPY_MODEL_a9113e9c7e9c4b329075b010b5b9b27e",
              "IPY_MODEL_6794944435b64e768b4e5bde6500e858"
            ],
            "layout": "IPY_MODEL_54c66b349a57417aa91618a8efa4b1a1"
          }
        },
        "17463f1794c04366a7f7a08a76696406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_777b8c712e1247d6a09f0c12e7155fa2",
            "placeholder": "​",
            "style": "IPY_MODEL_96d6f26fab084fec9b285cb5ec32011e",
            "value": "Epoch 0:   0%"
          }
        },
        "a9113e9c7e9c4b329075b010b5b9b27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7981eecff10f478e82d0ad4522488a37",
            "max": 148148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cced92b85104a069c2f6e8e00556d16",
            "value": 260
          }
        },
        "6794944435b64e768b4e5bde6500e858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba36dea4de6143409d397e150e6d98b9",
            "placeholder": "​",
            "style": "IPY_MODEL_0422690790d84df195ebb3832cbb832e",
            "value": " 260/148148 [00:11&lt;1:50:21, 22.33it/s, v_num=34]"
          }
        },
        "54c66b349a57417aa91618a8efa4b1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "777b8c712e1247d6a09f0c12e7155fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96d6f26fab084fec9b285cb5ec32011e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7981eecff10f478e82d0ad4522488a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cced92b85104a069c2f6e8e00556d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba36dea4de6143409d397e150e6d98b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0422690790d84df195ebb3832cbb832e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
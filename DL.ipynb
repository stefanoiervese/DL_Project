{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3xr2w9xJ9vPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0129b6ba-c55d-4a8f-b5d1-ad447a250138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.listdir('/content/drive/MyDrive/mathematics_dataset-v1.0/train-easy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJVyzfPAjZQ4",
        "outputId": "fccd82c0-974b-4477-d5ce-02dc15a7f887"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['algebra__linear_1d.txt',\n",
              " 'algebra__linear_1d_composed.txt',\n",
              " 'algebra__linear_2d.txt',\n",
              " 'algebra__linear_2d_composed.txt',\n",
              " 'algebra__polynomial_roots.txt',\n",
              " 'algebra__polynomial_roots_composed.txt',\n",
              " 'algebra__sequence_next_term.txt',\n",
              " 'algebra__sequence_nth_term.txt',\n",
              " 'arithmetic__add_or_sub.txt',\n",
              " 'arithmetic__add_or_sub_in_base.txt',\n",
              " 'arithmetic__add_sub_multiple.txt',\n",
              " 'arithmetic__div.txt',\n",
              " 'arithmetic__mixed.txt',\n",
              " 'arithmetic__mul.txt',\n",
              " 'arithmetic__mul_div_multiple.txt',\n",
              " 'arithmetic__nearest_integer_root.txt',\n",
              " 'arithmetic__simplify_surd.txt',\n",
              " 'calculus__differentiate.txt',\n",
              " 'calculus__differentiate_composed.txt',\n",
              " 'comparison__closest.txt',\n",
              " 'comparison__closest_composed.txt',\n",
              " 'comparison__kth_biggest.txt',\n",
              " 'comparison__kth_biggest_composed.txt',\n",
              " 'comparison__pair.txt',\n",
              " 'comparison__pair_composed.txt',\n",
              " 'comparison__sort.txt',\n",
              " 'comparison__sort_composed.txt',\n",
              " 'measurement__conversion.txt',\n",
              " 'measurement__time.txt',\n",
              " 'numbers__base_conversion.txt',\n",
              " 'numbers__div_remainder.txt',\n",
              " 'numbers__div_remainder_composed.txt',\n",
              " 'numbers__gcd.txt',\n",
              " 'numbers__gcd_composed.txt',\n",
              " 'numbers__is_factor.txt',\n",
              " 'numbers__is_factor_composed.txt',\n",
              " 'numbers__is_prime.txt',\n",
              " 'numbers__is_prime_composed.txt',\n",
              " 'numbers__lcm.txt',\n",
              " 'numbers__lcm_composed.txt',\n",
              " 'numbers__list_prime_factors.txt',\n",
              " 'numbers__list_prime_factors_composed.txt',\n",
              " 'numbers__place_value.txt',\n",
              " 'numbers__place_value_composed.txt',\n",
              " 'numbers__round_number.txt',\n",
              " 'numbers__round_number_composed.txt',\n",
              " 'polynomials__add.txt',\n",
              " 'polynomials__coefficient_named.txt',\n",
              " 'polynomials__collect.txt',\n",
              " 'polynomials__compose.txt',\n",
              " 'polynomials__evaluate.txt',\n",
              " 'polynomials__evaluate_composed.txt',\n",
              " 'polynomials__expand.txt',\n",
              " 'polynomials__simplify_power.txt',\n",
              " 'probability__swr_p_level_set.txt',\n",
              " 'probability__swr_p_sequence.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import words\n",
        "nltk.download('words')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssj6P_QQFEhw",
        "outputId": "55117860-0883-499d-f953-0f75e235ead3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check(x,vocabulary):\n",
        "  if x in vocabulary:\n",
        "    print(f\"{x} presente in vocabulary.\")\n",
        "  else:\n",
        "    print(f\"{x} non Ã¨ presente in vocabulary.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "k2KHttKvXqNq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "        self.word_to_id = {word: idx/10000 for idx, word in enumerate(vocab)}\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        tokens = re.findall(r'\\d|\\.|[-=+*/()?]|\\S+', text)\n",
        "\n",
        "\n",
        "\n",
        "        token_id = []\n",
        "        unknown_tokens = []\n",
        "\n",
        "        new_tokens = []\n",
        "        for token in tokens:\n",
        "          flag=0\n",
        "          if '.' in token and token != '.':\n",
        "            token=token=token.split('.')[0]\n",
        "            flag=1\n",
        "          if token in self.word_to_id:\n",
        "            token_id.append(self.word_to_id[token])\n",
        "          else:\n",
        "                token_id.append(self.word_to_id['unknown'])\n",
        "                unknown_tokens.append(token)\n",
        "          if(flag==1):\n",
        "            token_id.append(self.word_to_id['.'])\n",
        "\n",
        "\n",
        "        if unknown_tokens:\n",
        "            print(\"Parole sconosciute:\", unknown_tokens)\n",
        "\n",
        "        return token_id\n",
        "\n",
        "\n",
        "math_vocab = ['0','1','2','3','4','5','6','7','8','9','.','+',',','-','*','/', '?','(',')']\n",
        "english_words = words.words()\n",
        "vocab = math_vocab+english_words\n",
        "tokenizer = Tokenizer(vocab)\n",
        "\n",
        "text = \"(3*2?). \"\n",
        "token_ids = tokenizer.tokenize(text)\n",
        "print(\"Token IDs:\", token_ids)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUDhV4deahzy",
        "outputId": "bdd6ad46-0018-4795-c8f1-a1dc3c6411a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: [0.0017, 0.0003, 0.0014, 0.0002, 0.0016, 0.0018, 0.001]\n"
          ]
        }
      ]
    }
  ]
}